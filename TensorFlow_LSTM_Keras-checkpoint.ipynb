{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w4J2LlgHrd_l"
   },
   "source": [
    "**IMPORT LIBRARY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOsitRsGrnjr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlmEwyUbf2I5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import pandas_datareader.data as web\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jPR8nHH4r0ap"
   },
   "source": [
    "**IMPORT DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "PljmPNQ5f99B",
    "outputId": "a03333e3-7d8b-4ec8-9fc6-a8d894955740"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-e2461d9c-c56a-42f6-91b6-5f590c8d605c\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-e2461d9c-c56a-42f6-91b6-5f590c8d605c\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Data.csv to Data (3).csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "CaaSSK9Uf2JF",
    "outputId": "1c67c184-1cde-45cd-f8c9-5cf3b34b7ff0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEXSZUS    0\n",
       "DEXCHUS    0\n",
       "DEXMXUS    0\n",
       "DEXBZUS    0\n",
       "DEXINUS    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forex_df = pd.read_csv(\"Data.csv\", index_col = 0)\n",
    "forex_df.dropna(inplace=True)\n",
    "forex_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "4EsfbN8OOsrJ",
    "outputId": "43cad4bf-636e-4051-8e2b-57ed4489568f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEXSZUS</th>\n",
       "      <th>DEXCHUS</th>\n",
       "      <th>DEXMXUS</th>\n",
       "      <th>DEXBZUS</th>\n",
       "      <th>DEXINUS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5/20/2016</th>\n",
       "      <td>0.9920</td>\n",
       "      <td>6.5485</td>\n",
       "      <td>18.3770</td>\n",
       "      <td>3.5386</td>\n",
       "      <td>67.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/23/2016</th>\n",
       "      <td>0.9919</td>\n",
       "      <td>6.5533</td>\n",
       "      <td>18.4710</td>\n",
       "      <td>3.5753</td>\n",
       "      <td>67.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/24/2016</th>\n",
       "      <td>0.9930</td>\n",
       "      <td>6.5552</td>\n",
       "      <td>18.4435</td>\n",
       "      <td>3.5518</td>\n",
       "      <td>67.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/25/2016</th>\n",
       "      <td>0.9908</td>\n",
       "      <td>6.5538</td>\n",
       "      <td>18.4500</td>\n",
       "      <td>3.6072</td>\n",
       "      <td>67.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/26/2016</th>\n",
       "      <td>0.9898</td>\n",
       "      <td>6.5540</td>\n",
       "      <td>18.4500</td>\n",
       "      <td>3.5775</td>\n",
       "      <td>66.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  DEXSZUS  DEXCHUS  DEXMXUS  DEXBZUS  DEXINUS\n",
       "observation_date                                             \n",
       "5/20/2016          0.9920   6.5485  18.3770   3.5386    67.42\n",
       "5/23/2016          0.9919   6.5533  18.4710   3.5753    67.47\n",
       "5/24/2016          0.9930   6.5552  18.4435   3.5518    67.59\n",
       "5/25/2016          0.9908   6.5538  18.4500   3.6072    67.28\n",
       "5/26/2016          0.9898   6.5540  18.4500   3.5775    66.90"
      ]
     },
     "execution_count": 127,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "miXUnjHqxzTS",
    "outputId": "9a8cddef-303e-4f30-902c-615731c83eb9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEXSZUS</th>\n",
       "      <th>DEXCHUS</th>\n",
       "      <th>DEXMXUS</th>\n",
       "      <th>DEXBZUS</th>\n",
       "      <th>DEXINUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>577.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.981327</td>\n",
       "      <td>6.662789</td>\n",
       "      <td>19.001787</td>\n",
       "      <td>3.332352</td>\n",
       "      <td>66.130191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.020380</td>\n",
       "      <td>0.194325</td>\n",
       "      <td>0.877940</td>\n",
       "      <td>0.235594</td>\n",
       "      <td>1.746024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.923200</td>\n",
       "      <td>6.264900</td>\n",
       "      <td>17.477500</td>\n",
       "      <td>3.055700</td>\n",
       "      <td>63.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.967300</td>\n",
       "      <td>6.561100</td>\n",
       "      <td>18.485000</td>\n",
       "      <td>3.169900</td>\n",
       "      <td>64.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.983100</td>\n",
       "      <td>6.668500</td>\n",
       "      <td>18.830000</td>\n",
       "      <td>3.253000</td>\n",
       "      <td>66.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.995300</td>\n",
       "      <td>6.842700</td>\n",
       "      <td>19.361000</td>\n",
       "      <td>3.386000</td>\n",
       "      <td>67.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.033400</td>\n",
       "      <td>6.958000</td>\n",
       "      <td>21.891000</td>\n",
       "      <td>4.201600</td>\n",
       "      <td>71.940000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DEXSZUS     DEXCHUS     DEXMXUS     DEXBZUS     DEXINUS\n",
       "count  577.000000  577.000000  577.000000  577.000000  577.000000\n",
       "mean     0.981327    6.662789   19.001787    3.332352   66.130191\n",
       "std      0.020380    0.194325    0.877940    0.235594    1.746024\n",
       "min      0.923200    6.264900   17.477500    3.055700   63.380000\n",
       "25%      0.967300    6.561100   18.485000    3.169900   64.530000\n",
       "50%      0.983100    6.668500   18.830000    3.253000   66.500000\n",
       "75%      0.995300    6.842700   19.361000    3.386000   67.400000\n",
       "max      1.033400    6.958000   21.891000    4.201600   71.940000"
      ]
     },
     "execution_count": 128,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forex_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4aPbEEm2EOS0"
   },
   "source": [
    "**Correlation Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "id": "pJCn-cdGNp3P",
    "outputId": "a363542b-0d11-457f-d045-1874a7d616c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff22b69df98>"
      ]
     },
     "execution_count": 129,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcQAAAFKCAYAAACD5S+3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQRAEARAJURAEQRAAkRAFQRAEAYD/BxQzCxtwb/j9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff22b639b70>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(forex_df.corr(),annot= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iB2MKT-eFDgl"
   },
   "source": [
    "**Dropping China's Foreign Exchange column**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2ZlkTiLPBe6"
   },
   "source": [
    "**As  DEXCHUS has a corr value of 0.26 we are dropping that column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oN1QIuUrPVSO"
   },
   "outputs": [],
   "source": [
    "forex_df.drop('DEXCHUS', axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "tJSoP7WMPoiX",
    "outputId": "edbfdcc2-c10f-4daf-ed8a-c901f30ea01b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEXSZUS</th>\n",
       "      <th>DEXMXUS</th>\n",
       "      <th>DEXBZUS</th>\n",
       "      <th>DEXINUS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5/20/2016</th>\n",
       "      <td>0.9920</td>\n",
       "      <td>18.3770</td>\n",
       "      <td>3.5386</td>\n",
       "      <td>67.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/23/2016</th>\n",
       "      <td>0.9919</td>\n",
       "      <td>18.4710</td>\n",
       "      <td>3.5753</td>\n",
       "      <td>67.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/24/2016</th>\n",
       "      <td>0.9930</td>\n",
       "      <td>18.4435</td>\n",
       "      <td>3.5518</td>\n",
       "      <td>67.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/25/2016</th>\n",
       "      <td>0.9908</td>\n",
       "      <td>18.4500</td>\n",
       "      <td>3.6072</td>\n",
       "      <td>67.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/26/2016</th>\n",
       "      <td>0.9898</td>\n",
       "      <td>18.4500</td>\n",
       "      <td>3.5775</td>\n",
       "      <td>66.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  DEXSZUS  DEXMXUS  DEXBZUS  DEXINUS\n",
       "observation_date                                    \n",
       "5/20/2016          0.9920  18.3770   3.5386    67.42\n",
       "5/23/2016          0.9919  18.4710   3.5753    67.47\n",
       "5/24/2016          0.9930  18.4435   3.5518    67.59\n",
       "5/25/2016          0.9908  18.4500   3.6072    67.28\n",
       "5/26/2016          0.9898  18.4500   3.5775    66.90"
      ]
     },
     "execution_count": 131,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "28Va3XDOf2LK",
    "outputId": "74fda745-83ad-4e47-9620-1b728789d36e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 577 entries, 5/20/2016 to 9/7/2018\n",
      "Data columns (total 4 columns):\n",
      "DEXSZUS    577 non-null float64\n",
      "DEXMXUS    577 non-null float64\n",
      "DEXBZUS    577 non-null float64\n",
      "DEXINUS    577 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 22.5+ KB\n"
     ]
    }
   ],
   "source": [
    "forex_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPe_mFAsFQWV"
   },
   "source": [
    "**No NULL values in forex_df dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bEoWn8JOP2sB"
   },
   "source": [
    "**Since the range of the columns are at  different scales we are NORMALIZING the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWhanAaZf2LU"
   },
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "-ZqQu78of2LW",
    "outputId": "7f6cbb3d-f402-4442-960c-dad9ce8ddfc6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEXSZUS</th>\n",
       "      <th>DEXMXUS</th>\n",
       "      <th>DEXBZUS</th>\n",
       "      <th>DEXINUS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5/20/2016</th>\n",
       "      <td>0.624319</td>\n",
       "      <td>0.203807</td>\n",
       "      <td>0.421415</td>\n",
       "      <td>0.471963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/23/2016</th>\n",
       "      <td>0.623412</td>\n",
       "      <td>0.225105</td>\n",
       "      <td>0.453443</td>\n",
       "      <td>0.477804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/24/2016</th>\n",
       "      <td>0.633394</td>\n",
       "      <td>0.218874</td>\n",
       "      <td>0.432935</td>\n",
       "      <td>0.491822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/25/2016</th>\n",
       "      <td>0.613430</td>\n",
       "      <td>0.220347</td>\n",
       "      <td>0.481281</td>\n",
       "      <td>0.455607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/26/2016</th>\n",
       "      <td>0.604356</td>\n",
       "      <td>0.220347</td>\n",
       "      <td>0.455363</td>\n",
       "      <td>0.411215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   DEXSZUS   DEXMXUS   DEXBZUS   DEXINUS\n",
       "observation_date                                        \n",
       "5/20/2016         0.624319  0.203807  0.421415  0.471963\n",
       "5/23/2016         0.623412  0.225105  0.453443  0.477804\n",
       "5/24/2016         0.633394  0.218874  0.432935  0.491822\n",
       "5/25/2016         0.613430  0.220347  0.481281  0.455607\n",
       "5/26/2016         0.604356  0.220347  0.455363  0.411215"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_data(df):\n",
    "    min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    df['DEXINUS'] = min_max_scaler.fit_transform(df.DEXINUS.values.reshape(-1,1))\n",
    "    df['DEXMXUS'] = min_max_scaler.fit_transform(df.DEXMXUS.values.reshape(-1,1))\n",
    "    df['DEXBZUS'] = min_max_scaler.fit_transform(df.DEXBZUS.values.reshape(-1,1))\n",
    "    df['DEXSZUS'] = min_max_scaler.fit_transform(df.DEXSZUS.values.reshape(-1,1))\n",
    "    return df\n",
    "  \n",
    "forex_df_norm = normalize_data(forex_df)\n",
    "forex_df_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNbQ83jbFqAG"
   },
   "source": [
    "**Ploting  Normalized Forex Market**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "colab_type": "code",
    "id": "vVEnNdAxsr1t",
    "outputId": "a1efd747-2329-4ca5-8f2b-94feb9dcce73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff22b5a3ba8>"
      ]
     },
     "execution_count": 134,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFOCAYAAACxAKU1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnT4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff22b660b38>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "forex_df_norm[0:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WictL5-USh0g"
   },
   "outputs": [],
   "source": [
    "seq_len = 22\n",
    "d = 0.2\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [128, 128, 32, 1]\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AszyLTy0GILu"
   },
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g0MKS02MGNNc"
   },
   "source": [
    "**Converting  into arrays for  input to the neural network****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nj9LEnlwlJY6"
   },
   "outputs": [],
   "source": [
    "def load_data(forex, seq_len):\n",
    "    amount_of_features = len(forex.columns)\n",
    "    data = forex.as_matrix() \n",
    "    sequence_length = seq_len + 1 # index starting from 0\n",
    "    result = []\n",
    "    \n",
    "    for index in range(len(data) - sequence_length): # maxmimum date = lastmost date - sequence length\n",
    "        result.append(data[index: index + sequence_length]) # index : index + 22days\n",
    "    \n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0]) # 90% split\n",
    "    m\n",
    "    train = result[:int(row), :] # 90% date\n",
    "    X_train = train[:, :-1] # all data until day \n",
    "    y_train = train[:, -1][:,-1] # day m + 1 for DEXINUS\n",
    "\n",
    "    \n",
    "    X_test = result[int(row):, :-1] # all data until day\n",
    "    y_test = result[int(row):, -1][:,-1] # day m + 1 for DEXINUS\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features))#\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features))  \n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iVDupf1Rve4I"
   },
   "source": [
    "**We are incorporating 4 features(forex makets to predict India's FOREX)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tRK06ZWAlXRf"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_data(forex_df_norm , seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "_3P_UCDWw4UL",
    "outputId": "afe7fadc-833b-4dc5-c1e1-a19ede13737f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "22\n",
      "4\n",
      "55\n",
      "22\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0])#expected number of observations to read each batch\n",
    "print(X_train.shape[1])# number of time steps\n",
    "print(X_train.shape[2])#number of features.\n",
    "print(X_test.shape[0])#expected number of observations to read each batch\n",
    "print(X_test.shape[1])# number of time steps\n",
    "print(X_test.shape[2])#number of features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yqO10LTkl-Gl"
   },
   "source": [
    "**MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QtEZrR-ul7in"
   },
   "outputs": [],
   "source": [
    "  def build_model2(layers, neurons, d):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(neurons[0], input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(LSTM(neurons[1], input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(neurons[2],kernel_initializer=\"uniform\",activation='relu'))        \n",
    "    model.add(Dense(neurons[3],kernel_initializer=\"uniform\",activation='linear'))\n",
    "    # model = load_model('my_LSTM_stock_model1000.h5')\n",
    "    # adam = keras.optimizers.Adam(decay=0.2)\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "DbKunRdcg5gz",
    "outputId": "cff46d9c-255d-4ebb-dd22-ef48de1f1bc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model2(shape, neurons, d)\n",
    "# layers = [4, 22, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3518
    },
    "colab_type": "code",
    "id": "fqLUmM2pTzxy",
    "outputId": "9b437961-d277-46e3-c2dd-e38dc8406cfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 449 samples, validate on 50 samples\n",
      "Epoch 1/100\n",
      "449/449 [==============================] - 4s 10ms/step - loss: 0.0459 - acc: 0.0022 - val_loss: 0.0603 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0162 - acc: 0.0022 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0048 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0029 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0029 - acc: 0.0022 - val_loss: 0.0064 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0031 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0028 - acc: 0.0022 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0027 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0063 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.8647e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.4773e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.5612e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.6706e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.7980e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.7366e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.8942e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.0000e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.4613e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3006e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.6743e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.0582e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.8145e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.0680e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.3928e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.2801e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.8874e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.0699e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.9935e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.5352e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.2084e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.4442e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.3719e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.7762e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.2297e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.6504e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.7998e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.5694e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.9381e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.4070e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.2535e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.7327e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.2573e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.0762e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.6013e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.3925e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.1997e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.0340e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.6247e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.6010e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.8050e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.2026e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.0039e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff22c5616a0>"
      ]
     },
     "execution_count": 141,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=24,\n",
    "    epochs=100,\n",
    "    validation_split=0.1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVJLeQiHCvTj"
   },
   "outputs": [],
   "source": [
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "tHK9wkdHCvZK",
    "outputId": "bae0d0a6-9997-4283-dce1-a97d802cdbf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00060 MSE (0.02 RMSE)\n",
      "Test Score: 0.00469 MSE (0.07 RMSE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0006004237571734943, 0.004689315875822848)"
      ]
     },
     "execution_count": 143,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score(model, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VyyBM-oziiYY"
   },
   "outputs": [],
   "source": [
    "def denormalize(forex_df_norm, normalized_value): \n",
    "    forex_df_norm = forex_df_norm['DEXINUS'].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "    \n",
    "    #return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    a = min_max_scaler.fit_transform(forex_df_norm)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "    return new\n",
    "\n",
    "newp = denormalize(forex_df_norm, p)\n",
    "newy_test = denormalize(forex_df_norm, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rRJRR23BjPH7"
   },
   "source": [
    "**Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8Q80sK3jN4R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "colab_type": "code",
    "id": "hoU8qwX6iidX",
    "outputId": "a6a34d3a-8580-4ad9-89ca-231723c15509"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3XmczdX/wPHX5+5zZ2OYQaQSLbaK\nbAllC0Wy1FCWkCJtaLMkQgjJV4tQhBgxFZEtIkuRyK6QpZ8wg5kxc+fun98ftxkjY+bOzF1meT8f\nD49M997P5z1nxn3fc877nKOoqqoihBBCiIDTBDsAIYQQoqSSJCyEEEIEiSRhIYQQIkgkCQshhBBB\nIklYCCGECBJJwkIIIUSQ6AJ9w4SEyz69XunSZi5dsvj0msWZtJf3pK28J23lPWkr7xWntoqODs/2\n/xf5nrBOpw12CEWKtJf3pK28J23lPWkr75WEtirySVgIIYQoqiQJCyGEEEEiSVgIIYQIEknCQggh\nRJBIEhZCCCGCRJKwEEIIESSShIUQQoggkST8r3/+OUOrVk0ZNKg/gwb1p3//3mzatDHP11m2LI45\nc2by559HmDNn5nWft2XLJhwOBxcuJDJp0riChC6EEKKI8mrHrD/++IOBAwfSu3dvnnrqqase27Zt\nG1OnTkWr1dK0aVOef/55vwQaCJUr38SMGZ8CkJKSzNNPP0nDho0wGk15vla1ardTrdrt13188eKF\n1KlTjzJlyvLaa8PzHbMQQoiiK9ckbLFYeOedd2jUqFG2j48dO5Y5c+ZQrlw5nnrqKR566CGqVq3q\n80ADLSIikjJlyvLee++i1xtISUlizJgJTJo0jjNn/g+n00m/fs9Rt249fv11B9OnTyEqqgxlypTl\nhhsq8ttvvxIfv4SxYyexevVKli6NQ1EUYmOfxOFwcPDgfoYOfZE33hjJ6NEjmDNnPr/99iuffvoR\nOp2O6OgY3nzzLdavX8PevXtISrrEqVMn6d69B4880jHYzSOEEMIHck3CBoOBWbNmMWvWrGseO336\nNJGRkVSoUAGAZs2asX379gIl4dC3R2Bc8Y33L9AoRLnVHJ9ia9+RtLfH5imOf/45Q0pKMm63m4iI\nCF5/fTirV6+kTJmyvPnmWyQlJfHSS88xb95iZs6cwciR71Ct2m0MHfoiN9xQMfM6Fksac+fOZt68\nRdjtDsaNG8WECVOZPfsTJk+eTnJyUuZzJ09+l/ff/5By5cozdepE1q1bjaIoHDt2lE8++Yy//z7N\nqFHDJAkLIYSfnDunsG2blo4dnSiK/++XaxLW6XTodNk/LSEhgaioqMyvo6KiOH36dI7XK13anPN+\noGYDaPL2nWtzeb7ZbMB8nc2zM9hsoZw+fZLBgweiqipGo5HJk98jLi6Ohg3vJTo6nKNHD7Fr1y4O\nH94PgNPpIDLSyLlzZ7nvvroANG7cCJvNRqlSZoxGPcnJ56lWrSqVKkUDMGeO58OMVquhbNkwtFoH\nOp0Gvd6FTqelZs1qADzwQBN27txJ9erVqVevLuXLlyI8XE96etp1NwL3VkFfX5JIW3lP2sp70lbe\nC2RbqSp06gRbtkCHDlC+vP/vGfBTlHI9EeO1tzx/vBQdHe7dyUy5POfixTRuvPEmpk796Kr/b7U6\nsFicJCRcxumE7t170apVm8zHk5NtgJIZQ2qqFbvdTlKSBZvNQXKyFavVfk2MLpebxMRUkpPTcDrd\nXLiQhtPpynzehQspWK1OLl+2Yre7SUi4jMViweVyF+gkKq/bS0hb5YG0lfekrbwX6LZaulTHli0h\ntGvnQKu1kpDgu2v75RSlmJgYEhMTM78+d+4cMTExBblkoVa9ek22bNkEwKVLF5k580MAypaN5tSp\nE6iqyu7du656zU033cypUyexWCzYbDZeftnT01YUDS6XK/N5ERERKIrC2bNnAdiz5zfuuOPOAH1n\nQghRsqWmwujRRkwmlTFjbAG7b4F6wpUqVSI1NZW///6b8uXLs3HjRiZPnuyr2Aqd5s1b8ttvO3nu\nuT64XC769OkPQP/+Axkx4nXKl69ATEy5q14TEhJC377P8fLLAwF44onuKIrCPffUYeDAvgwf/nbm\nc197bQSjRw9Hq9VSsWIlWrRozdq13wfs+xNCiJJqyhQj585pGDrURuXKOdcZ+ZKiqmqOd9u/fz8T\nJ07k//7v/9DpdJQrV47mzZtTqVIlWrVqxc6dOzMTb+vWrenbt2+ON/T10IIM7eSNtJf3pK28J23l\nPWkr7wWqrY4eVWjWLJTy5VW2bEkjJMT397jecHSuPeGaNWsyf/786z5er1494uLi8h+ZEEIIESSq\nCsOHm3A4FMaMsfolAedEdswSQghRYq1erWPjRh3Nmjlp184Z8PtLEhZCCFEipafDyJFGdDqV8eNt\nAVkX/F+ShIUQQpRIH35o4NQpDf37O6hWzR2UGCQJCyGEKHFOnVKYPt1ATIybIUMCtyTpvwK+WYcQ\nQggRbKNGGbFaFSZPthIexA3MpCecxbp1q2nWrAFJSUnXfc7Ro39y6tTJPF+7S5f2WCy57BYmhBDC\n7zZt0rJypZ569Vx07Rr4YqysJAlnsW7dGipWrMSPP66/7nM2bdrA6dOnAhiVEEIIX7HbYfhwI4qi\nMmGCNSjFWFlJEv5XSkoyhw4dYNCgV1i/fi0Af/xxmGeffZoBA/rw4YcfcOzYUb79Np6ZM2dw8OD+\nq3q3M2ZMY9WqFaSlpfLaay/zwgvP8swzvTh4cH8wvy0hhBBZvP++gT/+0NKrl4NatYJTjJVVoZsT\nfvttIytWeB+WRgNud2iOz2nf3snbb+c88b5hw3ruu+9+GjRoxMSJY0lIOM+0aZN59dVhVK1ajXfe\neYvQ0FAaNGjEAw+0oHr1mtle58KFCzzySEeaNn2AXbt2snDhPMaNe8/r70cIIYR/7Nun4YMPDFSs\n6GbkyOAVY2VV6JJwsKxfv4Zevfqi1Wp58MEW/PDDWk6dOknVqp6jBUeOHOPVdaKiyjBv3mwWLZqP\nw+HAZDL5M2whhBBecDjgpZdMOJ0KU6akB7UYK6tCl4TfftuWa681K8/eomkFuuf58+c4eHA/M2ZM\nQ1EUrFYr4eFhaDQ5j9YrWSYTnE7P5P6SJV9StmwMI0e+w+HDB5kxY1qBYhNCCFFw//ufgf37tXTr\n5qB5c1fuLwgQmRPG0wt+7LGuzJu3iLlzv2TRomWkpKRw0003c+CAZ0733XfHcOLEXyiKknkEodkc\nyoULibhcLg4c2AdAcnISFStWAmDTpo2ZyVkIIURwHDyoYcoUA+XLuxkzxhrscK5S6HrCwbB+/RpG\njBid+bWiKLRt+whut5sZM94HoEaNWtx88y3cddc9TJv2Hmazmc6dH+f111+hcuWbuOWWKgC0afMw\nY8eOYuPG9XTu/Djr169l5crlQfm+hBCipHM6PcPQDofC5MnpREYGO6Kr5XqUoa/JUYbBJe3lPWkr\n70lbeU/aynu+aKvp0w2MHWukSxcHH30UvF7w9Y4ylOFoIYQQxdIff2iYNMlAdLSbceMK1zB0BknC\nQgghih2XyzMMbbcrTJpko3TpYEeUPUnCQgghip2ZM/Xs2qWlY0cHDz9ceAtkJQkLIYQoVo4dU5gw\nwUjZsm7Gjy8cm3Jcj1RHCyGEKFY++siA1aowfbqVsmUDWnucZ9ITFkIIUazs3q3FZFJ55JHCOwyd\nQZKwEEKIYsNmg8OHNVSv7kZXBMZ6JQkLIYQoNo4c0eB0KtSqVXi2psyJJGEhhBDFxt69WoBCcUyh\nNyQJCyGEKDb27fOktdq1pScshBBCBNTevVq0WpU77pCesBBCCBEwLpfnxKTbb3dTVI5ylyQshBCi\nWDh6VEN6ukLt2kWjFwyShIUQQhQTGfPBRaUyGiQJCyGEKCaKWmU0SBIWQghRTOzfr0FRVGrWlJ6w\nEEIIETCq6ukJV6miEhYW7Gi8J0lYCCFEkXfypEJKStHZKSuDJGEhhBBF3r59RW8+GCQJCyGEKAaK\n2k5ZGSQJCyGEKPKu9IQlCQshhBABtXevhkqV3ERFBTuSvJEkLIQQokg7d04hIUFTpJYmZZAkLIQQ\nokjbuzdjPrhoFWWBJGEhhBBFXFGdDwZJwkIIIYo46QkLIYQQQbJ/v5ayZd2UL68GO5Q8kyQshBCi\nyLp0CU6d0lCrlhtFCXY0eSdJWAghRJG1f79nPriobdKRQZKwEEKIIitjPriobVeZQZKwEEKIIqso\nV0aDJGEhhBBF2L59GsLDVW66qegVZYEkYSGEEEVUaiocPaqhVi0XmiKazYpo2EIIIUq6gwc1qKpS\nZOeDwcskPH78eJ544gliY2PZu3fvVY+tX7+ezp07061bNxYsWOCXIIUQQoj/KurzweBFEt6xYwcn\nT54kLi6OcePGMW7cuMzH3G4377zzDrNmzWLhwoVs3LiRs2fP+jVgIYQQArKeIVyMe8Lbt2+nZcuW\nANx6660kJyeTmpoKwKVLl4iIiCAqKgqNRkPDhg3Ztm2bfyMWQgghgL17tZhMKlWrFuMknJiYSOnS\npTO/joqKIiEhIfPvaWlpnDhxAofDwS+//EJiYqL/ohVCCCEAmw2OHNFQo4YbnS7Y0eRfnkNX1Stl\n4IqiMGHCBIYNG0Z4eDiVKlXK9fWlS5vR6bR5vW2OoqPDfXq94k7ay3vSVt6TtvKetJX3rtdWv/0G\nDgfUq6ct0u2ZaxKOiYm5qnd7/vx5oqOjM7+uX78+X375JQBTpkyhYsWKOV7v0iVLfmPNVnR0OAkJ\nl316zeJM2st70lbek7bynrSV93Jqq82b9YCJatWsJCQ4AhtYPlzvg0Kuw9GNGzdmzZo1ABw4cICY\nmBjCwsIyH+/Xrx8XLlzAYrGwceNGGjVq5KOQhRBCiOxd2a6y6FZGgxc94Tp16lCjRg1iY2NRFIVR\no0YRHx9PeHg4rVq14vHHH6dPnz4oikL//v2JiooKRNxCCCFKsL17teh0KnfcUXSLsgAUNeskbwD4\nehhGhnbyRtrLe9JW3pO28p60lfeu11YuF1SpEkaVKm42bvTtFKe/5Hs4WgghhChMtm7Vkp6uUKdO\n0R6KBknCQgghiphZswwAdO9e+AuyciNJWAghRJHx118Ka9dqqVvXRd26RXs+GCQJCyGEKEI++8yA\nqir062cPdig+IUlYCCFEkZCaCl9+qadcOTft2zuDHY5PSBIWQghRJMTF6bl8WaF3bwcGQ7Cj8Q1J\nwkIIIQo9txtmzzZgMKj07Fn0C7IySBIWQghR6G3cqOXYMQ2PPeYkOjqg21v4lSRhIYQQhV7GsqRn\nnikeBVkZJAkLIYQo1P78U8OGDToaNHBSu3bRX5aUlSRhIYQQhdqcOXoA+vcvPnPBGSQJCyGEKLSS\nk2HxYj0VK7pp27Z4LEvKSpKwEEKIQmvRIj0Wi8LTTzvQ5XruX9EjSVgIIUSh5HJ5liWFhKg89VTx\nKsjKIElYCCFEobRyJZw6paFLFwfF9ah6ScJCCCEKpQ8+8Py3b9/iV5CVQZKwEEKIQufQIQ0bNkCT\nJk6qVy9ey5KykiQshBCi0Pn4Y8/mHP36Fd9eMEgSFkIIUcgcOaJhyRIdNWpA69bFb1lSVpKEhRBC\nFCrjxxtwuxXGjwetNtjR+JckYSGEEIXGzp0avv9eT/36Ttq3D3Y0/idJWAghRKGgqjB2rBGAESPs\nKEqQAwoAScJCCCEKhR9+0LJ9u47WrZ00bOgKdjgBIUlYCCFE0Lndnl6woqgMG2YLWhym2Z9QpnoV\nlKRLAbmfJGEhhBBBt2yZjoMHtXTtGsR1wW435o9nQLoVVW8IyC0lCQshhAgqmw0mTjRiMKi8/nrw\nesH6rT+hPX0K26OPQWhoQO4pSVgIIURQffGFnlOnNDz9tIMbb1SDFodp0QIAbLFPBuyekoSFEEIE\nTWoqvP++gbAwlZdeCt5JSUpKMsaVy3HeUgVHg0YBu68kYSGEEEHz8ccGEhM1DBxop2zZ4PWCjcu/\nQUlP9/SCA7g2SpKwEEKIoEhIUPjoIwNly7p57rngnhdsWrQAVVGwPt4toPeVJCyEECIopk0zkJam\nMGSInbCw4MWhPfon+p2/4Gj6AO6KlQJ6b0nCQgghAi4hQWHuXD033eSmR4/gnpRkWrwQAGu3pwJ+\nb0nCQgghAm7zZi0Oh0LPng4MgVmSmz2XC+OSRbgjIrG1fSTgt5ckLIQQIuC2bvUcj9SkSXCPKtRv\n2oD27D/YHusCISEBv78kYSGEEAG3ZYuOiAiVWrWCtDvWv0yLMoaiA7c2OCtJwkIIIQLq778VTpzQ\ncN99zqCeF6xcuojx++9w3nY7znvqBiUGScJCCCECassWT+Zt3Di4JyUZv16GYrdjjX0qoGuDs5Ik\nLIQQIqC2btUBwU/CpsULULVarF1jgxaDJGEhhBABo6qeoqyoKHfwTksCtIcOot+zG3uLVqjlygUt\nDknCQgghAubECYW//9Zw330uNEHMQBmHNVifCE5BVgZJwkIIIQKmUAxFOxyYlsbhjorC/lDb4MWB\nJGEhhBABlFGU1aRJ8JKw4Yd1aBITsHZ+nODuFCJJWAghRICoqicJx8S4qVYtePPBmUPRsYHfpvK/\nJAkLIYQIiKNHNZw/r6FxY1ewVgShXLyAYd1qnDVq4apVOzhBZCFJWAghREBkDEXff38Qh6LXfI/i\ndGJ9rEvQYshKkrAQQoiAuLJJR/D2izauXA6A7ZEOQYshK0nCQggh/M7thm3btNxwg5tbblGDEoNy\nOQXDjxtwVq+Ju8qtQYnhvyQJCyGE8LvDhzVcuBDc+WDD+rUodju2h9sHJ4Bs6Lx50vjx4/n9999R\nFIVhw4ZRu/aVyeyFCxeyfPlyNBoNNWvWZPjw4X4LVgghRNFUGI4uNKxcAYDt4cIxFA1e9IR37NjB\nyZMniYuLY9y4cYwbNy7zsdTUVObMmcPChQtZtGgRx44dY8+ePX4NWAghRNHz009BPrQhPR3j+rU4\nq9yK687qwYkhG7km4e3bt9OyZUsAbr31VpKTk0lNTQVAr9ej1+uxWCw4nU7S09OJjIz0b8RCCCGK\nFJcLtm/XUbmymxtvDM58sOHHDSiWNOwPdwjaiUnZyTUJJyYmUrp06cyvo6KiSEhIAMBoNPL888/T\nsmVLHnzwQe666y5uueUW/0UrhBCiyDlwQENyshLUoejMquhCNB8MXs4JZ6WqVz7FpKamMnPmTFav\nXk1YWBi9evXi8OHD3HHHHdd9fenSZnQ6357iHB0d7tPrFXfSXt6TtvKetJX3Slpb7d7t+W/btgai\no/O2TaRP2spuh7XfQ6VKlG79QKHqCeeahGNiYkhMTMz8+vz580RHRwNw7NgxbrzxRqKiogC49957\n2b9/f45J+NIlS0Fjvkp0dDgJCZd9es3iTNrLe9JW3pO28s6FCwpGYxhhYSWrrdasCQF01K6dSkKC\n98PRvvq90m/8gVJJSVi6xpKWmFrg6+XH9T5M5Doc3bhxY9asWQPAgQMHiImJISwsDICKFSty7Ngx\nrFYrAPv37+fmm2/2UchCCFF8qCo8/ngIt90GS5bkeRCyyHI4YPt2LVWruihfPjjzwcZ/q6Lthagq\nOkOuvwl16tShRo0axMbGoigKo0aNIj4+nvDwcFq1akXfvn3p2bMnWq2We+65h3vvvTcQcQshRJHy\n889a9u3zTMUNGhTC2bM2XnjBXphGRvPl0CENlSq5Cb/OqPHvv2tIS1OCVxXtcmFctQJ32bI4GjQK\nTgw58Orj2NChQ6/6Outwc2xsLLGxsb6NSgghipnPP9cD8Mkn8M47bsaONXLmjMK4cTa0vi2TCZif\nftLSubOZmBg3Y8faePRR5zUfKjLODw7WftH6nb+gSUwgvUdvCmNDy45ZQgjhZ+fOKXz3nY4773TR\nvz+sWmXhzjtdfPaZgb59TaSnBzvCvHO54K23jCiKSnKyQv/+IXTrFsKJE1dn4Yz9ou+7LzhJ2FBI\nq6IzSBIWQgg/W7BAj9Op8PTTDhQFKlRQWbHCQuPGTlat0tO1awiXLgU7yryJi9Nx4ICWJ55wsmlT\nGs2aOdmwQUfTpqFMn27A4QCbDXbs0HLnnS6io4MwH6yqGFeuwB0RieP+ZoG/vxckCQshhB85nfDF\nF3rCwlS6dHFk/v+ICFi8OJ2OHR3s2KGjfXszp08XjQni1FQYP96I2azy5ps2qlRRWbIknU8+SScs\nTGXsWCMtWpiZPVtPenrw5oN1v+9G+/dp7K3bgCFvS6MCRZKwEEL40erVOv75R8Pjjzv4d2FJJqMR\nPvnEynPP2fnjDy3t2pk5ejSwidhuhxkz9Bw65H06mDHDwPnzGgYOtFOhgqeHqyjQqZOTbdvS6NHD\nzuHDWkaPNgHB26rS+F3GUHThq4rOIElYCCH8KKMg6+mnHdk+rtHAmDE2Ro2ycu6chrFjjYEMj4UL\n9YwZY6Jz5xBOnsz9A8CZMwoff2ygXDk3zz9vv+bxUqVgyhQbK1ZYuOMOF2XLuoNzfrCqYvjuW1Sz\nGfuDLQJ/fy9JEhZCCD/54w8NP/2ko3FjJ7ff7s7xuQMHOrj7bhfff6/j+PHA9IadTvjoIwMajUpi\noobu3UNISsr5NePHG0lPVxg+3EZo6PWf16CBi02bLPz2WxqlSvk2bm9ojxxGd/wY9uatwGwOfABe\nkiQshBB+Mneupxfcp0/2veCsFAUGDLCjqgqffhqY+csVK3ScPKmhRw8Hzz1n588/tfTpE4L92g4u\nAHv2aFiyRE/Nmi4efzz33q2igMnk46C9ZPzuW6DwVkVnkCQshBB+kJoKcXF6ypd306aNd8Ox7ds7\nqVTJzeLFer9XS6sqTJ/u6QUPHGjn7bdttGvnYMsWHYMHm1DVa58/apRnqHz0aBuaQp49jCtXoOr1\n2Fs9FOxQclTIm1EIIQLr6FGF++4z8957Bmy2/F9n2TI9ly8r9OjhQK/37jU6HTzzjB2LRWHePP/2\nhjdu1HLggJYOHZzccouKRgMffWSlTh0XS5bomTLl6vt//72O7dt1tGnjoEmTIO1+5SXNX8fRHdiH\nvdmDqBGF+3hdScJCCJHFL7/oOHpUy3vvGXnggVC2bs37Lkuq6inI0mpVevTIfSg6qyefdBAWpjJ7\ntr5AHwJy87//eZLsCy9cGXs2m+GLL9KpXNnNpElGvvrKs9uV3Q6jRxvR6VTeesuPQfmIccU3QOHc\nK/q/JAkLIUQW5855iqKaNHFy/LjCY4+ZeeEFExcueF8stWOHloMHtbRr58zzoQUREfDUUw7On9fw\n9df+Oejh1181bN2q48EHndSqdXXBWEyMysKF6UREqLz8solt27R8/rmev/7S0Lu3g6pVg3MIg7eU\nxETMM6bhDg3D1vbhYIeTK0nCQgiRRUYSHjPGxpo1FmrXdhEXp6dxYzOLFumumSvNTsayJG8KsrLT\nv78drVbl448NXt0vr7LrBWd1++1uPv88HVWF3r1DmDLFSGSkytChhb8XHDZmJJqkJCxvDEeNKhPs\ncHIlSVgIIbI4e9aThMuVU7n7bjerV1t45x0rVqvCSy+F8NhjIezbp7lucjx/XmHFCh233+7K937J\nlSqpdOjg5NAhLT/+6NtDB/74Q8P33+upU8eV4yYaTZq4mDrVSlKSQlKSwiuv2Pj36PhCS//zNkyL\nF+KoWZv0vs8GOxyvSBIWQogszp/XoNOpREV5sqxOB88+62Dr1jTatnWwbZuOFi1CufvuUF54wcRX\nX+kye8/g2fzC4VDo3dtRoGMKBwzw9FI//ti3BVoffnilF5xbfLGxTt5910qnTg769s1frz5gHA7C\nXnsFVVFInTTV84MrAopGlEIIESDnzimUK6deswSnYkWVefOsrFvnYOlSPZs3a4mL0xMX5xl6vvNO\nF02buli+XEdoqMrjjxcsad19t5tGjZz8+KOOgwc1VK+e82Yf3jhzRmHpUh1Vq7po29a7ZVN9+xaB\nBAyEfPIhusOHSO/xNM576wc7HK9JEhZCiH+pqmc4uWbN6ye8Vq1ctGrlwu2GAwc0bN6sZdMmHT//\nrOXQIc/Qca9e9usecp8XAwbY2b5dx8yZBj74wFrg633yiQGHQ+GFF+yFfp1vXmhOnyJ0ygTcZcuS\nNmJUsMPJE0nCQgjxr0uXwG5XiInJvdep0UCtWm5q1XLz/PMOrFb49Vcte/dqiI31Tc+xdWsXt97q\nZtkyHcOGeXro+XXpkuc0pwoV3HTuHIS9nP0obPjrKBYLlydMQS1dyCeu/6MYfRYSQoiCOXvW85aY\nn2RnMsH997sYONDhswImjQaefdaO3a7w2Wde7vhxHZ99ZsBiUXjuOXthPdUvXwxrvse4eiX2Ro2x\nPdE92OHkmSRhIYT4V0aBVUF6nL72+OMOoqLczJ1rIC0tf9ewWGD2bD2lSuV985BCLS2NsGGvoup0\npE6cSoEq4YJEhqOFEOJfGUk4rxts+JPZDL172Zn6vomv+28k9tP7uJBqIiFBuerPxYsKTmf2Sejk\nSYULFzQMHmy75kzjoiz0/ffQnj6F5YVXcN1xZ7DDyRdJwkII8a/z5zOGowteiewr2j//4JVNb/Eh\ny3h1XTuG3KJBzccgZliYSr9+xacXrD1ymJCPpuO6sTJpg18Ldjj5JklYCCH+VaiGox0OzDOmYZ4y\nkSi7nWG3L2XRmQcod/ko0YYkSjevTZm7KxIdrVK2rEqZMu4c53orVPA8r1hQVcJeH4zidJI6/j1y\nPNi4kJMkLIQQ/8q6W1Yw6XbvIvzlQegOHcBVrjypE6Yw4OH2DFBVTPP2EDb8NVjjxHLPCCxPDqFY\nrTfygmHlCgzbtmBr0w77Q22DHU6BlKyfnBBC5ODcOQWNJog9xrQ0Qt8aRqm2LdAdOkB6j95c2rID\ne8bB9IqCtXdfkpavxl3hBkLffYeInrEoSX4+fLgwcToJHT8aVaslbdQ7wY6mwCQJCyHEv86d0xAd\nraL17XbNXtGcOknUA40wfzID1003kxT/HalTpqNGlrrmuc669bi0/ifsTR/EuHY1pVs1Q7tvb+CD\nDgLT4oXojv6JtXtPXLdWC3Y4BSZJWAghuLJbVlCGoq1WIvr0QHvyBJbnBnHpx+047m+a40vUsmVJ\njosn7ZWhaE+eoPTDLTF8vzJLsh0FAAAgAElEQVRAAQdJejrm995FDQnB8uobwY7GJyQJCyEEkJIC\n6enBScJhw19Dv3cP6U/2JG3MeAgJ8e6FWi2WN98ieX4caLRE9O+NftsW/wYbRCGzZ6L95wzpzwzA\nXb5CsMPxCUnCQgiBZygaAr88ybhoASHz5+KofTep707O1zXsD7Ul+fMF4HIR0bMb2oMHfBxl8ClJ\nlzBPn4q7VCksL7wc7HB8RpKwEEIQnOVJun2/E/76YNyRpUiZ84Vn78t8cjzYgsvTP0aTkkxkbCc0\np0/5MNLgM/9vGprkJCwvDsl2nryokiQshBAEPgkrSZeIeLoHitXK5Y8+xX3TzQW+pq3LE6SOHo/2\n7D9EPvEYyoULBQ+0END8c4aQWR/juqEi6X37Bzscn5IkLIQQBDgJu92ED3oW7akTpA1+FXurNj67\ndPqAQViefwnd0T+JfKor+d5wuhAxT56AYrViefVN7+fLiwhJwkIIQdYTlPw/J2yePhXj2tXYmz2I\n5dVhPr9+2sjRWLvGot/1KxH9eoKj6G5XqT36J6Yv5+OsdhvWInhKUm4kCQshBJ7lSRCAnvD69Zgn\njMVVsRIpn3yGXxYlazRcnvYh9uYtMf6wjvDBL3jWYBVBoePHoLhcpA0bBbrit8mjJGEhhODKcHRM\njP+Sleb//oZu3UCrJWX2PNQyZfx2L/R6kmd/gaNOXUxxXxI6emTRS8Q7dmD87lscdethb/dIsKPx\nC0nCQgiBZ4lS2bJu9Ho/3UBVCX9xACQmkvrOBJx16/npRlmEhZG8cCnOW6ti/mg6ET2eQLlYRIq1\nVBXe8GzIkTZydJE8K9gbkoSFEAJPT9ifvWD95h8x/LQJ2rTB+nQ/v93nv9QyZUj6dvWVLS6b34/u\n5+0Bu39+6Tf+ABs3YmvRCsd99wc7HL+RJCyEKPFSUyE11Y+7ZakqoRP+PWxg3LiA9+rUmBiSl3xN\n2psj0Zz9h1KPtSPkgyngLjznJmelPfYnEYP6g0ZD2vC3gx2OX0kSFkKUeBlFWeXL+ycJG9atRr/r\nV2wPd4A6dfxyj1xpNFheeZXkb1bhjilH2LjRnrXE588HJ57r0PxzhsjHH0OTmAgffoirZq1gh+RX\nxa/UTAgh8sivW1a63ZgnjENVFNJeG4bR93fIE0fD+7i0YSvhLzyLcf1aSjdvzOWPZ+No0AjN//2N\n9vQptKdPoTl9Eu0pz99Vg4H0Xn2wt2vv1wpl5dJFIh/viPb0KdLeHEnoc89BwmW/3a8wkCQshCjx\n/LlRh2HlcvT792Lt1BXXndV9fv38UMuUIWXBEkI+nkHouLcp1bk9qqKgZFM9rWo0oKoYftqEq/LN\nWJ4biDX2KQgL821QqalEdu+C7shhLM8OxPLyUEJ9e4dCSZKwEKLE89vyJJeL0InjULXawnf0nkZD\n+vMv4mjQkNAxb4FGg/vGyrhurIyr8k2Zf3dXuAHtqROEfPIRpriFhA97jdBJ40nv3Y/0vs+ilitX\n8FhsNiL7PIV+169YH+9G2ujxxbYa+r8kCQshSjx/7ZZl/Hopuj+OkN69R6E9gN55b32Sl6/O8Tmu\nW6uR+t77pL0+nJDPPiXk81mETpuM+aPpWLs8gbXn0zjvqZu/xOlyET7oWQw/bsD2UFsuvz8DNCWn\nXKnkfKdCCHEdGT1hnxZmORyeA+j1eiyDX/PddYNILVsWy2vDuLDrAJcnvY+rYiVCvpxP6TbNiap3\nF6Fj30a7b6/3m4KoKmGvD8H0bTz2hveR8ulc/LdQu3CSnrAQosTzx3C0ackidH8dJ/3pfrgr3+Sz\n6xYKZjPW3n2x9uiNYcM6jPFLMaxehXn6VMzTp+K8tSq2jp2xdeyM6/Y7PK9xOFCSk9GkJKEkJaEk\nJ2NYv4aQLz7DUbM2KQviit3hDN6QJCyEKPHOn1coVUotyHG+V7PZME+ZiGoyYXnlVR9dtBDSarG3\nauM5BSo9HcP6tRi/jce4bjWhUyYSOmUi7rLRKBYLiiX705yct1QheXE8akRkgIMvHCQJCyFKvHPn\nND6dDzYtmIf279NYnhuEu3wFn123UAsJwd7+UeztH+VyairGdasxfr0M3aEDuCrcgFqqFGpEJO5/\n/6uWKoW7VGlsjzyKGh0d7OiDRpKwEKJES0+HpCSFWrV8NBRtsWB+/z1UcyiWF17xzTWLmrAwbI91\nwfZYl2BHUuhJYZYQokTz9W5ZIXPnoD1/Dkv/ASW6hye8I0lYCFGiXdmoo+DD0UrqZcz/m4o7IpL0\ngS8U+Hqi+PNqOHr8+PH8/vvvKIrCsGHDqF27NgDnzp1j6NChmc87ffo0Q4YMoX379v6JVgghfOzK\nlpUF7wkb45eiuXCBtFffRC1VusDXE8Vfrkl4x44dnDx5kri4OI4dO8awYcOIi4sDoFy5csyfPx8A\np9NJjx49aN68uX8jFkIIH8oYjvZJEl62BFVRsD7Zs8DXEiVDrsPR27dvp2XLlgDceuutJCcnk5qa\nes3zvv76ax566CFCQ0vCbp9CiOLi7FnfzAlr/j6NYftWHI0a476hoi9CEyVArj3hxMREatSokfl1\nVFQUCQkJhP1n8+6vvvqKzz77LNcbli5tRqfT5iPU64uODvfp9Yo7aS/vSVt5r6i2VXKy57933mmm\nQHVUn38HgKF3z1zboqi2VTAU97bK8xIlNZvtyHbv3k2VKlWuSczZuXTJktdb5ig6OpyEYn7UlS9J\ne3lP2sp7RbmtTp4MAXTodJdJSMj/dUrPm49Wr+dCs9aoObRFUW6rQCtObXW9DxO5DkfHxMSQmJiY\n+fX58+eJ/s/HxR9//JFGjRoVMEQhhAi8c+cUwsJUCjKTpj10EN3B/dhbtEYtHeW74ESxl2sSbty4\nMWvWrAHgwIEDxMTEXNPj3bdvH3fccYd/IhRCCD86f14pcFGWKf4rAKxdHvdFSKIEyXU4uk6dOtSo\nUYPY2FgURWHUqFHEx8cTHh5Oq1atAEhISKBMmTJ+D1YIIXzJbofERA233+7M/0XcbozxX+EOC/fs\noSxEHng1J5x1LTBwTa93xYoVvotICCECJCGh4MuTdDt3oD19CusT3UvkKUCiYGTHLCFEieWLIwxN\nyzz7Jlg7dfVJTKJkkSQshCixruyWlc8tKx0OjMu/xh0dg6NJMx9GJkoKScJCiBLryr7R+esJG378\nAc3Fi1g7dgKdHEon8k6SsBCixCroblnGZUsAsHWWqmiRP5KEhRAlVoH2jU5Nxbh6Fc5bquC8p66P\nIxMlhSRhIUSJVZA5YePqlSgWC7ZOXUFRfB2aKCEkCQshSqxz5xRCQlTC87E9sQxFC1+QJCyEKLHO\nnfPslpXXjqySmIjhxw047roHV9VqfolNlAyShIUQJZLL5dmsI19D0d/Go7hc2DrL2mBRMJKEhRAl\nUmKigtudv32jTcuWoCoKto6d/RCZKEkkCQshSqT8rhHWnPgL/a87cNzfDHf5Cv4ITZQgkoSFECVS\nfpOw6eulgJyYJHxDkrAQokQ6ezZ/y5MM3y1HNRiwP9zeH2GJEkaSsBCiRMpPT1i5nILuwD4cde5F\njYj0V2iiBJEkLIQokfKThHW/7UJxu3HWa+CvsEQJI0lYCFEiXUnC3g9H63f+AoCjfkO/xCRKHknC\nQogS6fx5DQaDSunS3r8mMwnfW99PUYmSRs7eEiIbR45o0OuDHYXwp7Nn87hbltuN7tedOG+tilqm\njF9jEyWH9ISF+I+zZxVatDDTo0ewIxH+4nZ7TlCKifF+Plh7+BCayykyHyx8SpKwEP+xfr0Ou13h\nu+/gr7/kdJzi6OJFBaczb1tWZg5FSxIWPiRJWIj/+OEHbebf5841BDES4S/5qYyWJCz8QZKwEFnY\n7bBpk47Kld3ExMCiRXrS04MdlfC1jCRcvnwelift/AV3RCSu2273V1iiBJIkLEQWO3ZoSU1VaN3a\nSb9+kJSk8M03vqtf3LNHw5QpBqxWn11S5ENelycpCQno/jqO8956oJG3TeE78tskRBY//OBJuC1b\nOnn2WdBoVD7/3DdD0qtXa3n0UTMTJxr57DMpvQ6mc+cytqz0ries/3UHIOuDhe9JEhYiix9+0GIy\nqTRq5KJyZWjd2smePVp++61g/1TmzdPTu3cIigKhoSozZhhITfVR0CLPMnrC3lZH63f8DMh8sPA9\nScIlyPHjCjZbsKMovP7+W+HwYS333+8iJMTz//r0cQDkuzesqjBhgoFXXzVRurRKfLyFAQPsJCZq\n+OwzKfoKlrwWZul3/oKq0eC4p64/wxIlkCThEuLnn7U0ahRKw4Zw+rQsu8lOxlB0ixbOzP/XtKmL\nKlXcfPONjosX83Y9hwNeftnE1KlGbrrJzcqVFurUcfPcc3ZKlVL58EMDly/78jsQ3jp7VoNWq1K2\nrBdJ2GZD9/tunDVqQViY/4MTJYok4RJi0SI9qqqwZw+0bm1myxZt7i8qYTKWJmVNwhoN9O5tx2ZT\n+PJL7+dxU1OhZ88QFi3Sc/fdLlautFCliucNPyICBg60c+mSwqefSm840Nav17Jrl4bbbnN7VWOl\n2/c7is2Gs55sVSl8T5JwCWCxwIoVOipVcvPRR5CSotC1awgzZ+pR83aeebFls8HmzTqqVnVx881X\nN0psrIOQEJW5cw24vSimTUhQ6NTJzA8/6GjRwkl8vOWaucd+/exERbn5+GMDSUm+/E5ETo4fV3ju\nuRAMBvjgA+9K1PU7/y3Kkvlg4QeShEuANWt0pKYqdO7sYMAAiI9PJypKZeRIE4MGmWQdLLB9uxaL\nRaFFC9c1j5UqBZ06OTh1SsOGDTmPIBw/rvDww2b27NHSrZuDL75Iz3YEMywMBg2yk5Ki8Mkn0hsO\nhNRU6NUrhJQUhcmTrdx9t3fLk2STDuFPkoRLgKVLPcOoXbt6hlkbNHCxfr2FunVdfPWVng4dzPz9\nd8meJ85uPjirp5/OvUDrt980PPywmRMnNAwebGPaNGuOh0D06eMgOtrNzJmGPM83FxfLl+tYtcr/\n58i43TBokIkjR7T072/niSey/zlfQ1XR7fgZV7nyuG+s7N8gRYkkSTjADh7U0KxZ4OZkExIUNmzQ\nctddLm677con/woVVL75xkL37nZ+/11L69Zmtm0rufPEP/ygxWz2LE3KTu3aburWdbF+vZaTJ6/9\nwLJunZZOncxcuqTw3ntW3njDnuvpPGYzvPiinbQ0hQ8/LHm94YQEhQEDTPTvb+LECf9+CJw2zcCq\nVXoaN3YyapT3SwQ0p06iPX8OZ/2GeH/ckhDekyQcQC4XDB5s4tAhLXPmBGazhm++0eFyKXTt6rjm\nMaMR3n/fxoQJVpKSFB5/PIRdu0rer8SJEwpHj2pp2tSJ0Xj95z39tB1VVZg37+qf3cKFenr2DEFV\nYe7cdHr1uratr6dnTwfly7uZM8dAQkLJepOPi9PhcCjY7Qpjx+bQ8AW0dq2WiRMNVKrkZtasnEcn\n/uvKULQUZQn/KHnvuEE0d66e337z9DY3bNBhseTt9adPKzzwgJm1a73vsS5dqkerVenYMfvhN0Xx\nDIvOn5+O0wlPPx2SuYaypMgYim7ePPtecIYOHZyUKePmyy/1WK2eNcCTJxt45RUTkZEqS5daaNMm\n52v8V0gIvPSSHYtF4X//Kzm9Ybcb5s83YDKp1KrlYvlyPTt2+P7t6OhRhQEDQjAaPR+QvFqSlIXM\nBwt/kyQcIGfPKowbZyQyUqV7dzvp6QobN+ZtLmzhQj0HD2p57TWTVwn86FGF3bu1PPCAK9edgVq0\ncDF8uJ2zZzX07WvCbvc+rq1btUyfXnSrfHObD85gMkH37g4uXtQQH69j6FAjkyYZqVzZzXffWahX\nz/tj8bJ66ikHFSu6mTtXz9mzJeMD0JYtWv76S0OHDk7efddTpfzWWyavqs+9dfmypxDr8mWFqVOt\n1K6d94vrdu5ANRpx1rrLd4EJkYUk4QAZMcJIaqrCyJE2evf2DFeuXOl9ElZViI/3jKOdOaNh5szc\ne01ffZVRkOXd8OigQXY6dnSwY4eOESO8Gx5ctEhHly4hjB1rpH79MP73P0ORqrZOT/ckhDvucHHj\njbn3knr1cqAoKkOHmpg/30CtWp41wFWr5n+tl9EIgwfbsVoVpk8vGb3h+fM9v5s9e9qpX9/No486\n+O03rc8Oy3C74fnnTfz5p5Znn7XTpYuXhVhZKKmX0R3cj/PuOmAoGT8XEXiShANg/Xoty5frqVfP\nxVNPObjrLjeVKrlZu1bndY9z924NJ05oaN3aSdmybqZPN+Q4bOx2e4aiQ0NV2rTx7g1IUeD9961U\nr+5i7lwDCxZcf/JMVWHqVAMvvRRCRAS8+KKn2OWdd4w0bBjKggV6nHl/3wu47du1WK1KrkPRGSpX\nVmnVyoXTqdCsmZNvv7Xk6Uza64mNdVC5spsvvtDzf/9XvHvDCQkKq1bpuOMOV+bowYgRNgwGlbFj\njQX+EJeaCv37m1i9Wk+TJnkrxMpK99suFLdbhqKFX0kS9rO0NHj9dRM6ncrkyVY0Gk+ye/hhJykp\nitdV0hm94J497bz2mqeidtKk638637FDy+nTGh55xInZ7H28oaEwb146pUurvPGGkV9/vfZXxOmE\nV181MmGCkRtvdLNyZRojRtjZuTOVF1+0kZSkMHiwiaZNzaxYoSvUG4KsX3/l1CRvTZli5YMP0lm4\nMPs1wPmh18PQoTbsdoVBg0z8+Wfx/ae5aJEeh0OhZ09HZsHxTTepPPOMg7//1jBrVv57nX/95Vmn\nvXy5noYNncyalY4un51rObRBBELx/ZdeSEyZYuD0aQ0DB9q5884rc1IPP+x50/dmSNrl8lQ5ly6t\n8sADnt707be7WLhQz4ED2f8Iv/rKc11vh6KzuukmlU8/zb5Qy2KBPn1MfPGFgZo1XaxadWUoNjIS\nRoyw88svafTsaeevvzT07RtC27ZmjhwpfL9qqgrr1ukIC1OpX9/7gqpy5VS6dXP6fISySxcnTZs6\n2bpVR5MmZgYPNnLmTPHqFbvdsGCBHpNJveZ38+WXbZQp42batPxVim/YoOWhh0I5dEhL3752li1L\nJyoq/7FKUZYIhML3zliMHDig4eOPDVSu7Gbw4KvHnevVc1G2rJvvv9fhyuX9f+tWLefPa2jf3oHB\nADodvP22Dbdb4e23jdf0NK1W+PZbPRUquGncOG/VuhmaNXMxcqSNc+c09OkTgt0OFy4odO5sZvVq\nPU2bXn8otnx5lcmTbWzZkkaHDp65vmeeyVuxVyAcP65w8qSGpk19n1DzQ6eDr75KZ+7cdKpWdbNg\ngYGGDUMZPdrIpUvBjs43fvpJy4kTGh591Elk5NWPRUbC0KF2UlNzHuX5L1WF6dMNdO8egsUCH3yQ\nzrvv2vK0FOkabje6X3firHIratmyBbiQEDkr0klYSUmG8ePR7d0T7FCu4XbD0KEmXC6FSZOs1wwJ\na7XQtq2TxEQNO3fmPCQdH+/p1XbufGXItHlzFw884GTTJt01WymuW6cjJUWhUycn2gLsvzFwoINO\nnRzs3KnlxRdNPPKImV27tHTp4uDLL9MJD8/59bfeqjJ7tpVevewcPqzl448LQabLIqMqumXL/H1Q\n8QdFgXbtnPz4o4Vp0zzbi374oYH69cOYPt2Q52Vthc0XX1yZVslOz54OqlVzMX++nsOHc397Skvz\nzP+OHWukXDmV5cstdOtW8GIE7ZHDaC6n4JResPCzIp2Edb/vgeHDKd2yKZEd22FYvQqfrnEogC++\n0LNrl5aOHR3XLfrJGJL+7rvrD0lbrfDdd3puuMFNgwZXrqMont6wRqMyapTxqiKoggxFZ6UoMHWq\nlZo1XcTH6zl2TMMLL9iYMcOap57jiBE2oqPdTJli8PvOSHmRMR+c29KkYNDpoHt3J9u3pzFqlBVF\ngbFjjTRoEMq8eXocBfvRBsX58wrff6/jzjtd3Htv9v9O9fqrR3ly8uefGtq1M/Ptt3oaNHCydq3n\nqEhfkKFoEShFOgk7mjSDNWuwP9Acw7YtRPaMpfR9dTF9NsvzETlIzp3z7AAUEaHyzjvXr8y8/34X\nEREqK1dev3jphx88vdqOHZ3XHLtWvbqbJ5908Mcf2swlHxcvel5To4aL6tUL/oZkNns2Obj/ficT\nJ1oZOdLu1fFvWUVGwtixNqxWhddfNxWKQq20NNi2TUv16i4qVCgEAV1HSAg8/7yDnTtTeeklGykp\nCq++aqJp01CWLy/cRW//tXixHqfz6oKs7LRs6aJJEycbNlw9ypOSAqtW6XjjDSP33WemcWPP/G/v\n3p75X19UqWeQJCwCpUgnYQBatyZ5yTdc/HE76d17oP37NOFvDKHMPXcSOm40yrlzAQ9pzBgjKSkK\nw4fbcnxjMBjgoYec/N//afj99+x/FF9/nTEUnX3X57XX7ISGqkyaZCAlxTMX7HBkv01lflWurBIf\nn555iEF+dOzo5MEHnWzcqPPZWtCC2LpVi92u5KkqOpgiI2H4cDs7dqTRq5edEycU+vUL4aGHzGze\nHLw9v1UVhgwx0q+fZ2nQ9Xh2yNITEqLSpUvOv0eKAqNH21AUzyjPhAkG2rY1c9ttYfTuHcJnnxk4\nc0ZDq1ae6udJk2w+n9PX7fgZd3gErtvv8O2FhfiPop+E/+WqXoPUaR9yYdcB0ga/BhoN5g+mEPVg\nI7T79wUsjqQk+PZbHbff7vJqD+GcqqQvX4a1a3VUq+aiZs3se7Xlyqm89JKdCxc0fDDNwFdLdGg0\nKp06Fa7koigwcaIVk0llxAgjycnBjSdjyVd2RxcWZuXKqbz3no2tW9N49FEHe/Zo6dLFTNeuIdf9\nIOdPO3dqmD/fwJw50LatmePHs+/ibt6s5eTJ7AuyslOzpptu3RwcOaJl6lQje/ZoqFvXzZAhNpYv\nt/DHH6ksXJjOo4/6/vdcSUhA99dxnPfWI8/DPkLkUbH7DVPLlcPyxggu7D5E6ojRaBITKdXpYXS7\ndwXk/itX6rHbFbp2vXb4ODsPPODEbFb57ju9Z2jR7c6c1161SofV6imwymn47tln7VQsZ+eTDzX8\nuktH0zoplC9f+MYpb75ZZcgQOwkJGp9s2L94sY6nngrJc0Lfs0dDfLyemjVdV82zFyVVqqjMmmVl\n3bo0mjXzFOi1ahXKvfde/0+zZma++MK3m6hkrOl9+GE4csSzRCi7M5dzK8jKzttv23jzTRtffGHh\nyJFUVq608Prrdho2dPm1mt0U9yUgQ9EiMIpdEs4UEkL6i6+QMv1jlJQUIrs8iu6Xn/1+24xK5sce\n827o1myG5s2dHDum4Y9DKpGxnShTsxrGxQsze2u5XavUmmW8mzQQh+p5fu/Db6I9eKAA34X/DBhg\n5447XMybZ2Dnzvz/+u3dq2HIEBNr1+oYN877hK6qMGqU5/mjR9uKfEfnrrvcfPVVOkuXWmjUyInL\nxXX/HD+uYehQE02ahPpkE5UzZxS++05H9eouVqyA6dPTsVqhW7cQpk83ZF7/3DmF1as9z6tb1/s6\nhVKl4JVX7LRp4yIiomCxeku/aSOh497GHR2D9alegbmpKNGK+FtQ7myxT3L5kzkoljRKPfEY+i2b\n/Xavs2c9O2DVr+/0ah/iDBlD0mvf2onhxw1oEhOwvvgWmzdCnTtTqVLlOtdKTydsyEtE9H+a7po4\n6t9yjtLmdDqnfkGpTg+j3bfXB9+VbxkM8N57nmK1oUNN+aryTU+HgQNNOBwK5cq5mTdPn+3OXtlZ\ntUrH9u062rRx0KRJ0ewFZ6dpUxfffpvO7t1p1/3z669X5pP79i34fPLnn+txuRSeecZTaBUb62T5\ncgsVKni2n3zmGROpqVcKsnr0yLkgK9g0fx0n4pleoNGQ/PlC3OUrBDskUQIoqpr75+Hx48fz+++/\noygKw4YNo3bt2pmP/fPPPwwePBiHw0H16tUZM2ZMjtdKSLhc8KiziI4O9+qahlXfef6BabUkz12I\no3krn8YB8Mknet56y8SECVb69PE+u6SkwJ13hFLTuYedFdqTvPAr5g/ay8sHn2OqZgjPDnCRNuR1\nsu6RqP3zDyL69UJ36ADOGrVImT2X5HLVsFgUKq+bR9jgF1AjI0leuhxn7bszX+dte2VKS0O/ayf6\nXTtRkpPBbkOxef5gt6FYbSh2G+7ISOzt2mNr+ZBn78tcDBliZP58AyNH2njhhbzt4jFsmJHZsw30\n62enQwcnHTqYqV7dxbp1lhw3aLDboUmTUE6fVti8OS3XQxfy3FZFxPHjChMmGPnmG09jNWvmZORI\nW55OGUpPh3vu8fycd+9Oo3LlK211/rxCv34mfv7Zsxzp8mWFixcV9u5NDViPNq+U1MuUatcS3eFD\nXH5/BtYne/rtXsX198ofilNbRUdnv7FCrt2HHTt2cPLkSeLi4hg3bhzjxo276vEJEybQp08fli5d\nilar5cyZM76J2Mfs7R4hef5iACJ7dsPw/Uqf3yM+3nN2b4cOeZt0i9Ck0kK/md3UYf9b83HVrMXC\n0GdQFJWuFTZj/vADoprUx7ByBagqxrgvKd2qKbpDB0jv3ZdL3/+A69ZqhIVBTIyK9cmeXP7gI5Tk\nZCI7d8jTfLiSkoxh/RpCx7xFqbYtKFvtRkp16UDou+9g/mg65tkzCZk/F9OSRZi+ice4eiWGDesx\nfb2MiGd6U7bGrYT37+2JNYed+EeMsFG2rJvJkw2cPOl992jDBi2zZxu47TbPjl4NG7p48kk7Bw9q\nmTkz5y2SPv9cz19/aejd21GgU4+KuipVVD799Or55JYtQxkzxvuJ1vh4PRcvaujRw0FIyNWPxcSo\nLFuWTt++dg4d0vL33xo6dnQU2gSM203488+iO3wIS79n/ZqAhfivXHvCH3zwATfccANdu3YFoE2b\nNixdupSwsDDcbjdNmzZl06ZNaL3cmilYPeEM+p82EdnjCbDbufzxbGyPdvJJHMePKzRsGEaLFk4W\nLcrbMTBhLw3ky0UG+m5Zj34AABudSURBVDGH0aOttGvnpF69MJo0cbJs/gXMH0zGPOMDFIcD5223\no/vjCO7wCFKnTs8xfuNXiwl/4TnU0DCS4+Jx3lv/2vZKS8Pw81b0m35Ev/UndPv3ovz7K6FqtTjv\nuhtHo/txNGiEOyYG1WgCoxHVYPj37wZUgxHtib8wfrsM4zfx6P46DoA7LBz7Q22xdeyMvUkz/rtt\n2NKlOgYODOHBB50sWJCe6zaDFy4oNGtm5tIlhdWrLdSq5em5XboEjRuHYrF4eriVK1/7K33pEjRo\nEIaqwi+/pHq1p3DAPoWnp6Pb+zv6X3eg2/MbakQEjvoNPW1+0834ewx382Ytr79u4tgxDYsXW3I9\nUUpV4cEHPfuB79qVxg03qNdtq8WLdcybZ2D6dCvVqhWOjXT+yzxxHKFTJmK/vynJcV9TsP0uc1ec\nenf+Vpza6no94VwXbCYmJlKjRo3Mr6OiokhISCAsLIyLFy8SGhrKu+++y4EDB7j33nsZMmSI76L2\nA0eTZiTFfUNkt86EP9sHd2QpHA80L/B1vS2i+i/D8q8JWbSAttUfRHPYUyVtt3vedDt3doDZjOXN\nt7B17UbY64Mx/LQJx133kPLp57hvqZLjtW1dY0GnI3zgM0Q+/hjJi5ZBmwfR7dqJYdNG9Jt/RL/z\nF5R/J2ZVoxFHw/twNLoPR8PGOO6tj7fHBLmq18BSvQaWN0ai2/c7xm/iMX4bj2nZEkzLlqDq9Tjv\nroOjUWPP9es1oHPnSOLiPGuHO3Qw89FH6dxyS/afCVUVhg41cv68hhEjbJkJGKB0aU+R1fPPh/Dm\nmyYWLEi/Jm9NmWIkKUnh7betBdrU3xc0p06i37UT3a87PIl3/77Mn0GGkPlzAXCVr4CjQSMcDRri\nbNAIZ/WaFGgv0mw0bepi1qx0Wrc2M3iwiZ9+SstxS9Jt27QcPKjl0Ucd3HBDziMKsbFOYmML13K5\nrAwrviV0ykRclW8iZdY8vydgIa6h5mLEiBHqunXrMr+OjY1Vjx8/rqqqqp4/f16966671JMnT6pO\np1Pt06ePunHjxhyv53A4c7tlYGzbpqoajareeaeqOhwFupTbraq3366qJpOqpqTk4YWnTqlqqVLq\n/7d353E21/sDx1/fM2ebc2YxpuG2oZQoSpHIEhGZKDGElqtFNLnlyk6XkiWUwS9ku9V0MSLaLCVL\n1skkFXWzxKDIOts5c/bP749zTVlmbWbOmTPv5+PhgbN8v+95P75n3t/P53wWFR6u1H//q1q3VgqU\nqllTKaNRqXPnLnOib79VyuksXoAffKCUXq+UxaJUdLT/JKCUpinVuLFSw4crtW6dUrm5xTtuYXw+\npXbsUGrIEKXuvFOpsLA/zq3TKXX77Sqj/zD1aNvfFCgVEaHUO+/433axhQv9b2vVSinPZS4hn0+p\ntm39r1m27MLnfv7Z/+Nff71SDkfp/ohF4vMptXu3UqNHK1W37h85AKUMBqWaNFHqhReUWrxYqV9+\nUSotTamkJKUSEpT6298ufH1UlFI9eij1n/9c5gL5a8aM8Z/i2WcLft3DD/tft3VrqZ6+/H33nVJW\nq//P998HOhpRSRXaHT1z5kzi4uLo2bMnAG3btuWjjz4iIiICj8fDgw8+yKpVqwCYP38+Sin69u2b\n7/EC3R39ZxEvvUB48jtkv/4mjiefKXEM33+vo107Kw895GbePEfR3uT1Ep3wIMatm8meOh3HE08y\nf76BkSPNAHTs6Obdd4t4rCIwfvYJUc89jXbVVeQ2vwdX6za4m7dEVY0ttXMURsvJRr/zaww7tmLY\nsR3DrjT/AC9gYfxiBm5+hOxsjYcecjNlioMqVfzvO3xYo00bKzodbNxoy3fk+cGDGq1bW4mJUWzd\n+kdr7u9/N7N6tYEFC3Lp3LnorbK/1BWmFPrduzB9+jGmT1YSdviQ/2GzGVfre/N6GjwNbuWSL1Uv\nOo7u8CEMqdsxfL0D41cbCTuS7n9Kr8fdrAXOjvG4OsTju7ZGyWL9H5cL7rvPwk8/hbFsmZ1WrS7t\nlj5yRKNJEysNGvj4/HN7Xo9DRes21M6cIaZDa8KOpJO5IBlX54fK7dwVLVeBFEq5KvHArObNm7N2\n7VoA9u7dS7Vq1Yj4XxelXq/n2muv5fDhw3nPX3fddaUUctmzDR2FzxqBdcoEtOysEh9n+XJ/F1Zx\nVqkKnzUT49bNOO9/AMfjfQD/rkrn/XnHpNLgeqAzpw/+CgcPkvPGdFydu5RrAQZQEZG427TFPuJf\nZH60mtP7j5Lx4ad4a9biqVW9SG07jDsbe/joIwNt2ljZti0Mjweefz4cm01j0iRHgVO/atf2rx52\n4oSOiRP9c4G3bQtj9Wr/Av+dOpVht6hS6H45iGn5UiJGDKZqo/rEdGiDZeY0tFOncHTpSuaC9zj9\n0yGy3ltCbuI/8DS5q+ACDKBp+K67HmfPR8l5cyZnd37P2Y3bsQ0fjad+A4ybNxI5ciixjeoT06Y5\nlqSp6I6XbHCk0QgzZjgIC1MMGmS+7DKUCxca8fk0+vZ1BfV0o4Lofj1G9KMJhB1Jx/bSsHItwEJc\nrEhTlKZOnUpaWhqapjFmzBh+/PFHIiMjue+++0hPT2f48OEopahTpw5jx45FV8AKCMHUEgawTJuC\ndeI47C8MwjZ6bLHf7/P5p2rY7Rp79uRgKsK6EfrvvqVKfDt8MVU5t2kHKvaPYtilSzg//6xj1y5b\nob+fSyIY7yy1kyeJ7tUNww/fYWvfmVfrL+KN6VZ8Pmja1Mv27Xq6dHHz9tuOQn/xO53+QUMHD+pY\ntcrOsGFmvv8+jDVrbMXeYaegXGmnT2P4Ng39rm8w7EpDv3sXuj9t+uuLivYPSuv0EK7W9xZebEtI\nd/w3jGtWYVrzGYYtX6G53SidDlebtjh6P46rQzzFXV5q/Hgj06ebeOopF5Mm/bEBic0GDRtGYDQq\ndu2yXXCtB+N1dTnGNauIfPE5dOfO4ejRi+wZs8t9acqKkqtgEEq5yq8lXKQiXJqCrQhjt1P17kbo\nzpzm7LZvit2lt21bGF26WHj0URfTpuW/Y9KfzxfTriX6A/vJSFmBu03bC57OzASHQyvVHWH+LFgv\nai07i6g+j2HcvBH3Xc1YN+hD+g+pxpEjOq680semTba87unCbN0axsMPW4iOVmRmanTr5mb27OJ3\n7eeXK/OCuUSOGHzBY96atXDf0QjPHY1x394Yz20NKdIdWSnSsjIxrfwQ86L3MOzyT0vzxcbiSHgE\nR6/H8d58SyFH8HM4oF07C/v2hbFypZ277/Z3S7/zjoGhQ80MHuxk6NAL53YH63WVx+nEOu5fWObO\nRpnN5Lz2ur8HKgDN+aDPVRAJpVxJES6Aaeliogb0w9G1O9lzFhTrvecXnVi+3F6kFZgsb07GOuk1\n7P0SsY2bVNKQSyyoL2qnk8gB/TB/9CGeejdzbP5K5n1Wg3btPPluYJGfF14ws2SJAbNZsW2bjWuu\nKf5lfrlcaWfPULXxrWDQk/t0PzyNGuNu2OiC3oxgEPbTj5gXv4/5g8XozpwBwH3b7bjatcd1z714\nGjUucCTwN9/oeOABCzVqKDZu9PfKtGxp4dAhfy/NxTeJwXxd6Q79QtSzT2L47ls8N9Yha967Rb4h\nKQvBnKtgE0q5kiJcEJ+PKh3aYPjuW86tWY/njsZFepvLBfXrR2AyKXbvthU6c0Q7e4aqd94GRgNn\nd36PiihgHkgZCfqL2ufDOnoYlvlv4736GjJTVuCtc1OxD3PmjEbPnuF06+amf/+SbcF4uVxZX/0X\nlv9LImfcRHL7PV+i45Yrlwvj52swL07GuH4dmtd/o+iLiMTdvAXuVq1x3XMv3hvrXNIqHDvWxKxZ\nRvr1c9G2rYcePSwkJLiZNevSXoVgva5MK5YR8dKL6HKyye31GDkTphRpRbeyFKy5CkahlKsSzxOu\nFHQ6bK+Mp0qXeCL+NZKMT9YWqZtqw4YwMjI0+vVzF2nqpmXGNHTZWeSMmxiQAlwh6HTYxk/GV/1v\nRIx/hSqd25P5/lI8xdzRJjZW8cUX9tIN7fcThC94G+9VV5P796dL9dhlxmjE1elBXJ0eRMvMwLB1\nC8ZN6zFs2oBp7WpMa1cD4L3qarx16+GLikJFRqOio3nFWpXPr3ieuXNj2PSZv/D27Vu8JUYDQcvJ\nJmzvXswp/yH8/XdRFitZb831z5sXIshIEf4f990tcHbshGn1pxg//bhIIyZXrDg/Krrwlpbut18J\nXzgX79XXVJxf4IGiaeS++BK+atWJHPQPqnTrTNas+bg6PRjQsCzTpqDl5mJ/bRiYzQGNpSRUdBVc\n8Z1wxXcCQHf0CMavNmLYtB7j5k0Y16+74PUW4B3W0JLN/PdYFE1Nu2i6byfOBj1AHwS/Onw+dMeO\not+7B/3eH/L+Pj8dDPCvqz7vHbw33BjAQIXIn3RH/0nYwf3EtLwL3zXXcnbLzgJHlebk+Luiq1dX\n7NhhK7ThnDcnOektHL0fL5V4S6Kide8Yv/ycqKf/Drl2bK9OKNcu4D/nSncknarN7sB39TWc3ZoW\neisrKQV2O7rsLLSsLLSsTLSsLHTZWYxIvpVZX93O0rCedPem4Kl9A/ZBQ3F27Z63elepX1dKYfz0\nIyxzZ6NlZYLz/MYhDnC60JwONNelrXJf1ap4bmmA5+b6eG69DWfnLkF3w1TRPoOBFEq5ku7oIvDW\nvpHcJ5/BMm8O4Qvnktt/QL6vXbtWj92u0bVr4fMlww7ux7woGc+NdXD06FXKUYc2V9v2ZHy8mqje\n3Yl4eQS6o0ewvTKh1JduLIx16iQ0txvbsFGhV4DB//WL1YrPaoWLtvB7uRN0+9HGbVVeJjfJgnlx\nMlHPP4snaSr2l4aV2vrr5+mOpBMxYjCmL9aidDpUVFTemuW+mKp/rF9uMuGrVg3PLQ3w3lIfzy0N\n/NsPVtQJzKJSkpbwRbSzZ6h61+2gwdnU3aiYyy80/Oij4XzxhZ6tW22FLkwf+WwfzCs/LPeVeS6n\not5Z6o4eIbp3Avqf/4szvjNZs+ZdsiFEaTufq7B9PxPT6i68N9Xl3IZt5T6vNNjojqRjSZqKefH7\naF6vf1ORhx7EnpGN5nDk/cHpQMt1gKbhurcdzq4JBe/R6/EQ/vYs/+I5djuulveQM2Ua3utvKL8f\nrhxU1M9gIIRSrmR0dDGEz/4/IsaMJPepvuRMeuOS58+e9XdF16vn48svCx78o/9+NzHtWuFueDsZ\nazcG/C69Il/UWmYGUU8+hnHLV7gbNSbzvRRUXFyZne98rqKefgLTJyvJfHcxro4PlNn5Khrd4UNY\npk3BvHRx3qjrgihNw93iHhwJPXA90BkVFZ33nH5XGpEvvYh+7w/4YmPJeWWCfyBVCLZqK/JnsLyF\nUq6kCBeH00lMq7vQH/oFe7/nsY197YLuz+nTjYwfb2LsWAeJiQUPyoru2RXj+nVkfPAR7nvalG6c\nJVDhL2qXi8h/DsD8wRK8NWuRuWQ53tplM+gmLi6Sc19u9t9E3dGIjNXrQ7Io/FW6334lNjeDs3Yv\nhIejTCaUORzCzSiTGS0rC9PHKzAvS8GwMxXw79jlat8Rx8MJGLZtJnzBXDSlyO31GLYx48p9SdXy\nVOE/g+UolHIlRbiYdIcPEf1od/T79+Hs0JGs2QsgIoKsLGjc2L92dlpaToEblRu2baFKl3hcLe8h\nc/knpR5jSYTERa2Ufw/YNyfji4om95l+5D7TH3XFFaV6mri4SJzt2mP68ouguYkKVkW9rnTphzF/\n+AGmZSno9+/Le9xzw43kTEnC3bxlWYYZFELiM1hOQilXJd7AobLy1bqOjFXrcLVsjWntamI6d0D3\n6zHmzjWSkaHx/POuAgswSmF9bSwAtlFjyiPkykPTsA8fTdaM2aAPw/rmZGIb3YJ11FB0x46W3nm2\nbMH05Re4WrTC3ap16R23EvPVrIX9n0M4t2Un59Z9hf0f/yRn7HjObdhWKQqwEBeTlnBh3G4ihg8m\nPPnfnI67idr2PRjMOnbutBW4371x7WqiH3/EP4jonf+UXXzFFEp3lgDYbJgXJ2OZNZOwY0dRej3O\nbj2wDxiI96a6JT+uUsQldILNmzn32RfFXiyksgm566oMSa6KLpRyJS3hkjIYyJmaRM4rE0g69RhZ\nNj0D2+4usADj9WKd8ApKp8M24uVyC7VSslpxPNOfs6m7yZo5B2/tGzCnLKJqyyZEPdELw6YNUIRB\nQxczbPgSNm/G2f5+KcBCiDIj84SLQtM41uMfTJ9oorrjdwYtbYG6YQjODvFoHrd/EWm3x/9vtxvD\nNzvR//Qjjp6P/rXWmCg6gwHnI71xdu+Jce1qLDPewLTmM0xrPsNbrTrOhx7G2bW7f13wAgZX6X4/\ngT51O9ap/s01bMNGl9dPIISohKQIF9FbbxnIcRgYmWjDtCKGsAmvYp3war6vV0YjtiEjyjFCAYBO\nh6vjA7juj0f/dSrmZSmYPlmBZd4cLPPm4K1ZC0e37jgf7o63zk2EHTyAIXU7hh3bMKRuv2DJQ558\nEm+DWwP3swghQp58J1wEJ09qNGliJTpakZpqw5JxnPA5b6Hl2lEGAxiM/r/1ejAaUXoDnoa3427R\nqkzjKolQ+o6lyNxujJvWY1r+AabVn6HZbYB/JyFdzh+58EVXwd3kLtx3NcPdpBkx8W05dbZ0N4EI\nVZXyuiohyVXRhVKuZNnKv2DmTCN2u8aYMU7MZvD97Ur/3GFRMRgMuNp1wNWuA9k2G6Yv1mBavpSw\nfT/jat8Bd5NmuJvejbduvQtXwyrnpTGFEJWPFOFCnDih8e67Bq65xkfv3iXbl1YEEasVZ5duOLt0\nC3QkQggho6MLM326EYdDY9AgFyZToKMRQggRSqQIF+DYMY3kZAM1a/p45BFpBQshhChdUoQLkJRk\nxOXSeOklZ0juXieEECKwpAjnIz1dY9EiA7Vr+0hI8AQ6HCGEECFIinA+3nzThMejMXiwE70MXxNC\nCFEGpAhfxr59OlJS9Nx0k5cuXaQVLIQQomxU6CL8228aTz0FBw6U7h6vEyYY8fk0Ro50yVRRIYQQ\nZaZCF+FjxzT+/W9ISLBw9GjpFOK0NB2rVhm4804v998vrWAhhBBlp0IX4SZNfEyeDL/9piMhwcLJ\nk3+tECsFr73mnwz88svOgtb5F0IIIf6yCl2EAYYMgYEDnRw6pKNHj3AyMkp+rPXrw9i2Tc9993lo\n2rT4298JIYQQxVHhizDAiBEunnzSxY8/htG7twWbrfjH8Pn8rWBNU4wa5Sz9IIUQQoiLhEQR1jSY\nONFJ165u0tLC6NMnHGcx6+iKFXr27g0jIcHDzTf7yiZQIYQQ4k9CogiDf/ObmTMddOjgYdMmPc89\nZ8ZTxHFVLhdMmmTCYFAMGyatYCGEEOUjZIowgMEAc+fm0ry5h08/NTBokBlfERq1yckG0tN19Onj\npkaNct1eWQghRCUWUkUYIDwckpNzadjQy5IlBgYNMnHuXP6vz8mBN94wYrUqBg50lV+gQgghKr2Q\nK8IAERGweHEu9ep5WbTISJMmEcyYYcRuv/S1c+YYOX1aR2Kii7g4aQULIYQoPyFZhAFiYxVr1tgZ\nO9aBTucf+dy0qZX33jPkfVd8+rTGW28ZueIKH889J61gIYQQ5StkizD4u6YTE918/XUOAwc6ycrS\nGDzYTMuWVj75RM+0aUZsNo1Bg1xERAQ6WiGEEJVNSBfh86KjYeRIF6mpNvr0cZGervH00+HMm2ek\nRg0fTzzhDnSIQgghKqFKUYTPq15dMXmyky1bbHTp4iYsTDF2rBOjMdCRCSGEqIwq5U6511+vmDvX\ngceD7BUshBAiYCpVS/hiUoCFEEIEUqUuwkIIIUQgSREWQgghAkSKsBBCCBEgUoSFEEKIAJEiLIQQ\nQgSIFGEhhBAiQKQICyGEEAEiRVgIIYQIECnCQgghRIBIERZCCCECRIqwEEIIESCaUkoFOgghhBCi\nMpKWsBBCCBEgUoSFEEKIAJEiLIQQQgSIFGEhhBAiQKQICyGEEAEiRVgIIYQIEH2gA/grJkyYwHff\nfYemaYwcOZJbb7010CEFnX379pGYmEifPn147LHHOH78OEOHDsXr9RIXF8eUKVMwGo2BDjMoTJ48\nmW+++QaPx0O/fv1o0KCB5OoycnNzGT58OGfOnMHpdJKYmEjdunUlVwVwOBx06tSJxMREmjVrJrm6\njNTUVF588UVuvPFGAOrUqcMzzzwT8rmqsC3hr7/+mvT0dFJSUhg/fjzjx48PdEhBx263M27cOJo1\na5b32IwZM+jduzeLFi2iZs2aLFu2LIARBo8dO3awf/9+UlJSmD9/PhMmTJBc5WPDhg3Ur1+f999/\nn6SkJCZNmiS5KsTs2bOJjo4G5DNYkCZNmpCcnExycjIvv/xypchVhS3C27dvp127dgDUrl2bzMxM\ncnJyAhxVcDEajcybN49q1arlPZaamkrbtm0BaNOmDdu3bw9UeEHlzjvvZPr06QBERUWRm5srucpH\nfHw8ffv2BeD48eNUr15dclWAgwcPcuDAAVq3bg3IZ7A4KkOuKmwRPn36NDExMXn/r1q1KqdOnQpg\nRMFHr9djNpsveCw3NzevOyc2NlZy9j9hYWFYLBYAli1bRqtWrSRXhejZsyeDBw9m5MiRkqsCvP76\n6wwfPjzv/5Kr/B04cID+/fvTq1cvtm7dWilyVaG/E/4zWX2z+CRnl1q3bh3Lli1j4cKFtG/fPu9x\nydWllixZwk8//cSQIUMuyI/k6g8rV66kYcOGXHvttZd9XnL1h1q1ajFgwAA6duzI0aNHeeKJJ/B6\nvXnPh2quKmwRrlatGqdPn877/8mTJ4mLiwtgRBWDxWLB4XBgNpv5/fffL+iqruw2b97MnDlzmD9/\nPpGRkZKrfOzZs4fY2FiuvPJK6tWrh9frxWq1Sq4uY+PGjRw9epSNGzdy4sQJjEajXFf5qF69OvHx\n8QDUqFGDK664gh9++CHkc1Vhu6ObN2/O2rVrAdi7dy/VqlUjIiIiwFEFv7vvvjsvb59//jktW7YM\ncETBITs7m8mTJ/P2229TpUoVQHKVn7S0NBYuXAj4vxay2+2Sq3wkJSWxfPlyli5dSvfu3UlMTJRc\n5ePjjz9mwYIFAJw6dYozZ87QtWvXkM9Vhd5FaerUqaSlpaFpGmPGjKFu3bqBDimo7Nmzh9dff51f\nf/0VvV5P9erVmTp1KsOHD8fpdHLVVVcxceJEDAZDoEMNuJSUFGbOnMl1112X99ikSZMYPXq05Ooi\nDoeDUaNGcfz4cRwOBwMGDKB+/foMGzZMclWAmTNncvXVV9OiRQvJ1WXk5OQwePBgsrKycLvdDBgw\ngHr16oV8rip0ERZCCCEqsgrbHS2EEEJUdFKEhRBCiACRIiyEEEIEiBRhIYQQIkCkCAshhBABIkVY\nCCGECBApwkIIIUSASBEWQgghAuT/AXEhuVjlqy1CAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff22b52edd8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "plt2.plot(newp,color='red', label='Prediction')\n",
    "plt2.plot(newy_test,color='blue', label='Actual')\n",
    "plt2.legend(loc='best')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BauL0QyFiicF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AFY2z9jd5PGP"
   },
   "source": [
    "**END**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L-HUKsd8iiWD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZEWQxLu5RO2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLRAhNuI5Rgl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDU6MZcz5Rt1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLiaY4pj5Rrj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nJ4TE_V5RoJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QWu0QVs_5RmX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJiuEz5R5Re1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qe0o1BZf5Rck"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-tnFFZDS5RZp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYr2ySkj5RWr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ymtwk4d5RUZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGVAUo8c5RNF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-hyniJjf5RJ9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1u_6vZqK5RG8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJykfXmDCvXt"
   },
   "outputs": [],
   "source": [
    "\n",
    "def percentage_difference(model, X_test, y_test):\n",
    "    percentage_diff=[]\n",
    "\n",
    "    p = model.predict(X_test)\n",
    "    for u in range(len(y_test)): # for each data index in test data\n",
    "        pr = p[u][0] # pr = prediction on day u\n",
    "\n",
    "        percentage_diff.append((pr-y_test[u]/pr)*100)\n",
    "    return p  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0XhzjLmNVshs"
   },
   "outputs": [],
   "source": [
    "p = percentage_difference(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6FA2VS8CvPs"
   },
   "outputs": [],
   "source": [
    "def denormalize(forex_df_norm, normalized_value):    \n",
    "    stock_name = stock_name['DEXINUS'].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "    \n",
    "    #return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    a = min_max_scaler.fit_transform(df)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0oLpvbKiCvOF"
   },
   "outputs": [],
   "source": [
    "def plot_result(stock_name, normalized_value_p, normalized_value_y_test):\n",
    "    newp = denormalize(stock_name, normalized_value_p)\n",
    "    newy_test = denormalize(stock_name, normalized_value_y_test)\n",
    "    plt2.plot(newp, color='red', label='Prediction')\n",
    "    plt2.plot(newy_test,color='blue', label='Actual')\n",
    "    plt2.legend(loc='best')\n",
    "    plt2.title('The test result for {}'.format(forex_df_norm))\n",
    "    plt2.xlabel('Days')\n",
    "    plt2.ylabel('Adjusted Close')\n",
    "    plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "colab_type": "code",
    "id": "A9nVqLkZCvIP",
    "outputId": "38d09e7b-5242-4e75-b888-e45c25ed6175"
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-eab8139af475>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-85-5f9c14d36312>\u001b[0m in \u001b[0;36mplot_result\u001b[0;34m(stock_name, normalized_value_p, normalized_value_y_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_value_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_value_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnewp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_value_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnewy_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_value_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewy_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Actual'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-e81c05d9601e>\u001b[0m in \u001b[0;36mdenormalize\u001b[0;34m(forex_df_norm, normalized_value)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdenormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforex_df_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mstock_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstock_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DEXINUS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnormalized_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#return df.shape, p.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'stock_name' referenced before assignment"
     ]
    }
   ],
   "source": [
    "plot_result(stock_name, p, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DgFI5Ckc3hJy"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr = 0.0005) , metrics = ['mean_squared_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3501
    },
    "colab_type": "code",
    "id": "OuXEolkX3hPC",
    "outputId": "83c0b790-4362-4a62-ae8d-e08c186e5185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 518 samples, validate on 57 samples\n",
      "Epoch 1/100\n",
      "518/518 [==============================] - 5s 9ms/step - loss: 0.0477 - mean_squared_error: 0.0477 - val_loss: 0.0346 - val_mean_squared_error: 0.0346\n",
      "Epoch 2/100\n",
      "518/518 [==============================] - 0s 662us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0796 - val_mean_squared_error: 0.0796\n",
      "Epoch 3/100\n",
      "518/518 [==============================] - 0s 699us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0377 - val_mean_squared_error: 0.0377\n",
      "Epoch 4/100\n",
      "518/518 [==============================] - 0s 667us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0091 - val_mean_squared_error: 0.0091\n",
      "Epoch 5/100\n",
      "518/518 [==============================] - 0s 675us/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 6/100\n",
      "518/518 [==============================] - 0s 718us/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 7/100\n",
      "518/518 [==============================] - 0s 684us/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 8.4945e-04 - val_mean_squared_error: 8.4945e-04\n",
      "Epoch 8/100\n",
      "518/518 [==============================] - 0s 652us/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 9.8359e-04 - val_mean_squared_error: 9.8359e-04\n",
      "Epoch 9/100\n",
      "518/518 [==============================] - 0s 712us/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 10/100\n",
      "518/518 [==============================] - 0s 661us/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 9.6318e-04 - val_mean_squared_error: 9.6318e-04\n",
      "Epoch 11/100\n",
      "518/518 [==============================] - 0s 678us/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 8.9266e-04 - val_mean_squared_error: 8.9266e-04\n",
      "Epoch 12/100\n",
      "518/518 [==============================] - 0s 700us/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 7.9477e-04 - val_mean_squared_error: 7.9477e-04\n",
      "Epoch 13/100\n",
      "518/518 [==============================] - 0s 672us/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 7.9811e-04 - val_mean_squared_error: 7.9811e-04\n",
      "Epoch 14/100\n",
      "518/518 [==============================] - 0s 684us/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 9.0032e-04 - val_mean_squared_error: 9.0032e-04\n",
      "Epoch 15/100\n",
      "518/518 [==============================] - 0s 717us/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 8.5986e-04 - val_mean_squared_error: 8.5986e-04\n",
      "Epoch 16/100\n",
      "518/518 [==============================] - 0s 686us/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 7.9876e-04 - val_mean_squared_error: 7.9876e-04\n",
      "Epoch 17/100\n",
      "518/518 [==============================] - 0s 669us/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 18/100\n",
      "518/518 [==============================] - 0s 696us/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 7.8869e-04 - val_mean_squared_error: 7.8869e-04\n",
      "Epoch 19/100\n",
      "518/518 [==============================] - 0s 651us/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 20/100\n",
      "518/518 [==============================] - 0s 675us/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 7.9724e-04 - val_mean_squared_error: 7.9724e-04\n",
      "Epoch 21/100\n",
      "518/518 [==============================] - 0s 692us/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 9.4632e-04 - val_mean_squared_error: 9.4632e-04\n",
      "Epoch 22/100\n",
      "518/518 [==============================] - 0s 646us/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 8.4259e-04 - val_mean_squared_error: 8.4259e-04\n",
      "Epoch 23/100\n",
      "518/518 [==============================] - 0s 681us/step - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 9.3046e-04 - val_mean_squared_error: 9.3046e-04\n",
      "Epoch 24/100\n",
      "518/518 [==============================] - 0s 701us/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 8.4012e-04 - val_mean_squared_error: 8.4012e-04\n",
      "Epoch 25/100\n",
      "518/518 [==============================] - 0s 652us/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 8.2881e-04 - val_mean_squared_error: 8.2881e-04\n",
      "Epoch 26/100\n",
      "518/518 [==============================] - 0s 662us/step - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 27/100\n",
      "518/518 [==============================] - 0s 694us/step - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 8.3350e-04 - val_mean_squared_error: 8.3350e-04\n",
      "Epoch 28/100\n",
      "518/518 [==============================] - 0s 651us/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 8.2566e-04 - val_mean_squared_error: 8.2566e-04\n",
      "Epoch 29/100\n",
      "518/518 [==============================] - 0s 669us/step - loss: 9.8636e-04 - mean_squared_error: 9.8636e-04 - val_loss: 8.4214e-04 - val_mean_squared_error: 8.4214e-04\n",
      "Epoch 30/100\n",
      "518/518 [==============================] - 0s 742us/step - loss: 8.8369e-04 - mean_squared_error: 8.8369e-04 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 31/100\n",
      "518/518 [==============================] - 0s 649us/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 32/100\n",
      "518/518 [==============================] - 0s 682us/step - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 9.6246e-04 - val_mean_squared_error: 9.6246e-04\n",
      "Epoch 33/100\n",
      "518/518 [==============================] - 0s 714us/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 8.0880e-04 - val_mean_squared_error: 8.0880e-04\n",
      "Epoch 34/100\n",
      "518/518 [==============================] - 0s 656us/step - loss: 9.4931e-04 - mean_squared_error: 9.4931e-04 - val_loss: 9.3874e-04 - val_mean_squared_error: 9.3874e-04\n",
      "Epoch 35/100\n",
      "518/518 [==============================] - 0s 707us/step - loss: 9.7237e-04 - mean_squared_error: 9.7237e-04 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 36/100\n",
      "518/518 [==============================] - 0s 729us/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 8.5784e-04 - val_mean_squared_error: 8.5784e-04\n",
      "Epoch 37/100\n",
      "518/518 [==============================] - 0s 695us/step - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 38/100\n",
      "518/518 [==============================] - 0s 689us/step - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 39/100\n",
      "518/518 [==============================] - 0s 674us/step - loss: 9.3210e-04 - mean_squared_error: 9.3210e-04 - val_loss: 8.4045e-04 - val_mean_squared_error: 8.4045e-04\n",
      "Epoch 40/100\n",
      "518/518 [==============================] - 0s 685us/step - loss: 9.1116e-04 - mean_squared_error: 9.1116e-04 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 41/100\n",
      "518/518 [==============================] - 0s 707us/step - loss: 9.8410e-04 - mean_squared_error: 9.8410e-04 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 42/100\n",
      "518/518 [==============================] - 0s 679us/step - loss: 9.8320e-04 - mean_squared_error: 9.8320e-04 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 43/100\n",
      "518/518 [==============================] - 0s 682us/step - loss: 9.1131e-04 - mean_squared_error: 9.1131e-04 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 44/100\n",
      "518/518 [==============================] - 0s 702us/step - loss: 8.7733e-04 - mean_squared_error: 8.7733e-04 - val_loss: 9.9947e-04 - val_mean_squared_error: 9.9947e-04\n",
      "Epoch 45/100\n",
      "518/518 [==============================] - 0s 652us/step - loss: 9.2573e-04 - mean_squared_error: 9.2573e-04 - val_loss: 9.4271e-04 - val_mean_squared_error: 9.4271e-04\n",
      "Epoch 46/100\n",
      "518/518 [==============================] - 0s 667us/step - loss: 8.8754e-04 - mean_squared_error: 8.8754e-04 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 47/100\n",
      "518/518 [==============================] - 0s 706us/step - loss: 8.9477e-04 - mean_squared_error: 8.9477e-04 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 48/100\n",
      "518/518 [==============================] - 0s 681us/step - loss: 9.8379e-04 - mean_squared_error: 9.8379e-04 - val_loss: 9.9247e-04 - val_mean_squared_error: 9.9247e-04\n",
      "Epoch 49/100\n",
      "518/518 [==============================] - 0s 680us/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 9.1952e-04 - val_mean_squared_error: 9.1952e-04\n",
      "Epoch 50/100\n",
      "518/518 [==============================] - 0s 708us/step - loss: 9.7804e-04 - mean_squared_error: 9.7804e-04 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 51/100\n",
      "518/518 [==============================] - 0s 681us/step - loss: 8.3752e-04 - mean_squared_error: 8.3752e-04 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 52/100\n",
      "518/518 [==============================] - 0s 643us/step - loss: 8.2987e-04 - mean_squared_error: 8.2987e-04 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 53/100\n",
      "518/518 [==============================] - 0s 732us/step - loss: 8.7447e-04 - mean_squared_error: 8.7447e-04 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 54/100\n",
      "518/518 [==============================] - 0s 697us/step - loss: 8.5538e-04 - mean_squared_error: 8.5538e-04 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 55/100\n",
      "518/518 [==============================] - 0s 669us/step - loss: 7.7431e-04 - mean_squared_error: 7.7431e-04 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 56/100\n",
      "518/518 [==============================] - 0s 696us/step - loss: 8.6363e-04 - mean_squared_error: 8.6363e-04 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 57/100\n",
      "518/518 [==============================] - 0s 674us/step - loss: 7.6752e-04 - mean_squared_error: 7.6752e-04 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 58/100\n",
      "518/518 [==============================] - 0s 685us/step - loss: 7.9499e-04 - mean_squared_error: 7.9499e-04 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 59/100\n",
      "518/518 [==============================] - 0s 700us/step - loss: 7.1261e-04 - mean_squared_error: 7.1261e-04 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 60/100\n",
      "518/518 [==============================] - 0s 677us/step - loss: 8.1919e-04 - mean_squared_error: 8.1919e-04 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 61/100\n",
      "518/518 [==============================] - 0s 671us/step - loss: 7.9209e-04 - mean_squared_error: 7.9209e-04 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 62/100\n",
      "518/518 [==============================] - 0s 697us/step - loss: 8.5700e-04 - mean_squared_error: 8.5700e-04 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 63/100\n",
      "518/518 [==============================] - 0s 662us/step - loss: 8.2992e-04 - mean_squared_error: 8.2992e-04 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 64/100\n",
      "518/518 [==============================] - 0s 667us/step - loss: 8.3713e-04 - mean_squared_error: 8.3713e-04 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 65/100\n",
      "518/518 [==============================] - 0s 704us/step - loss: 7.3508e-04 - mean_squared_error: 7.3508e-04 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 66/100\n",
      "518/518 [==============================] - 0s 665us/step - loss: 7.0475e-04 - mean_squared_error: 7.0475e-04 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 67/100\n",
      "518/518 [==============================] - 0s 682us/step - loss: 7.6849e-04 - mean_squared_error: 7.6849e-04 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 68/100\n",
      "518/518 [==============================] - 0s 710us/step - loss: 8.5971e-04 - mean_squared_error: 8.5971e-04 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 69/100\n",
      "518/518 [==============================] - 0s 672us/step - loss: 7.7688e-04 - mean_squared_error: 7.7688e-04 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 70/100\n",
      "518/518 [==============================] - 0s 652us/step - loss: 7.6765e-04 - mean_squared_error: 7.6765e-04 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 71/100\n",
      "518/518 [==============================] - 0s 708us/step - loss: 7.9410e-04 - mean_squared_error: 7.9410e-04 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 72/100\n",
      "518/518 [==============================] - 0s 683us/step - loss: 6.7291e-04 - mean_squared_error: 6.7291e-04 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 73/100\n",
      "518/518 [==============================] - 0s 656us/step - loss: 7.7667e-04 - mean_squared_error: 7.7667e-04 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 74/100\n",
      "518/518 [==============================] - 0s 722us/step - loss: 6.6924e-04 - mean_squared_error: 6.6924e-04 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 75/100\n",
      "518/518 [==============================] - 0s 662us/step - loss: 7.6259e-04 - mean_squared_error: 7.6259e-04 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 76/100\n",
      "518/518 [==============================] - 0s 659us/step - loss: 7.9117e-04 - mean_squared_error: 7.9117e-04 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 77/100\n",
      "518/518 [==============================] - 0s 717us/step - loss: 7.6083e-04 - mean_squared_error: 7.6083e-04 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 78/100\n",
      "518/518 [==============================] - 0s 712us/step - loss: 8.2642e-04 - mean_squared_error: 8.2642e-04 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 79/100\n",
      "518/518 [==============================] - 0s 734us/step - loss: 7.9228e-04 - mean_squared_error: 7.9228e-04 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 80/100\n",
      "518/518 [==============================] - 0s 658us/step - loss: 7.6269e-04 - mean_squared_error: 7.6269e-04 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 81/100\n",
      "518/518 [==============================] - 0s 687us/step - loss: 7.6378e-04 - mean_squared_error: 7.6378e-04 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 82/100\n",
      "518/518 [==============================] - 0s 689us/step - loss: 7.0606e-04 - mean_squared_error: 7.0606e-04 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 83/100\n",
      "518/518 [==============================] - 0s 682us/step - loss: 6.3814e-04 - mean_squared_error: 6.3814e-04 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 84/100\n",
      "518/518 [==============================] - 0s 675us/step - loss: 6.9768e-04 - mean_squared_error: 6.9768e-04 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 85/100\n",
      "518/518 [==============================] - 0s 703us/step - loss: 7.0808e-04 - mean_squared_error: 7.0808e-04 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 86/100\n",
      "518/518 [==============================] - 0s 645us/step - loss: 7.4180e-04 - mean_squared_error: 7.4180e-04 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 87/100\n",
      "518/518 [==============================] - 0s 663us/step - loss: 7.4688e-04 - mean_squared_error: 7.4688e-04 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 88/100\n",
      "518/518 [==============================] - 0s 719us/step - loss: 7.4024e-04 - mean_squared_error: 7.4024e-04 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 89/100\n",
      "518/518 [==============================] - 0s 651us/step - loss: 6.6527e-04 - mean_squared_error: 6.6527e-04 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 90/100\n",
      "518/518 [==============================] - 0s 655us/step - loss: 6.8829e-04 - mean_squared_error: 6.8829e-04 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 91/100\n",
      "518/518 [==============================] - 0s 702us/step - loss: 8.0539e-04 - mean_squared_error: 8.0539e-04 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 92/100\n",
      "518/518 [==============================] - 0s 815us/step - loss: 6.5356e-04 - mean_squared_error: 6.5356e-04 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 93/100\n",
      "518/518 [==============================] - 0s 692us/step - loss: 7.7721e-04 - mean_squared_error: 7.7721e-04 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 94/100\n",
      "518/518 [==============================] - 0s 707us/step - loss: 8.2365e-04 - mean_squared_error: 8.2365e-04 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 95/100\n",
      "518/518 [==============================] - 0s 674us/step - loss: 7.1719e-04 - mean_squared_error: 7.1719e-04 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 96/100\n",
      "518/518 [==============================] - 0s 691us/step - loss: 6.4175e-04 - mean_squared_error: 6.4175e-04 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 97/100\n",
      "518/518 [==============================] - 0s 710us/step - loss: 6.6994e-04 - mean_squared_error: 6.6994e-04 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 98/100\n",
      "518/518 [==============================] - 0s 663us/step - loss: 6.8946e-04 - mean_squared_error: 6.8946e-04 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 99/100\n",
      "518/518 [==============================] - 0s 657us/step - loss: 6.4574e-04 - mean_squared_error: 6.4574e-04 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 100/100\n",
      "518/518 [==============================] - 0s 711us/step - loss: 6.5930e-04 - mean_squared_error: 6.5930e-04 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100 , batch_size = 25 , \n",
    "            validation_data = (X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "colab_type": "code",
    "id": "A2GmdeLD3hNZ",
    "outputId": "6758e15d-3b16-434d-81c2-92c656144893"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ac343c780>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntRAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ac2408a58>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.title('model mean squared error')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "YFEmUhuF3hH0",
    "outputId": "0b895a96-9f29-4989-a514-305a87d04bda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00047 MSE (0.02 RMSE)\n",
      "Test Score: 0.00278 MSE (0.05 RMSE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00047402550321626097, 0.002784527201009424)"
      ]
     },
     "execution_count": 260,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]\n",
    "\n",
    "model_score(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "id": "icgbmol95pPd",
    "outputId": "979ea56d-1fe4-4062-a88c-6768dffa9dfb"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-264-b070d7d441a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: inverse_transform() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = MinMaxScaler.inverse_transform(pred)\n",
    "pred[:10]\n",
    "\n",
    "\n",
    "def denormalize(forex_df_norm, normalized_value): \n",
    "    forex_df_norm = forex_df_norm['DEXINUS'].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "    \n",
    "    #return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    a = min_max_scaler.fit_transform(forex_df_norm)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "    return new\n",
    "\n",
    "newp = denormalize(forex_df_norm, p)\n",
    "newy_test = denormalize(forex_df_norm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEaAcO8z5pUf"
   },
   "outputs": [],
   "source": [
    "def percentage_difference(model, X_test, y_test):\n",
    "    percentage_diff=[]\n",
    "\n",
    "    p = model.predict(X_test)\n",
    "    for u in range(len(y_test)): # for each data index in test data\n",
    "        pr = p[u][0] # pr = prediction on day u\n",
    "\n",
    "        percentage_diff.append((pr-y_test[u]/pr)*100)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XOVrCPO65pZ6"
   },
   "outputs": [],
   "source": [
    "pred = percentage_difference(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z_ZurmLk5pYd"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(testX)\n",
    "pred = scaler.inverse_transform(pred)\n",
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AhfNCWu35pTH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ETah0BN45pNq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "colab_type": "code",
    "id": "1hADBz5ll7nD",
    "outputId": "8eb5ff61-9ab0-460b-8198-7628eb3085e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model2(shape, neurons, d)\n",
    "# layers = [4, 22, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 10050
    },
    "colab_type": "code",
    "id": "FDjlEWOcl7rs",
    "outputId": "838d4ddf-3ed6-4c9a-9608-27df89b86f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 449 samples, validate on 50 samples\n",
      "Epoch 1/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0064 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.8997e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.1580e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.5299e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.7604e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.8485e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.3545e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.3949e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.3990e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.9703e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.3119e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.5246e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.9613e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.7050e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.6735e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.8610e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.3909e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.3657e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.0019e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.3289e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.1233e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7334e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.1148e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.6689e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.0635e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8493e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7704e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.6145e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4338e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1795e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.0601e-04 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.3030e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.6963e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.1976e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.8530e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.8100e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.0453e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1907e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8684e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.7508e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.0558e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4250e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.5500e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8998e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8406e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8284e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.5684e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.4532e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.9092e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.3491e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7671e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.0356e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7354e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7310e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7410e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4545e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8925e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8508e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8325e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.4431e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1707e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.5362e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.8307e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.4763e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7166e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0851e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3289e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.9437e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3296e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7884e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8330e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.3248e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0356e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.5619e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.5480e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.2588e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.6367e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1062e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.9622e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.5617e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7447e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7047e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1030e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8939e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6639e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4879e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.9672e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1432e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6371e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.2540e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.4286e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3358e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.6224e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3500e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3094e-04 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6277e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7859e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1709e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6963e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.8609e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.8342e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.8128e-04 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2180e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.9611e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6603e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7570e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.9067e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.4423e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.5639e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6710e-04 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.6769e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1990e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7375e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.3983e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3832e-04 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3020e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3106e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2191e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7857e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.5629e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7137e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6602e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.8550e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1441e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.4080e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8397e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3180e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8156e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1879e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.5516e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.5563e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6448e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0016e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.2025e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2426e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0737e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4832e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.4372e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0522e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.3909e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.0547e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.5513e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8410e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.2084e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4271e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1914e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.9967e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2557e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2341e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3092e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.5742e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.4533e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3816e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.4563e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7589e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0971e-04 - acc: 0.0022 - val_loss: 0.0060 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.9282e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.9606e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1583e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.7609e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.1789e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6552e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2888e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9558e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.5075e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.2411e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.7178e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1577e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4111e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.5870e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3639e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.5353e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9548e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.8153e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.7552e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1300e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2029e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.0000e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.8770e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2467e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.0072e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.9057e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4032e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.6824e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.3617e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6287e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1625e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.4675e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.9207e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1056e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.8288e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9673e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.6169e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.7526e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3709e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.7912e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.4001e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4773e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.4003e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.5155e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.8667e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4685e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.1619e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.3849e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4057e-04 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9833e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9008e-04 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.6647e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.6009e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.3579e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9567e-04 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2616e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3282e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.8534e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.8144e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4457e-04 - acc: 0.0022 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7116e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.5559e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.7080e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.8491e-04 - acc: 0.0022 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 4.8824e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.7678e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.8688e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.6018e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.7481e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.4613e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4363e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.6505e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9360e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1412e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.8517e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.7733e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.2945e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 3.9037e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4127e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8454e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.3046e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.6326e-04 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3964e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3162e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3776e-04 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.5208e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.7618e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 4.7095e-04 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4986e-04 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2870e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 3.8511e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.6396e-04 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.5540e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 3.8279e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 4.3729e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.3871e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.5841e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.4626e-04 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.6573e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9491e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.3086e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.4718e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.6604e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9003e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.3303e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.6939e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.2067e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.4842e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.4767e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.8235e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ae0476390>"
      ]
     },
     "execution_count": 173,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=24,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9YVbTaPl72n"
   },
   "outputs": [],
   "source": [
    "def percentage_difference(model, X_test, y_test):\n",
    "    percentage_diff=[]\n",
    "\n",
    "    p = model.predict(X_test)\n",
    "    for u in range(len(y_test)): # for each data index in test data\n",
    "        pr = p[u][0] # pr = prediction on day u\n",
    "\n",
    "        percentage_diff.append((pr-y_test[u]/pr)*100)\n",
    "    return p\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2000
    },
    "colab_type": "code",
    "id": "hzca146Sl70e",
    "outputId": "e8da787f-4438-4386-8013-5ed38e8e4208"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEXSZUS</th>\n",
       "      <th>DEXMXUS</th>\n",
       "      <th>DEXBZUS</th>\n",
       "      <th>DEXINUS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5/20/2016</th>\n",
       "      <td>0.624319</td>\n",
       "      <td>0.203807</td>\n",
       "      <td>0.421415</td>\n",
       "      <td>0.471963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/23/2016</th>\n",
       "      <td>0.623412</td>\n",
       "      <td>0.225105</td>\n",
       "      <td>0.453443</td>\n",
       "      <td>0.477804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/24/2016</th>\n",
       "      <td>0.633394</td>\n",
       "      <td>0.218874</td>\n",
       "      <td>0.432935</td>\n",
       "      <td>0.491822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/25/2016</th>\n",
       "      <td>0.613430</td>\n",
       "      <td>0.220347</td>\n",
       "      <td>0.481281</td>\n",
       "      <td>0.455607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/26/2016</th>\n",
       "      <td>0.604356</td>\n",
       "      <td>0.220347</td>\n",
       "      <td>0.455363</td>\n",
       "      <td>0.411215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/27/2016</th>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.215362</td>\n",
       "      <td>0.485644</td>\n",
       "      <td>0.418224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/31/2016</th>\n",
       "      <td>0.637024</td>\n",
       "      <td>0.211963</td>\n",
       "      <td>0.481456</td>\n",
       "      <td>0.436916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/1/2016</th>\n",
       "      <td>0.598911</td>\n",
       "      <td>0.242438</td>\n",
       "      <td>0.477616</td>\n",
       "      <td>0.474299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/2/2016</th>\n",
       "      <td>0.607985</td>\n",
       "      <td>0.261584</td>\n",
       "      <td>0.473078</td>\n",
       "      <td>0.448598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/3/2016</th>\n",
       "      <td>0.498185</td>\n",
       "      <td>0.257052</td>\n",
       "      <td>0.416703</td>\n",
       "      <td>0.421729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/6/2016</th>\n",
       "      <td>0.442831</td>\n",
       "      <td>0.257505</td>\n",
       "      <td>0.395933</td>\n",
       "      <td>0.400701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/7/2016</th>\n",
       "      <td>0.391107</td>\n",
       "      <td>0.217175</td>\n",
       "      <td>0.353172</td>\n",
       "      <td>0.380841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/8/2016</th>\n",
       "      <td>0.328494</td>\n",
       "      <td>0.146709</td>\n",
       "      <td>0.280391</td>\n",
       "      <td>0.365654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/9/2016</th>\n",
       "      <td>0.369328</td>\n",
       "      <td>0.183754</td>\n",
       "      <td>0.294703</td>\n",
       "      <td>0.385514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/10/2016</th>\n",
       "      <td>0.362976</td>\n",
       "      <td>0.237567</td>\n",
       "      <td>0.326468</td>\n",
       "      <td>0.404206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/13/2016</th>\n",
       "      <td>0.390200</td>\n",
       "      <td>0.302934</td>\n",
       "      <td>0.352736</td>\n",
       "      <td>0.442757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/14/2016</th>\n",
       "      <td>0.370236</td>\n",
       "      <td>0.340093</td>\n",
       "      <td>0.384152</td>\n",
       "      <td>0.462617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/15/2016</th>\n",
       "      <td>0.376588</td>\n",
       "      <td>0.313923</td>\n",
       "      <td>0.362859</td>\n",
       "      <td>0.432243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/16/2016</th>\n",
       "      <td>0.390200</td>\n",
       "      <td>0.342132</td>\n",
       "      <td>0.383541</td>\n",
       "      <td>0.473131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/17/2016</th>\n",
       "      <td>0.343013</td>\n",
       "      <td>0.313583</td>\n",
       "      <td>0.326730</td>\n",
       "      <td>0.435748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/20/2016</th>\n",
       "      <td>0.348457</td>\n",
       "      <td>0.269287</td>\n",
       "      <td>0.294965</td>\n",
       "      <td>0.485981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/21/2016</th>\n",
       "      <td>0.330309</td>\n",
       "      <td>0.266795</td>\n",
       "      <td>0.303779</td>\n",
       "      <td>0.508178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/22/2016</th>\n",
       "      <td>0.319419</td>\n",
       "      <td>0.238473</td>\n",
       "      <td>0.282485</td>\n",
       "      <td>0.480140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/23/2016</th>\n",
       "      <td>0.303085</td>\n",
       "      <td>0.186587</td>\n",
       "      <td>0.251593</td>\n",
       "      <td>0.456776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/24/2016</th>\n",
       "      <td>0.426497</td>\n",
       "      <td>0.311997</td>\n",
       "      <td>0.291299</td>\n",
       "      <td>0.518692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/27/2016</th>\n",
       "      <td>0.503630</td>\n",
       "      <td>0.379404</td>\n",
       "      <td>0.302644</td>\n",
       "      <td>0.530374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/28/2016</th>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.324572</td>\n",
       "      <td>0.219653</td>\n",
       "      <td>0.523364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/29/2016</th>\n",
       "      <td>0.509982</td>\n",
       "      <td>0.239719</td>\n",
       "      <td>0.159613</td>\n",
       "      <td>0.471963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/30/2016</th>\n",
       "      <td>0.508167</td>\n",
       "      <td>0.230203</td>\n",
       "      <td>0.126189</td>\n",
       "      <td>0.482477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7/1/2016</th>\n",
       "      <td>0.451906</td>\n",
       "      <td>0.207432</td>\n",
       "      <td>0.165023</td>\n",
       "      <td>0.450935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7/27/2018</th>\n",
       "      <td>0.642468</td>\n",
       "      <td>0.245157</td>\n",
       "      <td>0.573959</td>\n",
       "      <td>0.609813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7/30/2018</th>\n",
       "      <td>0.592559</td>\n",
       "      <td>0.240172</td>\n",
       "      <td>0.582162</td>\n",
       "      <td>0.609813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7/31/2018</th>\n",
       "      <td>0.601633</td>\n",
       "      <td>0.253880</td>\n",
       "      <td>0.601536</td>\n",
       "      <td>0.602804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/1/2018</th>\n",
       "      <td>0.627042</td>\n",
       "      <td>0.260111</td>\n",
       "      <td>0.608517</td>\n",
       "      <td>0.582944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/2/2018</th>\n",
       "      <td>0.645191</td>\n",
       "      <td>0.260451</td>\n",
       "      <td>0.610699</td>\n",
       "      <td>0.613318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/3/2018</th>\n",
       "      <td>0.629764</td>\n",
       "      <td>0.248102</td>\n",
       "      <td>0.573872</td>\n",
       "      <td>0.602804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/6/2018</th>\n",
       "      <td>0.663339</td>\n",
       "      <td>0.236547</td>\n",
       "      <td>0.580417</td>\n",
       "      <td>0.635514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/7/2018</th>\n",
       "      <td>0.646098</td>\n",
       "      <td>0.222273</td>\n",
       "      <td>0.573436</td>\n",
       "      <td>0.612150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/8/2018</th>\n",
       "      <td>0.645191</td>\n",
       "      <td>0.226691</td>\n",
       "      <td>0.600838</td>\n",
       "      <td>0.615654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/9/2018</th>\n",
       "      <td>0.611615</td>\n",
       "      <td>0.272573</td>\n",
       "      <td>0.663845</td>\n",
       "      <td>0.626168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/10/2018</th>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.330917</td>\n",
       "      <td>0.696570</td>\n",
       "      <td>0.642523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/13/2018</th>\n",
       "      <td>0.637024</td>\n",
       "      <td>0.405121</td>\n",
       "      <td>0.747535</td>\n",
       "      <td>0.775701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/14/2018</th>\n",
       "      <td>0.633394</td>\n",
       "      <td>0.345871</td>\n",
       "      <td>0.723885</td>\n",
       "      <td>0.767523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/15/2018</th>\n",
       "      <td>0.644283</td>\n",
       "      <td>0.394698</td>\n",
       "      <td>0.748582</td>\n",
       "      <td>0.764019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/16/2018</th>\n",
       "      <td>0.662432</td>\n",
       "      <td>0.346890</td>\n",
       "      <td>0.735492</td>\n",
       "      <td>0.795561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/17/2018</th>\n",
       "      <td>0.649728</td>\n",
       "      <td>0.358672</td>\n",
       "      <td>0.770399</td>\n",
       "      <td>0.783879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/20/2018</th>\n",
       "      <td>0.645191</td>\n",
       "      <td>0.352781</td>\n",
       "      <td>0.778078</td>\n",
       "      <td>0.754673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/21/2018</th>\n",
       "      <td>0.584392</td>\n",
       "      <td>0.315056</td>\n",
       "      <td>0.819531</td>\n",
       "      <td>0.755841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/22/2018</th>\n",
       "      <td>0.548094</td>\n",
       "      <td>0.303274</td>\n",
       "      <td>0.889606</td>\n",
       "      <td>0.755841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/23/2018</th>\n",
       "      <td>0.558984</td>\n",
       "      <td>0.313923</td>\n",
       "      <td>0.902435</td>\n",
       "      <td>0.783879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/24/2018</th>\n",
       "      <td>0.537205</td>\n",
       "      <td>0.303727</td>\n",
       "      <td>0.906449</td>\n",
       "      <td>0.768692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/27/2018</th>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.268268</td>\n",
       "      <td>0.885767</td>\n",
       "      <td>0.792056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/28/2018</th>\n",
       "      <td>0.471869</td>\n",
       "      <td>0.327405</td>\n",
       "      <td>0.932978</td>\n",
       "      <td>0.783879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/29/2018</th>\n",
       "      <td>0.453721</td>\n",
       "      <td>0.354367</td>\n",
       "      <td>0.930535</td>\n",
       "      <td>0.835280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/30/2018</th>\n",
       "      <td>0.432849</td>\n",
       "      <td>0.380650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/31/2018</th>\n",
       "      <td>0.422868</td>\n",
       "      <td>0.393339</td>\n",
       "      <td>0.935771</td>\n",
       "      <td>0.890187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9/4/2018</th>\n",
       "      <td>0.472777</td>\n",
       "      <td>0.424380</td>\n",
       "      <td>0.960206</td>\n",
       "      <td>0.957944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9/5/2018</th>\n",
       "      <td>0.439201</td>\n",
       "      <td>0.441713</td>\n",
       "      <td>0.962737</td>\n",
       "      <td>0.977804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9/6/2018</th>\n",
       "      <td>0.408348</td>\n",
       "      <td>0.426759</td>\n",
       "      <td>0.951654</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9/7/2018</th>\n",
       "      <td>0.410163</td>\n",
       "      <td>0.392772</td>\n",
       "      <td>0.875905</td>\n",
       "      <td>0.981308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>577 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   DEXSZUS   DEXMXUS   DEXBZUS   DEXINUS\n",
       "observation_date                                        \n",
       "5/20/2016         0.624319  0.203807  0.421415  0.471963\n",
       "5/23/2016         0.623412  0.225105  0.453443  0.477804\n",
       "5/24/2016         0.633394  0.218874  0.432935  0.491822\n",
       "5/25/2016         0.613430  0.220347  0.481281  0.455607\n",
       "5/26/2016         0.604356  0.220347  0.455363  0.411215\n",
       "5/27/2016         0.620690  0.215362  0.485644  0.418224\n",
       "5/31/2016         0.637024  0.211963  0.481456  0.436916\n",
       "6/1/2016          0.598911  0.242438  0.477616  0.474299\n",
       "6/2/2016          0.607985  0.261584  0.473078  0.448598\n",
       "6/3/2016          0.498185  0.257052  0.416703  0.421729\n",
       "6/6/2016          0.442831  0.257505  0.395933  0.400701\n",
       "6/7/2016          0.391107  0.217175  0.353172  0.380841\n",
       "6/8/2016          0.328494  0.146709  0.280391  0.365654\n",
       "6/9/2016          0.369328  0.183754  0.294703  0.385514\n",
       "6/10/2016         0.362976  0.237567  0.326468  0.404206\n",
       "6/13/2016         0.390200  0.302934  0.352736  0.442757\n",
       "6/14/2016         0.370236  0.340093  0.384152  0.462617\n",
       "6/15/2016         0.376588  0.313923  0.362859  0.432243\n",
       "6/16/2016         0.390200  0.342132  0.383541  0.473131\n",
       "6/17/2016         0.343013  0.313583  0.326730  0.435748\n",
       "6/20/2016         0.348457  0.269287  0.294965  0.485981\n",
       "6/21/2016         0.330309  0.266795  0.303779  0.508178\n",
       "6/22/2016         0.319419  0.238473  0.282485  0.480140\n",
       "6/23/2016         0.303085  0.186587  0.251593  0.456776\n",
       "6/24/2016         0.426497  0.311997  0.291299  0.518692\n",
       "6/27/2016         0.503630  0.379404  0.302644  0.530374\n",
       "6/28/2016         0.526316  0.324572  0.219653  0.523364\n",
       "6/29/2016         0.509982  0.239719  0.159613  0.471963\n",
       "6/30/2016         0.508167  0.230203  0.126189  0.482477\n",
       "7/1/2016          0.451906  0.207432  0.165023  0.450935\n",
       "...                    ...       ...       ...       ...\n",
       "7/27/2018         0.642468  0.245157  0.573959  0.609813\n",
       "7/30/2018         0.592559  0.240172  0.582162  0.609813\n",
       "7/31/2018         0.601633  0.253880  0.601536  0.602804\n",
       "8/1/2018          0.627042  0.260111  0.608517  0.582944\n",
       "8/2/2018          0.645191  0.260451  0.610699  0.613318\n",
       "8/3/2018          0.629764  0.248102  0.573872  0.602804\n",
       "8/6/2018          0.663339  0.236547  0.580417  0.635514\n",
       "8/7/2018          0.646098  0.222273  0.573436  0.612150\n",
       "8/8/2018          0.645191  0.226691  0.600838  0.615654\n",
       "8/9/2018          0.611615  0.272573  0.663845  0.626168\n",
       "8/10/2018         0.655172  0.330917  0.696570  0.642523\n",
       "8/13/2018         0.637024  0.405121  0.747535  0.775701\n",
       "8/14/2018         0.633394  0.345871  0.723885  0.767523\n",
       "8/15/2018         0.644283  0.394698  0.748582  0.764019\n",
       "8/16/2018         0.662432  0.346890  0.735492  0.795561\n",
       "8/17/2018         0.649728  0.358672  0.770399  0.783879\n",
       "8/20/2018         0.645191  0.352781  0.778078  0.754673\n",
       "8/21/2018         0.584392  0.315056  0.819531  0.755841\n",
       "8/22/2018         0.548094  0.303274  0.889606  0.755841\n",
       "8/23/2018         0.558984  0.313923  0.902435  0.783879\n",
       "8/24/2018         0.537205  0.303727  0.906449  0.768692\n",
       "8/27/2018         0.517241  0.268268  0.885767  0.792056\n",
       "8/28/2018         0.471869  0.327405  0.932978  0.783879\n",
       "8/29/2018         0.453721  0.354367  0.930535  0.835280\n",
       "8/30/2018         0.432849  0.380650  1.000000  0.859813\n",
       "8/31/2018         0.422868  0.393339  0.935771  0.890187\n",
       "9/4/2018          0.472777  0.424380  0.960206  0.957944\n",
       "9/5/2018          0.439201  0.441713  0.962737  0.977804\n",
       "9/6/2018          0.408348  0.426759  0.951654  1.000000\n",
       "9/7/2018          0.410163  0.392772  0.875905  0.981308\n",
       "\n",
       "[577 rows x 4 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = percentage_difference(model, X_test, y_test)\n",
    "forex_df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-EwNP7yl7vG"
   },
   "outputs": [],
   "source": [
    "def denormalize(forex_df_norm, normalized_value): \n",
    "    stock_name = stock_name['DEXINUS'].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "    \n",
    "\n",
    "    #return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    a = min_max_scaler.fit_transform(stock_name)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YuNQP40zl7qT"
   },
   "outputs": [],
   "source": [
    "def plot_result(stock_name, normalized_value_p, normalized_value_y_test):\n",
    "    newp = denormalize(stock_name, normalized_value_p)\n",
    "    newy_test = denormalize(stock_name, normalized_value_y_test)\n",
    "    plt2.plot(newp, color='red', label='Prediction')\n",
    "    plt2.plot(newy_test,color='blue', label='Actual')\n",
    "    plt2.legend(loc='best')\n",
    "    plt2.title('The test result for {}'.format(forex_df_norm))\n",
    "    plt2.xlabel('Days')\n",
    "    plt2.ylabel('DEXINUS')\n",
    "    plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "OzhzjHgerQwP",
    "outputId": "f3cdebff-5556-421a-f4c5-ac629b475d54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00047 MSE (0.02 RMSE)\n",
      "Test Score: 0.00425 MSE (0.07 RMSE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0004657650448546142, 0.004248936152593656)"
      ]
     },
     "execution_count": 178,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]\n",
    "\n",
    "\n",
    "model_score(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "zhX_XhK7rQ0i",
    "outputId": "fe7245ee-d2a4-4197-abe8-d37cc191c8b9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3XmYjeUbwPHv+55t9hnDDLKViGxJ\nyb5ki1RkS8oue7vqV8gSQijSolJkX1IREdmyFIXsRNkqY4zZZ87+/v44GdssZzjLLPfnulxj5rzn\nee/zOOY+z65omqYhhBBCCJ9T/R2AEEIIUVhJEhZCCCH8RJKwEEII4SeShIUQQgg/kSQshBBC+Ikk\nYSGEEMJP9L6+YWxsskfLK1IkiPj4NI+WWZBJfblP6sp9Ulfuk7pyX0Gqq6io0Ex/nu9bwnq9zt8h\n5CtSX+6TunKf1JX7pK7cVxjqKt8nYSGEECK/kiQshBBC+IkkYSGEEMJPJAkLIYQQfiJJWAghhPAT\nScJCCCGEn0gSFkIIIfxEkvB//v33H1q2bMzQof0ZOrQ//fv3YsuWTbku56uvljB79iz++OMYs2fP\nyvK6bdu2YLPZiIu7yOTJ428ldCGEEPmUWztmHT9+nMGDB9OrVy+efvrpax7bsWMH06ZNQ6fT0bhx\nY4YMGeKVQH2hbNlyzJz5CQBJSYn07v0UdevWw2QKyHVZFStWomLFSlk+vnjxAmrVqk3RosV49dXh\nNx2zEEKI/CvHJJyWlsZbb71FvXr1Mn183LhxzJ49m+LFi/P000/z0EMPUaFCBY8H6mthYeEULVqM\nd955G4PBSFJSAmPHTmTy5PH888/f2O12+vUbyH331ebXX3cxY8ZUIiOLUrRoMW67rRR79vzKihVL\nGTduMmvXrmb58iUoikLXrk9hs9k4fPggw4Y9x//+N5IxY0Ywe/Y89uz5lU8++RC9Xk9UVDSvv/4m\nGzasY//+fSQkxHPmzGm6devOI4+093f1CCGE8IAck7DRaOTTTz/l008/veGxs2fPEh4eTsmSJQFo\n0qQJO3fuvKUkHDx6BKZV37j/BFUh0qlle4nl0fakjh6Xqzj+/fcfkpIScTqdhIWF8dprw1m7djVF\nixbj9dffJCEhgeefH8jcuYuZNWsmI0e+RcWKdzFs2HPcdlupjHLS0lKZM+cz5s5dhNVqY/z4UUyc\nOI3PPvuYKVNmkJiYkHHtlClv8+67H1C8eAmmTZvE+vVrURSFkydP8PHHn3Pu3FlGjXpDkrAQQnhJ\nTIzCjh062re3oyjev1+OSViv16PXZ35ZbGwskZGRGd9HRkZy9uzZbMsrUiQo+/1Ag4yg5u6V63K4\nPijISFAWm2dfZrEEc/bsaV56aTCapmEymZgy5R2WLFlC3br3ExUVyokTR/jtt984evQgAHa7jfBw\nEzEx56lf/z4AGjSoh8ViISIiCJPJQGLiBSpWrEDp0lEAzJ7t+jCj06kUKxaCTmdDr1cxGBzo9Tqq\nVasIQNOmjdi9ezdVqlShdu37KFEigtBQA+npqVluBO6uW31+YSJ15T6pK/dJXbnPl3WladChA2zb\nBo89BiVKeP+ePj9FKccTMV590/XHTVFRoe6dzJTDNZcupVKmTDmmTfvwmp+bzTbS0uzExiZjt0O3\nbj1p2bJ1xuOJiRZAyYghJcWM1WolISENi8VGYqIZs9l6Q4wOh5OLF1NITEzFbncSF5eK3e7IuC4u\nLgmz2U5yshmr1UlsbDJpaWk4HM5bOonK7foSUle5IHXlPqkr9/m6rpYv17NtWyAPP2xDpzMTG+u5\nsr1yilJ0dDQXL17M+D4mJobo6OhbKTJPq1KlGtu2bQEgPv4Ss2Z9AECxYlGcOXMKTdPYu/e3a55T\nrtztnDlzmrS0NCwWCy+84GppK4qKw+HIuC4sLAxFUTh//jwA+/btoXLlu330yoQQonBLSYExY0wE\nBGiMHWvx2X1vqSVcunRpUlJSOHfuHCVKlGDTpk1MmTLFU7HlOc2atWDPnt0MHNgHh8NBnz79Aejf\nfzAjRrxGiRIliY4ufs1zAgMD6dt3IC+8MBiAJ57ohqIo3HtvLQYP7svw4aMzrn311RGMGTMcnU5H\nqVKlad68FT/88L3PXp8QQhRWU6eaiIlRGTbMQtmy2c8z8iRF07Rs73bw4EEmTZrE33//jV6vp3jx\n4jRr1ozSpUvTsmVLdu/enZF4W7VqRd++fbO9oae7FqRrJ3ekvtwndeU+qSv3SV25z1d1deKEQpMm\nwZQoobFtWyqBgZ6/R1bd0Tm2hKtVq8a8efOyfLx27dosWbLk5iMTQggh/ETTYPjwAGw2hbFjzV5J\nwNmRHbOEEEIUWmvX6tm0SU+TJnYeftju8/tLEhZCCFEopafDyJEm9HqNCRMsPlkXfD1JwkIIIQql\nDz4wcuaMSv/+NipWdPolBknCQgghCp0zZxRmzDASHe3k5Zd9tyTpej7frEMIIYTwt1GjTJjNClOm\nmAn14wZm0hK+yvr1a2nSpA4JCQlZXnPixB+cOXM612V36vQoaWk57BYmhBDC67Zs0bF6tYHatR10\n7uz7yVhXkyR8lfXr11GqVGk2b96Q5TVbtmzk7NkzPoxKCCGEp1itMHy4CUXRmDjR7JfJWFeTJPyf\npKREjhw5xNChL7Jhww8AHD9+lAEDejNoUB8++GA6J0+e4NtvVzBr1kwOHz54Tet25sz3WLNmFamp\nKbz66gs8++wAnnmmJ4cPH/TnyxJCCHGVd981cvy4jp49bVSv7p/JWFfLc2PCo0ebWLXK/bBUFZzO\n4GyvefRRO6NHZz/wvnHjBurXb0idOvWYNGkcsbEXeO+9KbzyyhtUqFCRt956k+DgYOrUqUfTps2p\nUqVapuXExcXxyCPtady4Kb/9tpsFC+Yyfvw7br8eIYQQ3nHggMr06UZKlXIycqT/JmNdLc8lYX/Z\nsGEdPXv2RafT8eCDzfnxxx84c+Y0FSq4jhYcOXKsW+VERhZl7tzPWLRoHjabjYCAAG+GLYQQwg02\nGzz/fAB2u8LUqel+nYx1tTyXhEePtuTYar2aa2/R1Fu654ULMRw+fJCZM99DURTMZjOhoSGoava9\n9cpVgwl2u2twf+nShRQrFs3IkW9x9OhhZs5875ZiE0IIcevef9/IwYM6nnzSRrNmjpyf4CMyJoyr\nFfz4452ZO3cRc+YsZNGir0hKSqJcuds5dMg1pvv222M5deovFEXJOIIwKCiYuLiLOBwODh06AEBi\nYgKlSpUGYMuWTRnJWQghhH8cPqwydaqREiWcjB1r9nc418hzLWF/2LBhHSNGjMn4XlEU2rR5BKfT\nycyZ7wJQtWp1br/9Du65517ee+8dgoKC6NixC6+99iJly5bjjjvKA9C6dVvGjRvFpk0b6NixCxs2\n/MDq1Sv98rqEEKKws9td3dA2m8KUKemEh/s7omvleJShp8lRhv4l9eU+qSv3SV25T+rKfZ6oqxkz\njIwbZ6JTJxsffui/VnBWRxlKd7QQQogC6fhxlcmTjURFORk/Pm91Q18mSVgIIUSB43C4uqGtVoXJ\nky0UKeLviDInSVgIIUSBM2uWgd9+09G+vY22bfPuBFlJwkIIIQqUkycVJk40UayYkwkT8samHFmR\n2dFCCCEKlA8/NGI2K8yYYaZYMZ/OPc41aQkLIYQoUPbu1REQoPHII3m3G/oyScJCCCEKDIsFjh5V\nqVLFiT4f9PVKEhZCCFFgHDumYrcrVK+ed7amzI4kYSGEEAXG/v06gDxxTKE7JAkLIYQoMA4ccKW1\nGjWkJSyEEEL41P79OnQ6jcqVpSUshBBC+IzD4ToxqVIlJ/nlKHdJwkIIIQqEEydU0tMVatTIH61g\nkCQshBCigLg8HpxfZkaDJGEhhBAFRH6bGQ2ShIUQQhQQBw+qKIpGtWrSEhZCCCF8RtNcLeHy5TVC\nQvwdjfskCQshhMj3Tp9WSErKPztlXSZJWAghRL534ED+Gw8GScJCCCEKgPy2U9ZlkoSFEELke1da\nwpKEhRBCCJ/av1+ldGknkZH+jiR3JAkLIYTI12JiFGJj1Xy1NOkyScJCCCHytf37L48H569JWSBJ\nWAghRD6XX8eDQZKwEEKIfE5awkIIIYSfHDyoo1gxJyVKaP4OJdckCQshhMi34uPhzBmV6tWdKIq/\no8k9ScJCCCHyrYMHXePB+W2TjsskCQshhMi3Lo8H57ftKi+TJCyEECLfys8zo0GSsBBCiHzswAGV\n0FCNcuXy36QskCQshBAin0pJgRMnVKpXd6Dm02yWT8MWQghR2B0+rKJpSr4dDwY3k/CECRN44okn\n6Nq1K/v377/msQ0bNtCxY0eefPJJ5s+f75UghRBCiOvl9/FgcCMJ79q1i9OnT7NkyRLGjx/P+PHj\nMx5zOp289dZbfPrppyxYsIBNmzZx/vx5rwYshBBCwNVnCBfglvDOnTtp0aIFAHfeeSeJiYmkpKQA\nEB8fT1hYGJGRkaiqSt26ddmxY4d3IxZCCCGA/ft1BARoVKhQgJPwxYsXKVKkSMb3kZGRxMbGZvw9\nNTWVU6dOYbPZ+OWXX7h48aL3ohVCCCEAiwWOHVOpWtWJXu/vaG5erkPXtCvTwBVFYeLEibzxxhuE\nhoZSunTpHJ9fpEgQer0ut7fNVlRUqEfLK+ikvtwndeU+qSv3SV25L6u62rMHbDaoXVuXr+szxyQc\nHR19Tev2woULREVFZXz/wAMPsHDhQgCmTp1KqVKlsi0vPj7tZmPNVFRUKLGxyR4tsyCT+nKf1JX7\npK7cJ3XlvuzqautWAxBAxYpmYmNtvg3sJmT1QSHH7ugGDRqwbt06AA4dOkR0dDQhISEZj/fr14+4\nuDjS0tLYtGkT9erV81DIQgghROaubFeZf2dGgxst4Vq1alG1alW6du2KoiiMGjWKFStWEBoaSsuW\nLenSpQt9+vRBURT69+9PZGSkL+IWQghRiO3fr0Ov16hcOf9OygJQtKsHeX3A090w0rWTO1Jf7pO6\ncp/UlfukrtyXVV05HFC+fAjlyzvZtMmzQ5zectPd0UIIIUResn27jvR0hVq18ndXNEgSFkIIkc98\n+qkRgG7d8v6ErJxIEhZCCJFv/PWXwg8/6LjvPgf33Ze/x4NBkrAQQoh85PPPjWiaQr9+Vn+H4hGS\nhIUQQuQLKSmwcKGB4sWdPPqo3d/heIQkYSGEEPnCkiUGkpMVevWyYTT6OxrPkCQshBAiz3M64bPP\njBiNGj165P8JWZdJEhZCCJHnbdqk4+RJlccftxMV5dPtLbxKkrAQQog87/KypGeeKRgTsi6TJCyE\nECJP++MPlY0b9dSpY6dGjfy/LOlqkoSFEELkabNnGwDo37/gjAVfJklYCCFEnpWYCIsXGyhVykmb\nNgVjWdLVJAkLIYTIsxYtMpCWptC7tw19juf+5T+ShIUQQuRJDodrWVJgoMbTTxesCVmXSRIWQgiR\nJ61eDWfOqHTqZKOgHlUvSVgIIUSeNH2662vfvgVvQtZlkoSFEELkOUeOqGzcCI0a2alSpWAtS7qa\nJGEhhBB5zkcfuTbn6Nev4LaCQZKwEEKIPObYMZWlS/VUrQqtWhW8ZUlXkyQshBAiT5kwwYjTqTBh\nAuh0/o7GuyQJCyGEyDN271b5/nsDDzxg59FH/R2N90kSFkIIkSdoGowbZwJgxAgriuLngHxAkrAQ\nQog84ccfdezcqadVKzt16zr8HY5PSBIWQgjhd06nqxWsKBpvvGHxdzg+I0lYCCGE3331lZ7Dh3V0\n7lyw1wVfT5KwEEIIv7JYYNIkE0ajxmuvFZ5WMEgSFkII4WdffmngzBmV3r1tlCmj+Tscn5IkLIQQ\nwm9SUuDdd42EhGg8/3zBPCkpO5KEhRBC+M1HHxm5eFFl8GArxYoVrlYwSBIWQgjhJ7GxCh9+aKRY\nMScDBxa+VjBIEhZCCOEn771nJDVV4eWXrYSE+Dsa/5AkLIQQwudiYxXmzDFQrpyT7t0L9klJ2ZEk\nLIQQwue2btVhsyn06GHDaPR3NP4jSVgIIYTPbd/uOh6pUaOCfVRhTiQJCyGE8Llt2/SEhWlUr154\ndsfKjCRhIYQQPnXunMKpUyr169sL/HnBOZEkLIQQwqe2bXNl3gYNCsdJSdmRJCyEEMKntm/XA5KE\nQZKwEEIIH9I016SsyEhn3jwtyelEjTnvs9tJEhZCCOEzp04pnDunUr++AzUPZqCQYc8TeW8VlIsX\nfXK/PFgFQgghCqq83BVt2PQjgfPnYr+7KlqRIj65pyRhIYQQPnN5UlajRnksCaekEDrseTSdjpT3\nZuKraduShIUQQviEprmScHS0k4oV89Z4cPDEt9CdPUP60BewV7/HZ/eVJCyEEMInTpxQuXBBpUED\nB4ri72iu0O/+hcBPP8Z+ZwVSX37Np/eWJCyEEMInLndFN2yYh7qiLRZCXxyKomkkv/sBBAT49PaS\nhIUQQvjElU068s5+0UHvvoP++DHS+zyDvW49n99fkrAQQgivczphxw4dt93m5I47NH+HA4Du0EGC\nZkzDUao0qSNG+yUGScJCCCG87uhRlbi4PDQebLcT+uIQFLudlHfeRQsJ9UsYencumjBhAr///juK\novDGG29Qo0aNjMcWLFjAypUrUVWVatWqMXz4cK8FK4QQIn/Ka0cXBs76EMO+vZg7PYG1xUN+iyPH\nlvCuXbs4ffo0S5YsYfz48YwfPz7jsZSUFGbPns2CBQtYtGgRJ0+eZN++fV4NWAghRP7z009559AG\n9c+TBE8ah7NYMVLemujfWHK6YOfOnbRo0QKAO++8k8TERFJSUgAwGAwYDAbS0tKw2+2kp6cTHh7u\n3YiFEELkKw4H7Nypp2xZJ2XK+Hk8WNMIffk5FLOZlAnvoBUt6tdwckzCFy9epMhV23dFRkYSGxsL\ngMlkYsiQIbRo0YIHH3yQe+65hzvuuMN70QohhMh3Dh1SSUxU8kRXtH7XLxi3/4SlRSss7Tr4Oxz3\nxoSvpmlXPsWkpKQwa9Ys1q5dS0hICD179uTo0aNUrlw5y+cXKRKEXu/Z7cCiovwzoJ5fSX25T+rK\nfVJX7itsdbV3r+trmzZGoqKMuXqux+vqq4UAmF5/jajoMM+WfRNyTMLR0dFcvOo0iQsXLhAVFQXA\nyZMnKVOmDJGRkQDcf//9HDx4MNskHB+fdqsxXyMqKpTY2GSPllmQSX25T+rKfVJX7omLUzCZQggJ\nKVx1tW5dIKCnRo0UYmPd74729PtKSUqk6NKlOMvdzqWq94EP37NZfZjIsTu6QYMGrFu3DoBDhw4R\nHR1NSEgIAKVKleLkyZOYzWYADh48yO233+6hkIUQouDQNOjSJZC77oKlS3PdCZlv2Wywc6eOChUc\nlCjh3/Fg09dfoaSlYX6qB3nlHMUc3wm1atWiatWqdO3aFUVRGDVqFCtWrCA0NJSWLVvSt29fevTo\ngU6n49577+X+++/3RdxCCJGv/PyzjgMHXENxQ4cGcv68hWefteaNNbO34MgRldKlnYRm0Wv8++8q\nqalKnpgVHbBgLpqqYn6im79DyeDWx7Fhw4Zd8/3V3c1du3ala9euno1KCCEKmC++MADw8cfw1ltO\nxo0z8c8/CuPHW3x1ap7H/fSTjo4dg4iOdjJunIV27ew3fKi4fH6wv/eL1h08gGHfXiytWuMseZtf\nY7la3miPCyFEARYTo/Ddd3ruvttB//6wZk0ad9/t4PPPjfTtG0B6ur8jzD2HA95804SiaCQmKvTv\nH8iTTwZy6tS1WfjyftH16/s3CQcs/BIA81M9/RrH9SQJCyGEl82fb8BuV+jd24aiQMmSGqtWpdGg\ngZ01awx07hxIfLy/o8ydJUv0HDqk44kn7GzZkkqTJnY2btTTuHEwM2YYsdnAYoFdu3TcfbeDqCg/\njgenpxOwbAmO6OJYW7TyXxyZkCQshBBeZLfDl18aCAnR6NTJlvHzsDBYvDid9u1t7Nql59FHgzh7\nNn8MEKekwIQJJoKCNF5/3UL58hpLl6bz8cfphIRojBtnonnzID77zEB6uv/Hg01rVqEmJmB5ohsY\nDH6N5XqShIUQwovWrtXz778qXbrY+G9hSQaTCT7+2MzAgVaOH9fx8MNBnDjh20RstcLMmQaOHHE/\nHcycaeTCBZXBg62ULOlq4SoKdOhgZ8eOVLp3t3L0qI4xY1xn8/o7CQcsuNwV3d2vcWRGkrAQQnjR\n5QlZvXvbMn1cVWHsWAujRpmJiVEZN87ky/BYsMDA2LEBdOwYyOnTOX8A+OcfhY8+MlK8uJMhQ6w3\nPB4RAVOnWli1Ko3KlR0UK+b06/nB6l9/Yty2FWv9hjjKV/BbHFmRJCyEEF5y/LjKTz/padDATqVK\nzmyvHTzYRs2aDr7/Xs+ff/qmNWy3w4cfGlFVjYsXVbp1CyQhIfvnTJhgIj1dYfhwC8HBWV9Xp46D\nLVvS2LMnlYgIz8adGwGL5gO41gbnQZKEhRDCS+bMcbWC+/TJvBV8NUWBQYOsaJrCJ5/kbmvHm7Vq\nlZ7Tp1W6d7cxcKCVP/7Q0adPINYbG7gA7NunsnSpgWrVHHTpknPrVlEgIMDDQeeG3U7Aovk4w8Kx\nPNLOj4FkTZKwEEJ4QUoKLFlioEQJJ61bu9cd++ijdkqXdrJ4scHrs6U1DWbMcLWCBw+2Mnq0hYcf\ntrFtm56XXgpA0268ftQoV1f5mDGWvLLhVLaMP65HF3MeS8fOEBjo73AylQ+qUQghfOfECYX69YN4\n5x0jFsvNl/PVVwaSkxW6d7e5PSFXr4dnnrGSlqYwd653W8ObNuk4dEjHY4/ZueMODVWFDz80U6uW\ng6VLDUydeu39v/9ez86delq3ttGokf93v3JHwIK5AJifzltrg68mSVgIIa7yyy96TpzQ8c47Jpo2\nDWb79txvZ6VprglZOp1G9+45d0Vf7amnbISEaHz2meGWPgTk5P33XUn22Wev9D0HBcGXX6ZTtqyT\nyZNNLFvm2u3KaoUxY0zo9RpvvunFoDxIjTmPcf06bDVqYq9+j7/DyZIkYSGEuEpMjGtSVKNGdv78\nU+Hxx4N49tkA4uLcnyy1a5eOw4d1PPywPdeHFoSFwdNP27hwQeXrr71z0MOvv6ps367nwQftVK9+\n7YSx6GiNBQvSCQvTeOGFAHbs0PHFFwb++kulVy8bFSr49xAGd5mWLERxOPLshKzLJAkLIcRVLifh\nsWMtrFuXRo0aDpYsMdCgQRCLFulvGCvNzOVlSe5MyMpM//5WdDqNjz4yunW/3MqsFXy1SpWcfPFF\nOpoGvXoFMnWqifBwjWHD8kcrGE0jcP5ctIAALB06+TuabEkSFkKIq5w/70rCxYtr1KzpZO3aNN56\ny4zZrPD884E8/nggBw6oWSbHCxcUVq3SU6mS46b3Sy5dWuOxx+wcOaJj82bPnu5w/LjK998bqFXL\nke0mGo0aOZg2zUxCgkJCgsKLL1r47+j4PM+wYxu6U39hebQ9Wrgf10e5QZKwEEJc5cIFFb1eIzLS\nlWX1ehgwwMb27am0aWNjxw49zZsHU7NmMM8+G8CyZfqM1jO4Nr+w2RR69bLd0jGFgwa5WqkffeTZ\nCVoffHClFZxTfF272nn7bTMdOtjo2/fmWvW+piQmEDzydSBvT8i6TNE0b3R2ZC02Ntmj5UVFhXq8\nzIJM6st9UlfuK0h1VatWMJoGe/emZvr4+vU6li83sHWrjri4K+2Yu+920Lixg5Ur9SQlKezfn5Lp\nGbu5qat27QLZuVPP5s2pVKmS/WYf7vjnH4XatYMpV87Jtm1peX6ZUa7fV6mpRHRpj2H3L6R3703K\nlPfIKwc2R0VlfuCyd0b9hRAiH9I0V3dytWpZJ7yWLR20bOnA6YRDh1S2btWxZYuen3/WceSIq+u4\nZ09rlofc58agQVZ27tQza5aR6dPNt1zexx8bsdkUnn3WmucTcK5ZLIT36oZh9y+YO3QiZfK0PJOA\nsyNJWAgh/hMfD1arQnR0zq1OVYXq1Z1Ur+5kyBAbZjP8+quO/ftVunb1TNdtq1YO7rzTyVdf6Xnj\nDYXixW++4zI+3nWaU8mSTjp29N9ezl5htxM2oA/GLZuwPNSG5Pdngc6zY+neUtA+CwkhxE07f971\nK/Fmkl1AADRs6GDwYJvHJjCpKgwYYMVqVfj881s7gu/zz42kpSkMHGjF6JtdMX3D6ST0+cGY1qzC\n2qgJSZ/OzXPHFWZHkrAQQvzn8gSrW2lxelqXLjYiI53MmWMkNfNh6hylpcFnnxmIiMj95iF5mqYR\n8vowApYtxnbf/STOXeTnzapzT7qjhRDiP5eTcG432PCmoCDo1cvGtGkmliwx0KOHjbg4hdjYa/9c\nuqRgt2c+Bnr6tEJcnMpLL1luONM4PwueMJbALz7DXqUaiQuXkx9fnCRhIYT4z4ULl7ujb30msif1\n6WPjgw+MDB9u4vXXTWha7icchYRo9OtXcFrBgTPeJWj6VOzl7yRh6TdoRfLJIubrSBIWQoj/5MXu\naHBtJfnyy1aWL9dTrJhGsWIaUVFX/hQrplG0qDPbsd6SJV3XFQTGH74nZNwoHKVKk7h8JVp0tL9D\nummShIUQ4j9X75aV17zwgpUXXsjioN9CRI05T+jzg9FMJhLnL8VZuoy/Q7olkoSFEOI/MTEKqlpw\nWowFjtNJ6LMDUePiSBk/CUfVav6O6JbJ7GghhPhPTIxKVJSWX5aYFjqBn3yIcfNGLM1bkt5voL/D\n8QhJwkIIwZXdsvJiV7QA3YH9BI8bjbNYFMnTP8oXu2G5Q5KwEEIASUmQni5JOE9KSyNsUF8Uq5Xk\nGR/m64lY15MkLIQQuLqiIe8tTxIQMmo4+uPHSHtmINYWD/k7HI+SJCyEEOTd5UmFnfH71QTOnY39\n7qqkjhzr73A8TpKwEEIgSThP+ucfQl8cgmYykfTx7Hy3JaU7ZImSEEIgSTjPcTqhZ0/US5dIfvsd\nHHdX8XdEXiEtYSGE4OoTlGRMOC8ImjENNmzA0vIhzH36+zscr5EkLIQQuJYnQR5uCZvNqKf+AofD\n35F4nWnpIoInjIVSpUh+78MCsxwpM9IdLYQQXOmOjo7Oe0lY//NOwgb1Rff3ObTAQOx3VcZxdxXs\nd1fF/t9XLTq6QCQrw8YNhL5qePDBAAAgAElEQVQwBGd4BOq6dWhRUf4OyaskCQshBK4lSsWKOfPW\nefAOB0HTpxI0eQIAltZtUc+dRX/kEIbf915zqbNoURyly+IsXhxn8ZL/fS2Bs4Tr746SpdxO1OrZ\nMxh2bMOwczvGHdvQFIXU8ZO8vjxIv/c3wvt0B52OpHmLiahaFWKTvXpPf5MkLIQQuFrCZcvmnfFg\n9fy/hA7qh3H7TzhuK0Xyx7Ox1a3vetBuR/fnSfRHDqE7cgj94cPojh1Bf+wIynXJ+WpaYCCOMmVx\nlC2Hs9ztOMrejqPc7ThLlEB/9EhG4tWdPZPxHGdYOGp6GuHdOpPevRepY8ajhYR6/PXq/jxBeLdO\nYE4n6fP5V15rASdJWAhR6KWkQEpK3tkty7h+LaHPDUKNi8PSui3J0z+49rxcvR7HXZVw3FUJ2nW4\n8nNNQ0lKRI2JQT3/L2rMedffY/5F9/ffqGdOoztzCv3xY1ne21mkCJY2j2Cr3wBb/YbYq1RDd/QI\nYUP6EzhvDsYtm0l+/yNs9Rp47PUqMTGEd+mAGhdH8jvvYX34EY+VnddJEhZCFHqXJ2WVKOHnJGyx\nEDxuNEGzPkAzmUh+ewrmPs+4P9arKGjhETjCI1wJOqvLEhPQnTmNeuqU6+s/53CUvxNbvYY4Kt8N\n6rVzdh1VqxH/w2aCpkwkaMY0wts/TPqAIaS+8eYtr91VkpMIf7IjujOnSB32P8w9+9xSefmNJGEh\nRKGXF7asVP/9h7AeT2L4fS/2ChVJ+mQOjmrVvXIvLTwCe/UIqH6P+08yGkl7402sLR8i9NmBBH08\nE+OmDSTPnIX9nntvLhCLhbBeT2M4uJ/07r1Je+X1mysnH5MkLIQo9Py9UYd65jQRHR9Fd/oU5q5P\nkfz2FAgO9kssObHXrkP8j9sIGTeKwNmfENGmObaGjbFXq4G9ajXs1WrguLMC6DNPL0piArq//kR3\n6i9MXy3F+NNmLK3bkjJpaoGY3Z1bkoSFEIWeP5cn6f48QXjHx9D9fY7UYf9ztQbzejIKDibl7SlY\nWrclZPirGDdvxLh5Y8bDWkAA9sp3Y69WA2dUFLrTp9Gd/gvdX3+iXrp0TVG2B+qSNOvzLJN2QVc4\nX7UQQlzFX7tl6Y4cJqLTY6ixF0gZOZb0Z1/w6f1vla3Jg8Rv242SEI/+8CH0B/ejO3QQ/cED6A8f\nwrDvykxtzWDAUbYctlr347j9Dpx3lMdxR3msjZqCyeS/F+FnkoSFEIXe5ZawLydm6ffvI7xL+4y9\nkc19B/js3p6mRRTBVr8htvoNr/zQZkP3x3HUuIuuZVClSoNO578g8yhJwkKIQs/X3dH6Xb8Q/mRH\nlJRkkt/7AHO37j65r08ZDDiqVKXgb7J5ayQJCyEKvQsXFCIiNN+clLdxIxFd2oPFTPJHn2Hp0NkH\nNxV5lRzgIIQo9GJiVJ+MBxs2boC2bcFuI2n2PEnAQpKwEKJwS0+HhATF613R6t/nCOvfG4DELxcV\nql2hRNakO1oIUaj5ZLcsTSP0hSGoSYnwySfYmrX03r1EviItYSFEoXZlow7vdUcHzJmNccsmLM1b\nQr9+XruPyH/caglPmDCB33//HUVReOONN6hRowYAMTExDBs2LOO6s2fP8vLLL/Poo496J1ohhPCw\nK1tWeqclrP55kpAxI3BGRJDy7kxMeX0jDuFTOSbhXbt2cfr0aZYsWcLJkyd54403WLJkCQDFixdn\n3rx5ANjtdrp3706zZs28G7EQQnjQ5e5oryRhh4Ow5wahpKWRPO19nCVKev4eIl/LsTt6586dtGjR\nAoA777yTxMREUlJSbrju66+/5qGHHiI4j+53KoQQmTl/3ntjwoEfvo9h18+YH3scy+OdPF6+yP9y\nbAlfvHiRqlWrZnwfGRlJbGwsISEh11y3bNkyPv/88xxvWKRIEHq9Z3dNiYry/AHTBZnUl/ukrtyX\nX+sqMdH19e67g4iK8mDBBw7ApHFQvDgBsz8hoFhYxkP5ta78oaDXVa5nR2vajZ8W9+7dS/ny5W9I\nzJmJj0/L7S2zFRUVSmxsskfLLMikvtwndeW+/FxXp08HAnr0+mRiYz1UqNVKRLenMVitJE6dgVUz\nwX/1k5/rytcKUl1l9WEix+7o6OhoLl68mPH9hQsXiLru4+LmzZupV6/eLYYohBC+FxOjEBKiefTk\nwKBpk11n5HbrjrVVG88VLAqcHJNwgwYNWLduHQCHDh0iOjr6hhbvgQMHqFy5snciFEIIL7pwQfHo\npCz93t8Imj4VR5mypL71tsfKFQVTjt3RtWrVomrVqnTt2hVFURg1ahQrVqwgNDSUli1dC85jY2Mp\nWrSo14MVQghPslrh4kWVSpXsHilPd/IPQocOQHE4SJ7+IVpoWM5PEoWaW2PCV68FBm5o9a5atcpz\nEQkhhI/Ext768iQlOQnTt18TsGg+ht2/AJA2YDC2ho09EqMo2GTbSiFEoXXTRxg6nRi2bSVg8QJM\nq1eipKejKQrWJg9i7voUlvYdvRCtKIgkCQshCq0ru2W5v2WlcdW3hIx6A925swDY7yiPpetTmDt3\nxVm6jFfiFAWXJGEhRKF1Zd9oN1vCTiehr72IkpJC+lM9MD/xFPY6dUG2ohQ3SZKwEKLQyu1uWboj\nh1EvXsTcuSsp7870ZmiikJBTlIQQhVZu9402/rQZAGujJt4KSRQykoSFEIVWbseEDT9tAcDWuKm3\nQhKFjCRhIUShFROjEBioEerO9sQ2G4Yd27HfWQHnbaW8HpsoHCQJCyEKrZgY125Z7syr0u/5DTU1\nBZt0RQsPkiQshCiUHA7XZh3udkVnjAc3ftCLUYnCRpKwEKJQunhRwel0f99ow09b0BQFW4OGXo5M\nFCaShIUQhVKu1ginpmL4dRf2GjXRikR6OTJRmEgSFkIUSrlJwoZfdqLYbDIeLDxOkrAQolA6f979\n5UnG/5Ymyfpg4WmShIUQhVKuWsI/bUEzGrHVqeftsEQhI0lYCFEouZuElfhL6A/8ju3+ByAoyBeh\niUJEkrAQolC6koSz7442bPsJRdNkPFh4hSRhIUShdOGCitGoUaRI9tcZt24GwCpbVQovkFOUhMjE\nsWMqBoO/oxDedP68e7tlGX7ajDMkFPu99/kmMFGoSEtYiOucP6/QvHkQ3bv7OxLhLU6n6wSl6Ojs\nx4PVv8+h//MktvoNQC9tFuF5koQLEPXMafQ/77yp5xo2/Ujg9KkoiQkejir/2bBBj9Wq8N138Ndf\nclh7QXTpkoLdnvOWlRmnJsl4sPASScIFhdNJeNcOFHnsIQI/+TBXTzV+t5Lwbp0IGT+GyDo1CZg9\nC2w2LwWa9/34oy7j73PmGP0YifAWd2dGZ4wHN2rq5YhEYSVJuIAwbliH/sQfAISM+B+BH81073lr\nviOsfy+0gEDSBj0LVhuhr79CkcZ1MH6/GjT39tUtKKxW2LJFT9myTqKjYdEiA+np/o5KeNrlJFyi\nRDbvb03D8NMWnMWicNxdxUeRicJGknABEfjxBwAkzp6Ho0RJQka9QeDM6dk+x7h2DWH9eoDRROKi\nr0gdM55Lv+wjvXc/dKf+Irznk4S3fxj9vj2+eAl5wq5dOlJSFFq1stOvHyQkKHzzjefGAvftU5k6\n1YjZ7LEixU1wZ3mS7o/j6GLOY23UGLfOOhTiJkgSLgB0B/Zj3LYVa+MHsT7ajoRv1uC4rRQhY0cS\nOH1qps8x/vA9YX27g9FI4qLl2Ou6dgLSoqJImTSN+K2/YHmoDcad2ynSqimhg/qhO3bUly/LL378\n0ZVwW7SwM2AAqKrGF194pkt67Vod7doFMWmSic8/l6nX/hQTc3nLyqxbwob/ji60SVe08CJJwgVA\n0H9jwOkDBwPgLH8nCV+vxlGqNCHjxxA0bfI11xs3rCOsT3cwGEhcuBxbvQY3lOmoeBdJ85aQsOI7\nbDVqEvDVUiIbPUBE25YELJwHKSnef2F+8OOPOgICNOrVc1C2LLRqZWffPh179tzaf5W5cw306hWI\nokBwsMbMmcaCWoX5wuWWcHazo41bZb9o4X2ShPM5NeY8phXLsFeoiLVZy4yfO+8o72oRlylL8MRx\nBL3zNn/+qWBZuY6wXk+BTkfi/KXY6md/NqqtYWMSfthM4ux5WB9sjv7XXYS+MISi1e8i5OXn0O/5\ntcCMG587p3D0qI6GDR0EBrp+1qePa4LazbaGNQ0mTjTyyisBFCmisWJFGoMGWbl4UeXzz2XSl7/k\nODHLbsew/Scc5W7HWe523wUmCh1JwvlcwBefothspA8YAuq1/5zOcre7EnHZ29n7zlbq1Q2ibvvi\nnFZuJ3HeEmwNG7t3E1XF+mg7Epd8zaVfD5D6yutoRYoQOG8ORVo3o0jT+gR+8iFKXJznX6APXe6K\nbt7cnvGzxo0dlC/v5Jtv9Fy6lLvybDZ44YUApk0zUa6ck9Wr06hVy8nAgVYiIjQ++MBIcrInX4Fw\n1/nzKjqdRrFimSdh/f59qEmJskuW8DpJwvlZejqBc2bjLFIEc+eumV7iLFOWhG9WMzvkeTRU9mk1\nud+4n01q85u6pbNMWdJeeZ1Lu/eTsHgFlkfboztxnJAR/6NojbsI6/00xnXfg92ec2F5zOWlSVcn\nYVWFXr2sWCwKCxe6P46bkgI9egSyaJGBmjUdrF6dRvnyrl/4YWEweLCV+HiFTz6R1rCvbdig47ff\nVO66y3n959YMsj5Y+Iok4XwsYNli1EuXSO/ZN9vTXVIiy7Bc60CZoFg+fP4YSWYjnTsHMmuW4eZ7\nknU6bM1akDT7S+J+P0bK2Ak4KtyFafVKwrs/QdF7KhM8ekS+mcxlscDWrXoqVHBw++3XVkrXrjYC\nAzXmzDHizPnoWWJjFTp0COLHH/U0b25nxYq0G8Ye+/WzEhnp5KOPjCTI/ig+8+efCgMHBmI0wvTp\nWU9RzxgPbihJWHiXJOH8StMI/ORDNIMBc59nsr103To9Kak6OjwTxqD3KrFiRTqRkRojRwYwdGjA\nLa+D1YoVI33gUOI37yB+w1bS+/YHu42gD2e4JnM91JSQl58jeOybBM6YRsDczzF98xWGTT+i3/sb\nSnwu+3m9YOdOHWlpCs2bO254LCICOnSwceaMysaNukyefcWffyq0bRvEvn06nnzSxpdfphMScuN1\nISEwdKiVpCSFjz/+rzWsaahnTqPExHjiJYnrpKRAz56BJCUpTJlipmbNLD5Rmc0Ydv+MvUo1tGLF\nfBukKHRkM9R8yrBpA/rjxzB37oqzRMlsr12+3NWN2rmzHTBRp46DDRvS6NMnkGXLDBw/rvLFF+mU\nLn2LE6wUBXuNmqTUqEnK6PEY160hYPECjBs3YNib9VpjLTCQxDkLsT14c13knpDZePDVeve2sWCB\nkS++MNKiReafWvbsUXnqqUDi4lReesnCa69Zs11e2qePjY8+NPDJByovnnudkj9/h+7MaQAcJW/D\nfk9N7Pfci73mvdhq3IsWFXVrLzIPWrlSj14PDz/s3eELpxOGDg3g2DEd/ftbeeKJrO9nWrMKxWyW\nWdHCJxRN8+3U1thYz85EiYoK9XiZ3nT4sMqgQQGMH2+hYcMbW13uCu/cDuOWTcT/+BP26vdkeV1s\nrEKNGsFUq+Zk/fq0a+rLYoHXXjOxcKGRYsWcfPaZmfr1bz6mrCiJCagXLqAkxKMmJqAkJLh+lpiI\nEneRwHlzQNNInLsQ21UzvH2pfv0g/vlH5dixFEwm18+uf2+1aRPEnj0qu3alUq7ctf9t1q/X8cwz\ngZjNMGmShZ49s9j2U9Mw/LwDw+YfMW7eyMy9jXmJd3mNiUwIn4StQSNw2NH/vg/d+X+veaqjVGns\n99yL7f4HsNWug/2emhAQ4MlquGk38/8wNlahZs1gFAW2bUu9YRjAk6ZNMzJxookGDewsXZqe5QlZ\n+r2/EfF4W9A04r/fiKNKVY/Hkt9+Z/lTQaqrqKjQTH8uLWEfcjjgpZcCOHJEx+zZhptOwrojhzFu\n2YS1QaNsEzDAN9/ocTgUOne+MSmYTPDuuxZq1HAyYoSJLl0C+fbbNO67z42Bz1zQwiNwhEdk+bi1\nZWvCe3QlvMeTJM1ZgLXFQx69f05OnVI4cUJH69a2jAScmd69rfz2WyBz5xp4801rxs8XLDAwbJgJ\noxHmzEmndess/l01jdChAwhYttj1rV5PnwfCeOdwEu/bXqHHtkFEFb8yQqTGnEf/+170+/ai/30v\nhn17Ma1ZhWnNKtfzDQbsNWpiq10HW+0HsNeuk2OvSF6yZIkem83VVTBunInPPvPONmI//KBj0iQj\npUs7+fRTc5YJWD19ivCnuoDZTNKchV5JwEJcT8aEfWjOHAN79rjGFDdu1JOWlrvnnz2r0LRpEJve\n3A7gWpaUg+XLDeh0Gu3bZ979piiubtF589Kx26F378CMNZS+YmvajMT5S0GnI6zXUxh/+N6n97/c\nFd2sWfYfih57zE7Rok4WLjRgNrvWAE+ZYuTFFwMID9dYvjwt6wQMBE2eQMCyxdhq3kvi/CXEHT+N\n9buVPDfcSJpFx/sfBF5zvbN4Cayt2pD26hskLVhG3ME/iNtziKRPviCt/yDs1aqj/30vQR/PJLxv\nD4rWqEREm2YYNm7I82u3nU6YN89IQIBG9eoOVq40sGuX538dnTihMGhQICaT6wNSVkuSlPhLhD/Z\nEfViLCnjJ2Nt/bDHYxEiM5KEfeT8eYXx402Eh2t062YlPV1h06bcdUQsWGDg8GEdL2zpQlK5Klhb\ntc72+hMnFPbu1dG0qSPHc1ObN3cwfLiV8+dV+vYNwGrN9vJrbN+uY8aMW5vla2vclMQFy1yJuPfT\nGNeuufnCcimn8eDLAgKgWzcbly6prFihZ9gwE5Mnmyhb1sl336VRu3bWPQimJQsJnjoJR9nbSVyw\nHGurNmghru6pp5+2UaqUkzlzDJw/n80HIEXBWboMlvYdSR03iYR1m7l44hwJ335PyojRWJs2w/Db\nr0R07UDEow9lLLPJi7Zt0/HXXyqPPWbn7bddLeA33wxwa/a5u5KTXROxkpMVpk0zU6NG1hOxwns8\nif7EH6QNeR5z3/6eC0KIHEgS9pERI0ykpCiMHGmhVy9X1/Dq1dclYZuNsB5PUrRSOcI7tSN43GiM\n361E/fscmlNjxQpXP9o5SjOl0qwbNue43rJllydkuXcs4dChVtq3t7Frl54RI7Lpl73KokV6OnUK\nZNw4Ew88EML77xtvera1rWFjEhd9BQYDYX27Y1zz3c0VlAvp6a6EULmygzJlcm499uxpQ1E0hg0L\nYN48I9Wru9YAV6iQzR7E238i9KVncYZHkLho+Q0TrEwmeOklK2azwowZuVw3HBSErV4D0p97icSl\n33Dpx21YWrfFsOtnIjo+SvjjbTH8vCN3ZfrAvHmu92aPHlYeeMBJu3Y29uzReeywDKcThgwJ4I8/\ndAwYYKVTpyw+YDmdhD43EMMvOzG360DqyDEeub8Q7pIk7AMbNuhYudJA7doOnn7axj33OCld2skP\nP+ivtDg1jZBXXsC01nV8oHHrJoJmTCO8z9MUvbcKf1bqzKlTKm0Na4lSYpm2vX623cZOp6srOjhY\no3Vr92aeKgq8+66ZKlUczJljZP78rDen0DTXZJfnnw8kLAyee84CwFtvmahbN5j58w03tV+HrX7D\n/xKxkbB+PTB+tzL3heTCzp06zGYlx67oy8qW1WjZ0oHdrtCkiZ1vv03L9hAA3R/HXduEAklzFuCo\neFem13XtaqNsWSdffmng779vfjjAUb0GSV8uIv6HzVhatMK4/SciHmtNeOd26Hf/ctPlelJsrMKa\nNXoqV3Zk9B6MGGHBaNQYN850y0vmUlKgf/8A1q410KiRnVGjLFleGzxuNAHfrMBWpx7J73+c4wdb\nITxN3nFelpoKr70WgF6vMWWKGVV1Jbu2be0kJSls2+YaIw569x0CF87Dds+9xO05zMXjp0lYvpKU\nEaOxPNKORY4uAAy0zWRE062kpqpMnpx1q2nXLh1nz6o88og9u308bhAcDHPnplOkiMb//mfi119v\nfIvY7fDKKyYmTjRRpoyT1atTGTHCyu7dKTz3nIWEBIWXXgqgceMgVq3S53p40lavAQmLV6CZAgh7\npiemxQtyV0AubNhw5dQkd02damb69HQWLMh8DfBlSmws4U92Qk1MIHna+66Zz1kwGGDYMAtWq8LQ\noQH88cet/de016xF0sLlxK9ej7XJgxi3bKJI25aEd26HYef2Wyr7Vi1aZMBmU+jRw5axhKtcOY1n\nnrFx7pzKp5/e/C5if/3lWqe9cqWBunXtfPppOvosGtcBsz8haOZ72CtUJPHLRXlmprkoXCQJe9nU\nqUbOnlUZPNjK3XdfGZNq29b1S3/1ar1rvHDiOBxlyromKIWEoEUUwda4KenPvUT8p/NYHNSbIuEO\nHvjqOTp/0ZRKlRwsWGDg0KHM/wmXLXP95nG3K/pq5cppfPJJ5hO10tKgT58AvvzSSLVqDtasudIV\nGx4OI0ZY+eWXVHr0sPLXXyp9+wbSpk0Qx47l7q1mr1uPxCVfowUFE/bcIEKfG+T6RONBmgbr1+sJ\nCdF44AH3Z6qXWzubIRMrEPnKYAwb17s2ib5eejrhPbqiO3OK1GH/w/JEtxzL7dTJTuPGdrZv19Oo\nURAvvWTin39ubZKcvXYdEpd9S8LKtVgbNcW4ZRMR7doQ3q4Nhs0bfT6By+mE+fMNBARoN7w3X3jB\nQtGiTt57z0hsbO5f98aNOh56KJgjR3T07Wvlq6/SiYzM/Frj2jWEDH8VZ7EoEhcuRyuSxYVCeJkk\nYS86dEjlo4+MlC3r5KWXrp3pVLu2g2LFnKxdqRH0wnP/jRd+hVa8+A3lbN+u48IFlUfbOVAa1UMf\nZGT0aAtOp8Lo0aYbfo+azfDttwZKlnTSoMHNLYNq0sTByJEWYmJU+vQJxGqFuDiFjh2DWLvWQOPG\nWXfFliihMWWKhW3bUnnsMddY3zPP5G6yF4D9gTrEr9/iOkpx8QKKtGqC7tDBm3o9mfnzT4XTp1Ua\nN7ZjdLPxpVyKI3jsm+j+/YfARfOJ6NqRolXvJOSFIa5ZyTYbOJ2EDR2A4bfdmDs9Qdorr7tVtl4P\ny5alM2dOOhUqOJk/30jdusGMGWMiPv4WXihgq1ufxK9WEr96vaubeud2Irq0J+Lh5q7Z6D5Kxj/9\npOPUKZV27eyEh1/7WHg4DBtmJSVFybaX53qaBjNmGOnWLZC0NJg+PZ2337ZkvRZ41y+EDegNJhOJ\nC5bivP2OW3hFQtwaScJe4nTCsGEBOBwKkyebb+gS1umgbb1YYhNN7FAakDR3IY67KmVa1ooVrlZt\nx45XukybNXPQtKmdLVv0N2yluH69nqQkhQ4d7Oiy32UxW4MH2+jQwcbu3Tqeey6ARx4J4rffdHTq\nZGPhwnRCM197nuHOOzU++8xMz55Wjh7V8dFHue9mdJa/k4TV60nrPwj9H8cp0qYZAV9+4ZGkcXlW\ndIsW7n9QCXp3CmpyEiljJxD/nSsuLSCQwIXziOjagaLVKhD+eFtMq77BWq8Bye/OJNtts66jKK7d\nozZvTuO991zbi37wgZEHHghhxgxjrpe1Xc9eu46rm3rDViwPP4rht18Jf/oJIpo3wvTNV5m36j3o\nyy+vTMjKTI8eNipWdDBvnoGjR3P+9ZSa6hr/HTfORPHiGitXpvHkk1kPLeiOHSX86c5gtZL02Vzs\n9953cy9ECA+RHbO8ZM4cA6++GkD79jY++eTGTQjU8//yy4NjaRs3n0EPHmTMknKZlmM2Q7VqIYSE\naOzZk3rNvJHDh1WaNQuiQgUnmzenZYx99ejhmpSyeXMqVapcuywjt/WVlgaPPBLEwYOubP7ssxaG\nD7fmav5KYiLUrx9McrLC1q03vzOS8fvVhD4/CDUhAXO7DqRMnY4WFp7zE7PQpUsgmzfr+f33FEqW\nvDGm6+tKPXOayPr34SxRkkvbfyVjZw+nE/2uXzCt+hrTym/QxZzHfmcFEtZsuOVuzvR0+PxzA9On\nm0hIUChe3MmwYVa6dbNl2dLLDd3hQwRNn4LpmxUomoaj5G2Ye/YhvXvvXG2T6c776sIF1w5ZFSu6\n3q9ZfTZZv17HU08F0ayZncWLs56l9ccfKv36uTa/qVPHzmefmbOdJKf+fY6Iti3R/fM3STM+wtL1\nKbdem6fl1d9ZeVFBqqusdsySlrAXxMQojBtnIixM4623bpyZqaQkE/ZUF1rELSXcZGbl8SpZNux+\n/NHVqm3f3n5D4qtSxclTT9k4flyXseTj0iXXc6pWddyQgG9GUJBrk4OGDe1MmmRm5MjcJWBwdTOO\nG2fBbFZ47bWAm27EWtu0JX7jdmy16xDw7QqKNG+Efl/We1JnJzUVduzQUaWKI9MEnJngt99CsVpJ\n/d8IrtlaS1Wx161H6vjJXPr9KPHrNpGwer1HxhkDA2HIEBu7d6fw/PMWkpIUXnklgMaNg1m5MveT\n3q7nqFKV5FlfEL/jV9L6DUBJTiZ44jiK3ns3oUMH3HT9ZmbxYgN2+7UTsjLTooWDRo3sbNx4bS9P\nUhKsWaPnf/8zUb9+EA0auMZ/e/Vyjf9ml4CV+EuEP/E4un/+JmXkWL8lYCGuJ0nYC8aONZGUpDB8\nuOXGXwx2O6HP9MJw4Hcc3Z+m1WMqf/+t8vvvmf9TfP315a7ozLsJX33VSnCwxuTJRpKSXGPBNlvm\n21TerLJlNVasSKd375svs317Ow8+aGfTJv0trQV1li5DwjdrSHv+ZdQzp4l4uAVBE8e5NsLOhe3b\ndVitituzovUHfifgq6XYqt+DpUPnrC9UVez33ocWWTRX8eQkPByGD7eya1cqPXtaOXVKoV+/QB56\nKIitW29hzOE/jjsrkjrhHS79foTkt9/BUbYcAUsXUaRVUyLaNMf09XIy20lD0+Dll0306+daGpQV\n1w5ZBgIDNTp1yv59pHLBBh8AABuTSURBVCgwZowFRdEYNcrExIlG2rQJ4q67QujVK5DPPzfyzz8q\nLVu6Zj9PnmzJfkw/LY3wp7qgP36MtAFDSB/6vJu1IoT3SRL2sIQE+PZbPZUqOTLdxN+0fAmmH9dj\nad6SlElTadvWNR55w8YduHb8+eEHPRUrOqhWLfNWbfHiGs8/byUuTmX6dCPLlhlQVY0OHbx7Kk1u\nKQpMmmQmIEBjxAgTiYm3UJjBQOrwUSQu+Rpn8RIET5tMkeYNc7UO9vLGJ5kdXZiZ4LFvArg2c/Dj\nWtLixTXeecfC9u2ptGtnY98+HZ06BdG5c2CWH+RyQwsNw9x3APHbdpOweAWWlg+h3/MrYQP6EPLi\nUNcG6FfZvVtl3jwjs2e7Drj488/Mm7hbt+o4fTrzCVmZqVbNyZNP2jh2TMe0aSb27VO57z4nL79s\nYeXKNI4fT2HBgnTatcvhfW6zEfZMTwy/7sLcoTOpY8bnaoxeCG+TJOxhq1cbsFoVOne+sfsYIHDO\nZ2iKQsrkd0Gvp2lTO0FBGt99Z7iha3HNGj1ms2uCVXa/NwYMsFKqlJOPPzby6686GjVyUKJE3ts7\n+PbbNV5+2UpsrMq4ce7tyJWdeedb8XCl4/zb7Vn0x48R8Ugrgke8luNSpn37VFasMFCtmoM6dXJO\nwobNG10HZjR5EFvTZrcctyeUL6/x6adm1q9PpUkT1wS9li2Duf/+rP80aRLEl1+6uYmKqmJr1oKk\nBcu4tHMPtpr3ErhoPqED+nD1NPfLa3rbtoVjx1xLhDI7czmnCVmZGT3awuuvW/jyyzSOHUth9eo0\nXnvNSt26Dvdms2saoS8/h2n9OqxNm5E84yPZjEPkOfKO9LDLM5kff/zGVrB+/z4Me37D2vIhnGXK\nAq4x12bN7Jw8qXL8uHpdWYYsy7paYCAMH27JOJHGk13RnjZokJXKlR3MnWtk9//bu/M4G+v+8eOv\n62xzZl9sNxVFufGtaLFliSxFlETNUHLThOEut6ZIamSbIcpSPztpEO4RyU+GsrRwE9/vN2skDIXM\nDM6Ysy/X94+LYZgNM84s7+fjMQ+POec61/mct2vO+/p8rs/1ef9884ffnj063nzTzIZNgYw0TebC\nmvV4a9chaM5Moh5vhnHr5jxfp6qQkKCdAHzwgbPw72Sfj+CxCQBY3x9z0+0tKQ0b+vj3v+2kpNho\n3tyD10u+P0eP6oiPN9OqVfANLaLiq10Hy8qvcTVvgXnNKsJeiQGbjVOnFNauNdCggZevv4bp0+04\nHBATE8j06aac/f/1l8L69dp2N1KhKyIC/vUvF0895SUs7MZjEzz+A8zLluB+6GEsCxZT5PvQhLiN\nJAkXozNntBWwmjTx5LkOsXnRAgAcffvnevzqhTsuS09X+P57PQ8/7KV27cK/Lbt39/Doo14iI9US\nL5B+K0wm+PBD7fptfLz5pu6IsdshLs6M263NFl60yMh2Q0vOb96mXSv+8w8iej5LyNDBKJbcVSXW\nrTOwfbuBp55y06pV4b3ggFUpGPf+guP5FwotG+lPrVt7+eorO//zP9Z8f3btunI9uX//G7uerIaG\nYfliJa4n2hPw3UbCY55n4WwVr1chNlabaBUd7WHNGhvVq2vLT8bGmsnOvjIh6+WXC56QVWyyswl5\n83WCpn+Ep3YdLEtSKHBpMyH8qEhJeMKECbz44otER0ezZ8+eXM+dPn2amJgYevTowfvvv18ijSxQ\ncZZduUWrVxtQVSXP67FKlgXzyhV4a9bC1bZ9ruc6dPBgNKq5kvCaNVod4MJ6wZfpdLBihY0ffrCW\n+u+bpk29vPyyi4MH9cyadeO9k7FjAzh8WM+rr7qYO9eBqipaQtebsb6bwIXUzbjvf1C7d7djG/RH\nfgO0UdQxYwIwGFTef78IE7mcToITx6KaTNqM6DLu6uvJ3brlvp68Z08RvgqCgrB8vgxn1254t+9m\n8RwPURFeune/cow+9JCPDRtsNGvmYc0aI08/HcSiRUaCgq5fIaskGHb/TGS7lgQmf4anwf1YVqxG\nrVy5xN9XiJtV6F/ezp07SUtLY/ny5YwfP57x48fnej4pKYl+/fqRkpKCXq/n1KlTJdbYaxl+3gFR\nUdrMzVLgyy+12r3PPHN9Eg749zIUmw37y325dgWNsDCtJ7N3r560NCVnX4qSfx3gvISEUGjJwtJi\n1CgnlSv7mDzZlPOZi2LTJj3z5pmoW1db0atZMy+9e7s4cEDP7Nna8L3nwUZcSN2M7fVhGI4dJaJT\nO4zfb2HhQiPHjuno29ddYNWjHDNnoj+Rhv0fr+KrdfdNftLSp3ZtlTlzcl9Pbt8+mDFjinBCZDKR\nNXsBixpPJ9MbSax+PsFZZ3JtUrWqysqVdvr31060/vhDR7du7psaUi4yj4egyUlEdOmI/vgxbIPf\n4HzqZnw1877/XojSotAkvH37dtq313puderUwWKxkH3pXgSfz8fu3bt54gltskpCQgI1atQowebm\n5qteQ5t88UZcsd7PeDOOHlX43//VavdeVzhcVQn8bD6q0YijV588X9+li5Zs160zkJam8PPPelq2\n9BZ472NZFhkJY8Y4sdsV3n67aMPSmZkKr79uxmhUmTnTQWCg9vj7719O6AGcOHEpoRuNWEeNJmvG\nLBSbFe8L/ZgyAcLDVeLjC+8FK1kWGDcOX2gYtqFv3cInLb2uvp5cp46PTz4JyHNS1bVUvYEZ1n7o\nFS9DMscQ0fVJ2LkTJTMzZ2TKaITERCfTp9t55BEvgwffRC9YVdH/ehAlI6PAzXTHjhLR9UmCJ03A\nV+1vWFZ+jTVhbO57uYUopQpNwhkZGURGRub8HhUVRXp6OgDnzp0jODiYxMREYmJimDJlSsm1NA++\nO++CL74Ap5OwV3qh++tM4S8qIQVNojL+ZxuGQ7/i7PJMvqsQPfmkB51OmyW9erW2r/zuDS4vnn/e\nw+OPa/cOP/NMEMeO5d8jVlWIjw/g7Fkdw4e7eOCBK5chIiO1SVY2m8I77+ReDMT5Yi8urFzLGNNY\nLtjNDK+/iqjwwq8FB82YCpmZ2F7/F2ql4r3nt7Rp3dp7qdqQyrBhZi4WskDRtm16DhzQ06Wrj8hh\nvdAfPwZNm1K5/j1UrhFFpQZ1iGzdlPDuXYj97iW+b/YmdcNv8G/T7SZ00KtEtW5K5Qa1iWpYj7De\nPQlKHIPp69Xojh0Fnw/z0mSi2rbQ1unu3oPzW7bhbtn65oMhxO2mFmLUqFHqxo0bc36Pjo5Wjx49\nqqqqqp49e1Zt2LChmpaWpno8HrVfv37q5s2bC9yf2+0p7C1v3MSJqgqq2ry5qjocxb//Qvh8qvr3\nv6uq2ayqWVl5bBAdrbVv69YC99OmjbZZrVqqajKp6vnzJdLcUuXCBVXt3Vv73CEhqvrZZ1o8r7Vg\ngbZN69aq6snjEPL5VLVdO22blJTczx06pKoGg0+tbUxTHZhUtXNnVbVYcm/k9arqzp2q+sEHqtq0\nqaoqiqrecYeqWq3F92FLuYQELX6vvVbwds89p23300+XHli6VFUHDNCeaNlSVevWVdWICG2jyz81\na6rqnj1Fa4jdrqpdu2qve/hhVe3SRfu/uHp/oKqBgdq/4eGqumTJrXx0Ifym0KWLqlatSsZVw0Fn\nz56lyqXeXGRkJDVq1KBmTe12m+bNm/Pbb7/Rpk2bfPd3/vwtrkB/jSpVQknvO5DQnbsxr1yB/R+v\nkj3109t6Q/6ePToOHQrm2WfdOBwOHFctFa2kp1Np5Uq89epzvl4jKGAd1I4djWzZYiYtDTp1cuN2\nO7g06FBsSuNarB9/DC1aGBg+3EzfvgqrVrn58EMHERHa88ePK/zzn8GEhsLHH1s5dy7vIfpx4xR+\n/DGYIUNUHnrImlNgYuhQMx6PkVGfBKN82RrWrcPTrDlZn8zBcOQwpu82Ytq0Ed2l41zV63E3ewzT\nxETSrV6wlq54lZTYWFixIog5c/R07GijdevrRwxOnFD46qtgGjb0ce+9Nu34bN+FKjEx1x9XLhe6\nc5mYFy/Shoofa8HFuQtxteuYbxuU7IuE9YnB9OP3uNo8gWXhEq3INaBkZGDYvxfDvr0Y9v6C4cA+\nvDVrkZ04Wbvlr5Qd1/kpjX+DpVV5itVNrx3dokULUlNTAdi/fz9Vq1Yl5NL0W4PBwF133cXx48dz\nnr/nHj+UBVMUrWj6pQUFAufOvK1vv3KlNnyc16xo8xfJKG439lf6FXpi0KnTlddfXTGpIujRw8Om\nTVYaN/by1VdG2rYNZts2PR4PDB4ciNWqkJTkyPPWr8vq1NFWDztzRkdionY9cNs2Pd98Y6RpUw9P\n9zRhWbwCW+xADAcPENWuJWED+mFe8QWqTo895iUs8z8n89djWL76Blq1ul0fv1QwmWD6dAd6vTYs\nndcylAsWmPD5FGJjXYWf55pM+P5WHVv8CLLmLERxuwjr/QLm+bPz3Fw5l0n4810x/fg9zqefwZK8\nPCcBA6iVK+N+vC32wa9zcdZ8zn+/g6zFK3LuuReiLCpSFaXJkyeza9cuFEUhISGBAwcOEBoaSocO\nHUhLS2PEiBGoqkrdunUZPXo0ugJWQCjJKkq6U38S2eFxlMwMLMu+vC2rG/l88NBDwdhsCvv2Zeee\nC+L1EtW0EbqMdDL3HCpSxZ9u3QI5dEjHf/+3NWfiUXEq7WeWHg9MnWpiyhQTPh80a+Zl+3YD3bq5\nmT3bUegXv9MJbdsG8fvvOtatszF8uJk9e/SsX2/l4YevXEc2L/kc0zdr8TzaBFe7Dnj+64HrVlMq\n7bEqKePHm5g2LYB+/VwkJV2ZxGa1QqNGIZhMWkWvq4/1osTKsGsn4X1i0GWkY+//Gtljk7hc+kv3\n1xnCez6L4deDOKJ7c/GjGTnPlTcV9bi6GeUpVvn1hMtdKUPDzzuIeO5p1KAgzq/fjK92nWJ9v2tt\n26anW7cgevd28fHHuWfdmr5NJbxXT+wvvUL2RzOKtD+LBRwOpcRmRZeVg/rnn3UMGhTIiRM6qlf3\nsXWrNWd4ujA//aTnueeCCA9XsVgUnn/ezcyZ15eTLExZiVVxczigffsgDh/Ws3q1jcce04alL5fn\njI938vbbuZefLGqsdCfSCH/5RQwHD+Bs14GLcxainDtHRI9n0KcdxxY7EOvYpHK9vGRFPa5uRnmK\nVYUpZehp3JSLH05Fd+EC4X2iUS5mlej7rVypna3nORT92Xzg+hWyChIeTrm9LelGNG7sY/NmKyNH\nOlmyxF7kBAzQooWX6Gg3FouC2azy7rs3VmGpojObYdo0BzqdytChZmw2bSbUvHlGjEY1z8IkReWr\nWYsLazfkrLwV0aUjEV2fRJ92HGv8CKzjJpbrBCzEtcrl0e6MeQnbgDgMhw8R9nI0uuPHSuR9XC74\n+msj1ar5cnoLl+lOnsC0MRX3w4/gebBRibx/eRcaCkOHuvKtIFWQhAQnDRt6GTnSyZ13yknNjXrk\nER8DB7o5fly7vr51q57Dh/U8+6znlk8S1dAwLItXYO//GoaDB9CfOU32mAnY3h4pFY5EhVM+L7oA\n1oRx6E+cIOCbtUS1bort9WHYhgzVTvOLyebNei5cUBgwwH3tIliYkz9DUVXsfV8ttvcTRVepksrG\njcU7E7+iGT7cSWqqgTlzjGzZoh3gsbFFr4JUIIOB7MTJuJs9hmoOxPVkp+LZrxBlTLnsCQNgMJD1\n2RKyZs3HFx5B8KQJRLVqgunb1GJ7i1WrLs+KvmZ4zuUicMnn+MIjcD7zXLG9nxC3U2AgTJ2qXUs/\ndEjPo496eeih4l2r3flsd0nAokIrv0kYQFFwdu/J+W27sA0cgu6Pk4T36klYnxh0J9JuadfZ2bB+\nvYF77vHRqFHuL6aAb9aiSz+LI7qXVqtQiDKqaVMvr72mnWQOGlRMvWAhRI7ynYQvUUPDsI6ZwPlN\nP+Fq3oKA9f+fqJaNCfpoEjdVSw9ITTVgsyl07567PJv+14MEJY0DwPFK0SdkCVFajR7t5LvvrHTt\nWrHuXRfidqgQSfgyb/0GWFavI+v/zUUNDSM4aRyhQwdT5OrmV7m8VnTOrGhVxTx/NpEdH8fw+xFs\ng/6J9977irP5QviFXk+utbqFEMWnQiVhQBui7vEi57bvxv1IY8z/XkbQxPGFv+4q585pk7IeeMDL\nfff5UM6eJax3T0LfeQs1KAjLZ0uxfnBj+xRCCFHxVLwkfIkaFo7l82V4a91N8EeTMC9NLvJrk5NN\neDzaIhCmDd8Q1aYZAd9uwNXmCc5v2Y6rc5cSbLkQQojyosImYQC1ShUsy1bii4wkJP4NjFs2Ffqa\nrCz49FMTEeE+Bhx+i/CXXkTJyiJ7bCKWZV/i+1v129ByIYQQ5UGFTsIA3jr3YVm0DPR6wvq9jH7/\nvgK3nzPHyIULCvGGj/nb0k/w1G/A+dQt2AcMlpV+hBBC3BDJGoCnWXMuzpiFLvsi4b16oDv1Z57b\nZX//C7OneKhMOm9kJmCLHcj51C14/+v+29xiIYQQ5YEk4Uuc3Z4n+70x6E+fIrxXz1xrTuuP/EZY\n/z4s6LEZizeEN+/9Evd367GOn1SsK3AJIYSoWMrtspU3wz7kDfQn0ghcNJ+w/n24OHkaQdOmYF6a\nTKY3gqm6xVQNcxLzbS88sgaHEEKIWyRJ+GqKQnbih+hO/UHAxlQqPfoAAJ776jLu3lVkfxPMiHiH\nLIIlhBCiWMhw9LUMBrJmL8T9aBO8d97FxamfcihlB3O31qd6dR99+tx8GTchhBDiatITzktICBfW\nbtDKqikKM94LwGZTSEhwyiVgIYQQxUaScH4u3W505ozCokVG7rzTR69e0gsWQghRfGQ4uhDTpplw\nOBSGDXMREODv1gghhChPJAkX4I8/FJKTjdSq5ePFF6UXLIQQonhJEi7A1KkmXC6FN990YjT6uzVC\nCCHKG0nC+UhLU1i61EidOj569JA6qkIIIYqfJOF8fPRRAB6PQny8E4NMXxNCCFECJAnn4fBhHcuX\nG/j737106ya9YCGEECWjTCfhU6cU+vWDI0eUYt3vhAkmfD6FkSNd6PXFumshhBAiR5lOwn/8obBw\nIfToEcTJk8WTiHft0rFunZHGjb089ZT0goUQQpScMp2EmzTxMWkSnDqlo0ePIM6evbVErKowbpx2\nM/B77zlRireDLYQQQuRSppMwwFtvwdChTo4d0/HCC4FcuHDz+9q0Sc+2bQY6dPDQrJm3+BophBBC\n5KHMJ2GAd95x8Y9/uDhwQE+vXkFYrTe+D59P6wUrisq77zqLv5FCCCHENcpFElYUSEx00r27m127\n9PTtG4jzBvPoqlUG9u/X06OHhwYNfCXTUCGEEOIq5SIJg1ZvYcYMB08+6WHrVgODBpnxFHFelcsF\nSUkBGI0qw4dLL1gIIcTtUW6SMIDRCHPm2GnRwsPatUaGDTPjK0KnNjnZSFqajr593dSsqZZ8Q4UQ\nQgjKWRIGCAyE5GQ7jRp5WbbMyLBhAZw/n//22dkwZYqJ4GCVoUNdt6+hQgghKrxyl4QBQkLgiy/s\n1K/vZelSE02ahDB9ugmb7fptZ80ykZGhIy7ORZUq0gsWQghx+5TLJAxQqZLK+vU2Ro92oNNpM5+b\nNQvm88+NOdeKMzIUPv3UROXKPgYNkl6wEEKI26vcJmHQhqbj4tzs3JnN0KFOsrIU4uPNtGoVzNdf\nG/j4YxNWq8KwYS5CQvzdWiGEEBVNuU7Cl4WHw8iRLnbssNK3r4u0NIX+/QOZO9dEzZo++vRx+7uJ\nQgghKqAKkYQvq1ZNZdIkJz/+aKVbNzd6vcro0U5MJn+3TAghREVUISvl1q6tMmeOA48HqRUshBDC\nbypUT/hakoCFEEL4U4VOwkIIIYQ/SRIWQggh/ESSsBBCCOEnkoSFEEIIP5EkLIQQQviJJGEhhBDC\nTyQJCyGEEH4iSVgIIYTwE0nCQgghhJ9IEhZCCCH8RJKwEEII4SeKqqqqvxshhBBCVETSExZCCCH8\nRJKwEEII4SeShIUQQgg/kSQshBBC+IkkYSGEEMJPJAkLIYQQfmLwdwNuxYQJE/jll19QFIWRI0fy\n4IMP+rtJpc7hw4eJi4ujb9++vPTSS5w+fZq3334br9dLlSpV+PDDDzGZTP5uZqkwadIkdu/ejcfj\nYcCAATzwwAMSqzzY7XZGjBhBZmYmTqeTuLg46tWrJ7EqgMPhoEuXLsTFxdG8eXOJVR527NjBG2+8\nwX333QdA3bp1efXVV8t9rMpsT3jnzp2kpaWxfPlyxo8fz/jx4/3dpFLHZrMxduxYmjdvnvPY9OnT\n6dWrF0uXLqVWrVqkpKT4sYWlx3/+8x9+++03li9fzrx585gwYYLEKh+bN2/m/vvvZ/HixUydOpWk\npCSJVSFmzpxJeHg4IH+DBWnSpAnJyckkJyfz3nvvVYhYldkkvH37dtq3bw9AnTp1sFgsZGdn+7lV\npYvJZGLu3LlUrVo157EdO3bQrl07ANq2bcv27dv91bxSpXHjxkybNg2AsLAw7Ha7xCofnTt3JjY2\nFoDTp09TrVo1iVUBfv/9d44cOUKbNm0A+Ru8ERUhVmU2CWdkZBAZGZnze1RUFOnp6X5sUeljMBgw\nm825HrPb7TnDOZUqVZKYXaLX6wkKCgIgJSWF1q1bS6wKER0dTXx8PCNHjpRYFWDixImMGDEi53eJ\nVf6OHDnCwIEDiYmJ4aeffqoQsSrT14SvJqtv3jiJ2fW+/fZbUlJSWLBgAR07dsx5XGJ1vWXLlnHw\n4EHeeuutXPGRWF2xevVqGjVqxF133ZXn8xKrK+6++26GDBlCp06dOHnyJH369MHr9eY8X15jVWaT\ncNWqVcnIyMj5/ezZs1SpUsWPLSobgoKCcDgcmM1m/vrrr1xD1RXdDz/8wKxZs5g3bx6hoaESq3zs\n27ePSpUqUb16derXr4/X6yU4OFhilYctW7Zw8uRJtmzZwpkzZzCZTHJc5aNatWp07twZgJo1a1K5\ncmX27t1b7mNVZoejW7RoQWpqKgD79++natWqhISE+LlVpd9jjz2WE7cNGzbQqlUrP7eodLh48SKT\nJk1i9uzZREREABKr/OzatYsFCxYA2mUhm80mscrH1KlTWblyJStWrKBnz57ExcVJrPKxZs0a5s+f\nD0B6ejqZmZl079693MeqTFdRmjx5Mrt27UJRFBISEqhXr56/m1Sq7Nu3j4kTJ/Lnn39iMBioVq0a\nkydPZsSIETidTmrUqEFiYiJGo9HfTfW75cuXM2PGDO65556cx5KSkhg1apTE6hoOh4N3332X06dP\n43A4GDJkCPfffz/Dhw+XWBVgxowZ3HHHHbRs2VJilYfs7Gzi4+PJysrC7XYzZMgQ6tevX+5jVaaT\nsBBCCFGWldnhaCGEEKKskyQshBBC+IkkYSGEEMJPJAkLIYQQfiJJWAghhPATScJCCCGEn0gSFkII\nIfxEkrAQQgjhJ/8HNmNdEYO8heAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ae03e9278>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "plt2.plot(newp,color='red', label='Prediction')\n",
    "plt2.plot(newy_test,color='blue', label='Actual')\n",
    "plt2.legend(loc='best')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4igAFhJvB4ug"
   },
   "source": [
    "**Saving Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ReskBcgfrQuq"
   },
   "outputs": [],
   "source": [
    "model.save('LSTM_forex_prediction-20170429.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AH3eSshJCCFz"
   },
   "source": [
    "**Hyperparameter Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxiubkuQCkhJ"
   },
   "outputs": [],
   "source": [
    "seq_len = 22\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [128, 128, 32, 1]\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZG9eDHQOCO1b"
   },
   "outputs": [],
   "source": [
    "def quick_measure(forex_df_norm, seq_len, d, shape, neurons, epochs):\n",
    "    df = forex_df_norm\n",
    "    X_train, y_train, X_test, y_test = load_data(df, seq_len)\n",
    "    model = build_model2(shape, neurons, d)\n",
    "    model.fit(X_train, y_train, batch_size=24, epochs=epochs, validation_split=0.1, verbose=1)\n",
    "    # model.save('LSTM_Forex_prediction-20170429.h5')\n",
    "    trainScore, testScore = model_score(model, X_train, y_train, X_test, y_test)\n",
    "    return trainScore, testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75486
    },
    "colab_type": "code",
    "id": "gN-mstHPBJGO",
    "outputId": "99b9e575-71f8-488a-90ad-5c8673dda5a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 449 samples, validate on 50 samples\n",
      "Epoch 1/300\n",
      "449/449 [==============================] - 5s 11ms/step - loss: 0.0514 - acc: 0.0022 - val_loss: 0.0561 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0168 - acc: 0.0022 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0043 - acc: 0.0022 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0028 - acc: 0.0022 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0028 - acc: 0.0022 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0029 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0042 - acc: 0.0022 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0034 - acc: 0.0022 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "449/449 [==============================] - 4s 10ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "449/449 [==============================] - 4s 10ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "449/449 [==============================] - 4s 9ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "449/449 [==============================] - 3s 7ms/step - loss: 9.8616e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.8806e-04 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "449/449 [==============================] - 3s 7ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.6151e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.9288e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.6454e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.8570e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.5433e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.4383e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "449/449 [==============================] - 3s 7ms/step - loss: 9.5350e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.9982e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.8685e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.5690e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.8487e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.7331e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.1013e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.8966e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.9770e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.6369e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.6290e-04 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.5616e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.2552e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.0077e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.6042e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.3763e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.3527e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.9627e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.9381e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.5103e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.6115e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.5921e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.6863e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.9052e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.7097e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.1896e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.5483e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.5779e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.4218e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.0835e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.5148e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.6045e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.2187e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.5751e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.3051e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.1953e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.8880e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.4158e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.9465e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.1497e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.3070e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.7802e-04 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.8555e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.8063e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.0312e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.0687e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.8576e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.9993e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.4747e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.1350e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.1829e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.3310e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.1652e-04 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.3193e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.1956e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.7683e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.9749e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.0358e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.2855e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.3124e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.7185e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.1513e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.3575e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.6687e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.0506e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.4620e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.7674e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.0955e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.8518e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.3941e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.4894e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.9261e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.0944e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.5166e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.8961e-04 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.3583e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.4352e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.4199e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.1794e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.8894e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.7775e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.3534e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.7157e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.4304e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.5332e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.3394e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.5551e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.8538e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.8530e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.6942e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.3703e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.6106e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.6248e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.1468e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.6156e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.3172e-04 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.9441e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.8162e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.9100e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.5241e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.6626e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.3876e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.7124e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.7276e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.6770e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.4812e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.7519e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.8617e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.9176e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.1981e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.6127e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.2895e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.6569e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.6678e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.0379e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.6130e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.7375e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.7051e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.3373e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.2228e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.4655e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.2822e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.2227e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.1080e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.3694e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.7593e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.8471e-04 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.0753e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.4114e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.9296e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.9679e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.2307e-04 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.1246e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.5884e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.4076e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.0284e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.5881e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.7724e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.9933e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.8484e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.0559e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.3937e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.6044e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.5112e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.6766e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.0173e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.2785e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.6454e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.9258e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.2578e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.8514e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.7051e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.4479e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.8778e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.0645e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.4974e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.0638e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.7573e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.8041e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.5152e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.2951e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.7460e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.6283e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.5331e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.4900e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.0971e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.5749e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.9855e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.7580e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.8163e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.6348e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.2445e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.3086e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.2734e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.0157e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.9534e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.3767e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.9444e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.0552e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.1339e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.5803e-04 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.2774e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.2917e-04 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.0889e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.8789e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.1337e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.8725e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.3447e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.6524e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.1221e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.1819e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.9245e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.3133e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.7295e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.5338e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.7411e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.5935e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.9855e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.7510e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.8025e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.0723e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.0842e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.9085e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.4111e-04 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.5202e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.7519e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.6953e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.6501e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.5864e-04 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.6108e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.6290e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.6988e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.7800e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.8994e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.4826e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.7697e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.7156e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.4355e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.6505e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.1771e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.4030e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.7943e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.7918e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.5537e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.5217e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.1316e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.4131e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.1836e-04 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.5065e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.3897e-04 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.6464e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.2796e-04 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 4.9223e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00066 MSE (0.03 RMSE)\n",
      "Test Score: 0.00304 MSE (0.06 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 449 samples, validate on 50 samples\n",
      "Epoch 1/300\n",
      "449/449 [==============================] - 5s 12ms/step - loss: 0.0485 - acc: 0.0022 - val_loss: 0.0441 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0156 - acc: 0.0022 - val_loss: 0.0108 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0043 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0035 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0030 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0029 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0030 - acc: 0.0022 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.8610e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.3520e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.5444e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.7151e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.5703e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.4506e-04 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.4538e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.5263e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.6440e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.8569e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.3572e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.1820e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.2100e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.9717e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.6993e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.5738e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.9121e-04 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.0112e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.1895e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.8556e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.6050e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.7062e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.4988e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.4055e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.4023e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.2660e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.5603e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.5826e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.0181e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.8884e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.9687e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.2406e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.5867e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.0272e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.4416e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.6352e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.2154e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4936e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.5332e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1413e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1432e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.3710e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.5120e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8579e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.7629e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.2798e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.0800e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.0091e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8943e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.8670e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.9271e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4750e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4114e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7968e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.3990e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.8864e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.3688e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.1461e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.6454e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7273e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.8273e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.4133e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.4948e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1110e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.8793e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0894e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.6500e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0357e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3060e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.6012e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4840e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.9299e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.6160e-04 - acc: 0.0022 - val_loss: 9.7409e-04 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.6312e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.6377e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3518e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3072e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0016e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1321e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.0944e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.9736e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.2447e-04 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.3689e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.9312e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.4350e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.3424e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.8734e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.8432e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6199e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.5658e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.9263e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.5414e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1866e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.3804e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.3206e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.3474e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0609e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3069e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.4705e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.5935e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.5512e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0371e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.2842e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.8803e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.7786e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4181e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0364e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.6493e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.1303e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.9965e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.0575e-04 - acc: 0.0022 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.8390e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7150e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7495e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.0068e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.5778e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.6083e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8880e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8954e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.5554e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.2383e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8183e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1124e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1689e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8683e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2148e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0422e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.6201e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.4291e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.7878e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6812e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8570e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7214e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.6674e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6063e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8830e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6637e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3485e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.2907e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 4.9424e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.6265e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0881e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8602e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7460e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4415e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9950e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.0130e-04 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.4537e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.1361e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7556e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1999e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7277e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1132e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.9531e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2130e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1533e-04 - acc: 0.0022 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.3072e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.0614e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6322e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7980e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.5149e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4703e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7960e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1169e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2001e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.0793e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9786e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.8950e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.6193e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.5668e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.8544e-04 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.9192e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.5206e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.7195e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7112e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9722e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6701e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.4176e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2525e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.5446e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.0901e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.0551e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3001e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2558e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3070e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2718e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.4493e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4798e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7163e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.5124e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3602e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.0918e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1198e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.0678e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.4050e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8327e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1281e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9899e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2046e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.9942e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.0159e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.9985e-04 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3822e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.8382e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1631e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.8461e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2044e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.7444e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7103e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.7332e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2878e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.0618e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.0017e-04 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.0034e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.6730e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.8567e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9428e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 4.8599e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.1240e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9397e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.9153e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.3310e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6657e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.7155e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.0669e-04 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00058 MSE (0.02 RMSE)\n",
      "Test Score: 0.01089 MSE (0.10 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 449 samples, validate on 50 samples\n",
      "Epoch 1/300\n",
      "449/449 [==============================] - 5s 12ms/step - loss: 0.0582 - acc: 0.0022 - val_loss: 0.0495 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0239 - acc: 0.0022 - val_loss: 0.0233 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0076 - acc: 0.0022 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0042 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0036 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0033 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0032 - acc: 0.0022 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0030 - acc: 0.0022 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0029 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0030 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0039 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0036 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0033 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0031 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0032 - acc: 0.0022 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0034 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.8978e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.9907e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.7605e-04 - acc: 0.0022 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.2485e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.7117e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.7121e-04 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.9118e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.6663e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.8593e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.9300e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.2241e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.8392e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.9588e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.2014e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3971e-04 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3286e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.3102e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.6396e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.5451e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.0511e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.1169e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.7926e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.9802e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.0063e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.6936e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.5801e-04 - acc: 0.0022 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.0322e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.5631e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.7064e-04 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.9703e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.2548e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.8168e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7038e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.0093e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.4729e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.9679e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.7599e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.8275e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.5586e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.5205e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7338e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3513e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.1102e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.1997e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.2747e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.7749e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.0518e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.0140e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.0026e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.2889e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.4094e-04 - acc: 0.0022 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.9841e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.4907e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.0147e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.0307e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.0289e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.8045e-04 - acc: 0.0022 - val_loss: 0.0064 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.1494e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.7995e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.2265e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.1461e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.2399e-04 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.2870e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.3881e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.9472e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.6571e-04 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.3734e-04 - acc: 0.0022 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.8013e-04 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.4255e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.6423e-04 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7429e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.8959e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.5688e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.5445e-04 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1862e-04 - acc: 0.0022 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.6303e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.8132e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.4268e-04 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.2950e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1832e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.3798e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.8821e-04 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.5623e-04 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.4757e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.9133e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.3013e-04 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.2807e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.2578e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.9397e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.3445e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.9980e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.9641e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.3689e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7966e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.5404e-04 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.9532e-04 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.5926e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.7694e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3443e-04 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.7376e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.6056e-04 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.8249e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.4521e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.8277e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.3519e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1150e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.2747e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.5493e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7747e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.2897e-04 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.7416e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.4631e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.0640e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.3514e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7419e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.2920e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.3875e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.6187e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.4234e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.5853e-04 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.2178e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7224e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.2801e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.5748e-04 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.8711e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.6093e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.6131e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1857e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.3720e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1163e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.4183e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.2311e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.6705e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.6708e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.2293e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.1853e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.0483e-04 - acc: 0.0022 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.2819e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.4962e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.9911e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.2725e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.5362e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1798e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0994e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.9822e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8181e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.1800e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.1936e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.6797e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.4982e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.7335e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1754e-04 - acc: 0.0022 - val_loss: 0.0058 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.6325e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.6578e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.4042e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.1493e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.7453e-04 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.5825e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.9298e-04 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3086e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.3225e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.1057e-04 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.4834e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.0983e-04 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.9458e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0332e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.2138e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.2130e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6414e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.0927e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2719e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.0553e-04 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.6797e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.6001e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.1481e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.3432e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.0764e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.2567e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.3619e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6322e-04 - acc: 0.0022 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.7678e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8404e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.5754e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.6118e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8677e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.5949e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.7912e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8016e-04 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1592e-04 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0956e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.5522e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.0303e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1868e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.3606e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.0124e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7718e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.6078e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8211e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.2819e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7716e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 4.3987e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.6240e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1759e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.1939e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.0529e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.0160e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00056 MSE (0.02 RMSE)\n",
      "Test Score: 0.01458 MSE (0.12 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 449 samples, validate on 50 samples\n",
      "Epoch 1/300\n",
      "449/449 [==============================] - 6s 13ms/step - loss: 0.0551 - acc: 0.0022 - val_loss: 0.0604 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0208 - acc: 0.0022 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0085 - acc: 0.0022 - val_loss: 0.0148 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0045 - acc: 0.0022 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0049 - acc: 0.0022 - val_loss: 0.0060 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0037 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0034 - acc: 0.0022 - val_loss: 0.0060 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0033 - acc: 0.0022 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0032 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0033 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0033 - acc: 0.0022 - val_loss: 0.0118 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0039 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0031 - acc: 0.0022 - val_loss: 0.0058 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0028 - acc: 0.0022 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0028 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0029 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0028 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.7594e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.8142e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.7914e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.6382e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.8844e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.6317e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.6396e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.7776e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.4348e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.6735e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.7474e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.8235e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.6978e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.9900e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.3146e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.8524e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.4252e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.7163e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.3612e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3155e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3475e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.8742e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.6449e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.2012e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.3795e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.3869e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.1284e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.3195e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3330e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.8680e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.2039e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.1924e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.2739e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.7475e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.3580e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.1783e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.8686e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.7113e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.8950e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.8382e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.2167e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.5806e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.4504e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.0910e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.0074e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.5543e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.1540e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.1483e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.8341e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3136e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.2152e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.7879e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.9523e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.0122e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3389e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.2968e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.4101e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.1700e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.6270e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.0777e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.5295e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.7075e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.0978e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.2825e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.7172e-04 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.8636e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.8111e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.6471e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.1107e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4321e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.6043e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.9405e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.2610e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7363e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.9082e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7228e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.2904e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.7798e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.0083e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.9343e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.2004e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.0021e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7236e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7815e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8078e-04 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.4940e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.7252e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3282e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.1602e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.2106e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.8328e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4769e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.7218e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7867e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7404e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7888e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.8632e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.0752e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.6827e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.0738e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.4448e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4226e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.5620e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3077e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.1067e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.4576e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.5150e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.8734e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.3929e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.0833e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.4480e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.1890e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.0806e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.1730e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.2280e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7976e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.5688e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.6861e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.5940e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.0289e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.6847e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.6361e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.6526e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.4871e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.8125e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.3846e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7395e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.6673e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.5351e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.6549e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.6806e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.9991e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3185e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7592e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.4127e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.3696e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1258e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.8784e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.6114e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1838e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.6651e-04 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1075e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.2431e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1985e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8699e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.1417e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.2524e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.2086e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.5791e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1947e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.1783e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.3933e-04 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.5645e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.2746e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7769e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.9755e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.7139e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.6870e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7007e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.4038e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.8789e-04 - acc: 0.0022 - val_loss: 9.4613e-04 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.4164e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.2553e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.8642e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.8853e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.7600e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.5251e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.9670e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.5277e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.2972e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.1067e-04 - acc: 0.0022 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.8239e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.6915e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.4432e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.4235e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.1198e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.0378e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 5.7582e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3499e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.9955e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.7895e-04 - acc: 0.0022 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.6779e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.6157e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.1822e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 5.7699e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00073 MSE (0.03 RMSE)\n",
      "Test Score: 0.00688 MSE (0.08 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 449 samples, validate on 50 samples\n",
      "Epoch 1/300\n",
      "449/449 [==============================] - 6s 13ms/step - loss: 0.0568 - acc: 0.0022 - val_loss: 0.0475 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0176 - acc: 0.0022 - val_loss: 0.0076 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0089 - acc: 0.0022 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0058 - acc: 0.0022 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0052 - acc: 0.0022 - val_loss: 0.0131 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0040 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0041 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0036 - acc: 0.0022 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0039 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0035 - acc: 0.0022 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0044 - acc: 0.0022 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0039 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0032 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0034 - acc: 0.0022 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0037 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0036 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0036 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0033 - acc: 0.0022 - val_loss: 0.0060 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0028 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0027 - acc: 0.0022 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0028 - acc: 0.0022 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0036 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0031 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0027 - acc: 0.0022 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0031 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0027 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0027 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.8880e-04 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.9721e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.6646e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.5218e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.9304e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.9150e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.8978e-04 - acc: 0.0022 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.3410e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.4083e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.2897e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.8325e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.9073e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.2979e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.7514e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.9970e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.4022e-04 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.3059e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.8352e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.6165e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.3851e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.3218e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.7468e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3944e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.5988e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.1185e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.7485e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.8754e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.8094e-04 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.7522e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.1577e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.9008e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.8867e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.2356e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.3088e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.0173e-04 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.6471e-04 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.7423e-04 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.3827e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.6932e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.4900e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.0292e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.5059e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.3136e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.3366e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.9149e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.8909e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.8862e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.7187e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.6481e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.2338e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.2860e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.1816e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.8374e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.7517e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.6378e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.4484e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.9107e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3136e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.1067e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.7645e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.1293e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.2793e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.3742e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7669e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.6704e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.8991e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.6598e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.1484e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.6657e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.9601e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.3827e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7412e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.2227e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.5932e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.9171e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.8847e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.4284e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.0879e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.0081e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7299e-04 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.3396e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.9797e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.2290e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.8452e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4125e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1854e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.6543e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.5174e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.6628e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.6262e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1954e-04 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.7743e-04 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.6537e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.3564e-04 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7843e-04 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.4063e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.0510e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.6142e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3116e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.0847e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.5657e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.6907e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.1803e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4214e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.2670e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.1016e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.7478e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.2937e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.0874e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4803e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.9140e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.2193e-04 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4350e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4995e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.5952e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.0785e-04 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.6999e-04 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.7761e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.7402e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.2664e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.2625e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.7581e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.3378e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.8875e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.1313e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.2127e-04 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.8293e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.7883e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.4145e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.2777e-04 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.4976e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.2968e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.6029e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.2791e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.9077e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3854e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8834e-04 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8755e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3624e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.5394e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 5.7930e-04 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.6702e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00062 MSE (0.02 RMSE)\n",
      "Test Score: 0.00928 MSE (0.10 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 449 samples, validate on 50 samples\n",
      "Epoch 1/300\n",
      "449/449 [==============================] - 6s 14ms/step - loss: 0.0536 - acc: 0.0022 - val_loss: 0.0382 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0202 - acc: 0.0022 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0090 - acc: 0.0022 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0061 - acc: 0.0022 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0051 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0056 - acc: 0.0022 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0066 - acc: 0.0022 - val_loss: 0.0072 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0051 - acc: 0.0022 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0046 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0039 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0041 - acc: 0.0022 - val_loss: 0.0064 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0046 - acc: 0.0022 - val_loss: 0.0113 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0049 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0035 - acc: 0.0022 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0038 - acc: 0.0022 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0042 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0042 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0035 - acc: 0.0022 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0032 - acc: 0.0022 - val_loss: 0.0058 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0031 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0036 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0033 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0035 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0037 - acc: 0.0022 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0032 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0032 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0030 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0027 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0030 - acc: 0.0022 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0028 - acc: 0.0022 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0034 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0032 - acc: 0.0022 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0035 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0029 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0028 - acc: 0.0022 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.8521e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0058 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0088 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.3454e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0060 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.9783e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.7773e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.9535e-04 - acc: 0.0022 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.4453e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.4012e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.3100e-04 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.6126e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.5626e-04 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.2669e-04 - acc: 0.0022 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.3328e-04 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.6407e-04 - acc: 0.0022 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.6138e-04 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.0490e-04 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.7531e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.2827e-04 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.8127e-04 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.4750e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.8132e-04 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.4822e-04 - acc: 0.0022 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.6364e-04 - acc: 0.0022 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.9258e-04 - acc: 0.0022 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.5449e-04 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.7919e-04 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.4919e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.9623e-04 - acc: 0.0022 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.8066e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.2996e-04 - acc: 0.0022 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.8962e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.7537e-04 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.8207e-04 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.8488e-04 - acc: 0.0022 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3988e-04 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.5326e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.0707e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.0317e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.9529e-04 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.4542e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.7420e-04 - acc: 0.0022 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.7470e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.4721e-04 - acc: 0.0022 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.7884e-04 - acc: 0.0022 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 8.7530e-04 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.5896e-04 - acc: 0.0022 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.3423e-04 - acc: 0.0022 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.3385e-04 - acc: 0.0022 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.1645e-04 - acc: 0.0022 - val_loss: 0.0058 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.0054e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7599e-04 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.2991e-04 - acc: 0.0022 - val_loss: 0.0064 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.7895e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.3589e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.4354e-04 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.2568e-04 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.2535e-04 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.2192e-04 - acc: 0.0022 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.9163e-04 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.5538e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.6947e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.4481e-04 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.0831e-04 - acc: 0.0022 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.7638e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.9613e-04 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.8752e-04 - acc: 0.0022 - val_loss: 0.0058 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.0327e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.3931e-04 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.4368e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.1302e-04 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.7609e-04 - acc: 0.0022 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.7973e-04 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.2536e-04 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.6820e-04 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 8.0770e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.4509e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.8502e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.7359e-04 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.1063e-04 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.8243e-04 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 6.4308e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.4834e-04 - acc: 0.0022 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.7872e-04 - acc: 0.0022 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.6586e-04 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.7851e-04 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.4032e-04 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.7318e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.6908e-04 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 8.0377e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.4516e-04 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.1345e-04 - acc: 0.0022 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 7.3253e-04 - acc: 0.0022 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 7.4385e-04 - acc: 0.0022 - val_loss: 0.0063 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.5557e-04 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 6.3440e-04 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 7.2791e-04 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 6.3232e-04 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00075 MSE (0.03 RMSE)\n",
      "Test Score: 0.02559 MSE (0.16 RMSE)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 449 samples, validate on 50 samples\n",
      "Epoch 1/300\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.0567 - acc: 0.0022 - val_loss: 0.0302 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0264 - acc: 0.0022 - val_loss: 0.0244 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0117 - acc: 0.0022 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0070 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0070 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0055 - acc: 0.0022 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0061 - acc: 0.0022 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0074 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0057 - acc: 0.0022 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0040 - acc: 0.0022 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0053 - acc: 0.0022 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0041 - acc: 0.0022 - val_loss: 0.0063 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0057 - acc: 0.0022 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0050 - acc: 0.0022 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0047 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0049 - acc: 0.0022 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0044 - acc: 0.0022 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0041 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0043 - acc: 0.0022 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0043 - acc: 0.0022 - val_loss: 0.0063 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0035 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0040 - acc: 0.0022 - val_loss: 0.0064 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0034 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0041 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0033 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0033 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0037 - acc: 0.0022 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0035 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0031 - acc: 0.0022 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0034 - acc: 0.0022 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0040 - acc: 0.0022 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0037 - acc: 0.0022 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0032 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0031 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0027 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0029 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0033 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0030 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0029 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0029 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0028 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0028 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0027 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0027 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0028 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0027 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0027 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0026 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0023 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0024 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0022 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0025 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0020 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0021 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0018 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 9.9032e-04 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 9.2227e-04 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0019 - acc: 0.0022 - val_loss: 9.3755e-04 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 8.8567e-04 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 8.5066e-04 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 9.1953e-04 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0017 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0016 - acc: 0.0022 - val_loss: 8.9240e-04 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0014 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 9.8577e-04 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0015 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0013 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.9672e-04 - acc: 0.0022 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.2587e-04 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 9.1603e-04 - acc: 0.0022 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.8204e-04 - acc: 0.0022 - val_loss: 0.0060 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0012 - acc: 0.0022 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.0010 - acc: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 9.1465e-04 - acc: 0.0022 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "449/449 [==============================] - 2s 6ms/step - loss: 0.0011 - acc: 0.0022 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "449/449 [==============================] - 3s 6ms/step - loss: 9.5294e-04 - acc: 0.0022 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Train Score: 0.00075 MSE (0.03 RMSE)\n",
      "Test Score: 0.03311 MSE (0.18 RMSE)\n"
     ]
    }
   ],
   "source": [
    "dlist = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "neurons_LSTM = [32, 64, 128, 256, 512, 1024, 2048]\n",
    "dropout_result = {}\n",
    "\n",
    "for d in dlist:    \n",
    "    trainScore, testScore = quick_measure(forex_df_norm, seq_len, d, shape, neurons, epochs)\n",
    "    dropout_result[d] = testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r_aI7m88BJer"
   },
   "outputs": [],
   "source": [
    "def percentage_difference(model, X_test, y_test):\n",
    "    percentage_diff=[]\n",
    "\n",
    "    p = model.predict(X_test)\n",
    "    for u in range(len(y_test)): # for each data index in test data\n",
    "        pr = p[u][0] # pr = prediction on day u\n",
    "\n",
    "        percentage_diff.append((pr-y_test[u]/pr)*100)\n",
    "    return p\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1a02sR1BBJj2"
   },
   "outputs": [],
   "source": [
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]\n",
    "\n",
    "\n",
    "model_score(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "teikFNpiBJqo",
    "outputId": "66352297-d92b-40a8-8342-751471423ea2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-258f7737a3ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finding the best hyperparameter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Days'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seq_len_result' is not defined"
     ]
    }
   ],
   "source": [
    "lists = sorted(seq_len_result.items())\n",
    "x,y = zip(*lists)\n",
    "plt.plot(x,y)\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwoqXlbCBJio"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5CniBZK9BJdT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TensorFlow_LSTM_Final123.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
